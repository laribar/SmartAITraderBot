{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laribar/SmartAITraderBot/blob/main/Modelo_Funcional_Close%2C_Min_High.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDCUpKv0IhK",
        "outputId": "869742bd-e961-4709-a0a6-878e188440e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=7dc60a11baf4da47104b6bddfd8b7ce53164e324a2ceb8215764c43c61b76593\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Collecting python-binance\n",
            "  Downloading python_binance-1.0.28-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-binance) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from python-binance) (1.17.0)\n",
            "Collecting dateparser (from python-binance)\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from python-binance) (3.11.15)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from python-binance) (15.0.1)\n",
            "Collecting pycryptodome (from python-binance)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.20.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2025.1.31)\n",
            "Downloading python_binance-1.0.28-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome, dateparser, python-binance\n",
            "Successfully installed dateparser-1.2.1 pycryptodome-3.22.0 python-binance-1.0.28\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "!pip install yfinance\n",
        "!pip install xgboost\n",
        "!pip install python-binance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # ====================================================\n",
        "  # 1. IMPORTAÇÕES\n",
        "  # ====================================================\n",
        "  import yfinance as yf\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "  import ta\n",
        "  import requests\n",
        "  import time  # Para usar time.sleep()\n",
        "  import matplotlib.pyplot as plt\n",
        "  from datetime import datetime\n",
        "  from datetime import timedelta\n",
        "  import pytz\n",
        "  import glob\n",
        "  import json\n",
        "  import warnings\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.metrics import classification_report\n",
        "  from xgboost import XGBClassifier\n",
        "  XGBClassifier(\n",
        "      n_estimators=200,\n",
        "      max_depth=4,                 # menor profundidade = menos overfitting\n",
        "      subsample=0.8,               # usa 80% dos dados por árvore\n",
        "      colsample_bytree=0.8,        # usa 80% das features por árvore\n",
        "      learning_rate=0.05,          # suaviza o aprendizado\n",
        "      early_stopping_rounds=10,    # para de treinar se não melhorar\n",
        "      eval_metric=\"mlogloss\",\n",
        "      use_label_encoder=False,\n",
        "      random_state=42\n",
        "  )\n",
        "\n",
        "  from tensorflow.keras.models import Sequential\n",
        "  from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "  from sklearn.preprocessing import MinMaxScaler\n",
        "  from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "  # Fuso horário do Brasil\n",
        "  BR_TZ = pytz.timezone(\"America/Sao_Paulo\")\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # BLOCO 1 - CONFIGURAÇÃO DE PASTAS E IMPORTS EXTRA\n",
        "  # ====================================================\n",
        "  import os\n",
        "  import joblib\n",
        "  from tensorflow.keras.models import load_model\n",
        "\n",
        "  # Criar pasta onde os modelos serão salvos\n",
        "  os.makedirs(\"/content/models\", exist_ok=True)\n",
        "  # ====================================================\n",
        "  # BLOCO 2 - SALVAR E CARREGAR MODELOS TREINADOS\n",
        "  # ====================================================\n",
        "  def get_model_path(asset, interval, model_type=\"xgb\"):\n",
        "      asset_clean = asset.replace(\"-\", \"\")\n",
        "      ext = \"joblib\" if model_type == \"xgb\" else \"h5\"\n",
        "      return f\"/content/models/{model_type}_model_{asset_clean}_{interval}.{ext}\"\n",
        "\n",
        "  # --- XGBoost ---\n",
        "  def save_xgb_model(model, asset, interval):\n",
        "      path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "      joblib.dump(model, path)\n",
        "      print(f\"💾 Modelo XGBoost salvo em: {path}\")\n",
        "\n",
        "  def load_xgb_model(asset, interval):\n",
        "      path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "      if os.path.exists(path):\n",
        "          print(f\"📂 Modelo XGBoost carregado de: {path}\")\n",
        "          return joblib.load(path)\n",
        "      return None\n",
        "\n",
        "  # --- LSTM ---\n",
        "  def save_lstm_model(model, asset, interval):\n",
        "      path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "      model.save(path)\n",
        "      print(f\"💾 Modelo LSTM salvo em: {path}\")\n",
        "\n",
        "      # Salvar metadados no novo formato\n",
        "      meta_path = path.replace(\".h5\", \"_meta.pkl\").replace(\".keras\", \"_meta.pkl\")\n",
        "      joblib.dump({\n",
        "          \"scaler_x\": model.scaler_x,\n",
        "          \"scaler_y\": model.scaler_y,\n",
        "          \"feature_cols\": model.feature_cols,\n",
        "          \"target_cols\": model.target_cols,\n",
        "          \"window_size\": model.window_size\n",
        "      }, meta_path)\n",
        "      print(f\"📦 Metadados salvos em: {meta_path}\")\n",
        "\n",
        "\n",
        "\n",
        "  def load_lstm_model(asset, interval, window_size=20):\n",
        "      from tensorflow.keras.models import load_model\n",
        "      import joblib\n",
        "      import os\n",
        "\n",
        "      model_path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "      meta_path = model_path.replace(\".h5\", \"_meta.pkl\").replace(\".keras\", \"_meta.pkl\")\n",
        "\n",
        "      if not os.path.exists(model_path):\n",
        "          print(f\"🚫 Modelo LSTM NÃO encontrado em: {model_path}\")\n",
        "          return None\n",
        "\n",
        "      try:\n",
        "          model = load_model(model_path, compile=False)\n",
        "          print(f\"📂 Modelo LSTM encontrado em: {model_path}\")\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Erro ao carregar modelo LSTM de {model_path}: {e}\")\n",
        "          return None\n",
        "\n",
        "      # Carrega os metadados\n",
        "      if os.path.exists(meta_path):\n",
        "          try:\n",
        "              meta = joblib.load(meta_path)\n",
        "              model.scaler_x = meta.get(\"scaler_x\")\n",
        "              model.scaler_y = meta.get(\"scaler_y\")\n",
        "              model.feature_cols = meta.get(\"feature_cols\")\n",
        "              model.target_cols = meta.get(\"target_cols\", [\"High\", \"Low\", \"Close\"])\n",
        "              model.window_size = meta.get(\"window_size\", window_size)\n",
        "\n",
        "              # ✅ Compatibilidade com códigos antigos\n",
        "              model.scaler = model.scaler_x\n",
        "\n",
        "              print(f\"📦 Metadados carregados de: {meta_path}\")\n",
        "          except Exception as e:\n",
        "              print(f\"⚠️ Erro ao carregar metadados de {meta_path}: {e}\")\n",
        "              model.scaler_x = None\n",
        "              model.scaler_y = None\n",
        "              model.scaler = None\n",
        "              model.feature_cols = None\n",
        "              model.target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "              model.window_size = window_size\n",
        "      else:\n",
        "          print(f\"⚠️ Metadados não encontrados em: {meta_path}\")\n",
        "          model.scaler_x = None\n",
        "          model.scaler_y = None\n",
        "          model.scaler = None\n",
        "          model.feature_cols = None\n",
        "          model.target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "          model.window_size = window_size\n",
        "\n",
        "      return model\n",
        "\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 2. CONFIGURAÇÕES\n",
        "  # ====================================================\n",
        "  ASSETS = [\"BTC-USD\" , \"ETH-USD\", \"SOL-USD\", \"XRP-USD\", \"AVAX-USD\", \"AAVE-USD\", \"DOT-USD\", \"NEAR-USD\", \"ADA-USD\", \"VIRTUAL-USD\", \"PENDLE-USD\"]\n",
        "\n",
        "\n",
        "  TIMEFRAMES = [\n",
        "      {\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02},\n",
        "      {\"interval\": \"1h\", \"period\": \"90d\", \"atr\": 0.03},\n",
        "      {\"interval\": \"1d\", \"period\": \"1000d\", \"atr\": 0.05},\n",
        "      {\"interval\": \"1wk\", \"period\": \"max\", \"atr\": 0.08}  # 👈 Adicionado o semanal\n",
        "  ]\n",
        "\n",
        "  TELEGRAM_TOKEN = \"8142008777:AAHvP5uHzEmQqR4xKyu_bfm0Vf3C8cYbmj0\"\n",
        "  TELEGRAM_CHAT_ID = \"-4744645054\"\n",
        "  ALERTA_VARIACAO_MINIMA = {\n",
        "      \"15m\": 1.0,\n",
        "      \"1h\": 2.0,\n",
        "      \"1d\": 5.0,\n",
        "      \"1wk\": 5.0\n",
        "  }\n",
        "  # ====================================================\n",
        "  # 3. COLETA DE DADOS\n",
        "  # ====================================================\n",
        "  def get_stock_data(asset, interval=\"15m\", period=\"30d\", max_retries=3, sleep_sec=5):\n",
        "      import time\n",
        "      for attempt in range(max_retries):\n",
        "          try:\n",
        "              data = yf.download(asset, period=period, interval=interval, progress=False, auto_adjust=False)\n",
        "              if data.empty:\n",
        "                  raise ValueError(f\"⚠️ Dados vazios recebidos de {asset} ({interval})\")\n",
        "              if isinstance(data.columns, pd.MultiIndex):\n",
        "                  data.columns = data.columns.get_level_values(0)\n",
        "              data.columns = [col.split()[-1] if \" \" in col else col for col in data.columns]\n",
        "              data = data.loc[:, ~data.columns.duplicated()]\n",
        "              col_map = {col: std_col for col in data.columns for std_col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"] if std_col.lower() in col.lower()}\n",
        "              data = data.rename(columns=col_map)\n",
        "              data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "              if not all(col in data.columns for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]):\n",
        "                  raise ValueError(f\"⚠️ Colunas necessárias ausentes em {asset} ({interval})\")\n",
        "              return data\n",
        "          except Exception as e:\n",
        "              print(f\"❌ Falha na tentativa {attempt+1} para {asset} ({interval}): {e}\")\n",
        "              time.sleep(sleep_sec)\n",
        "      raise RuntimeError(f\"❌ Falha ao baixar dados de {asset} ({interval}) após {max_retries} tentativas.\")\n",
        "\n",
        "\n",
        "\n",
        "  def safe_read_csv(filepath):\n",
        "      import os\n",
        "      import pandas as pd\n",
        "\n",
        "      if not os.path.exists(filepath):\n",
        "          print(f\"⚠️ Arquivo não encontrado: {filepath}\")\n",
        "          return None\n",
        "      if os.path.getsize(filepath) == 0:\n",
        "          print(f\"⚠️ Arquivo está vazio: {filepath}\")\n",
        "          return None\n",
        "      try:\n",
        "          df = pd.read_csv(filepath)\n",
        "          if df.empty or len(df.columns) == 0:\n",
        "              print(f\"⚠️ Arquivo inválido (sem colunas): {filepath}\")\n",
        "              return None\n",
        "          return df\n",
        "      except pd.errors.EmptyDataError:\n",
        "          print(f\"⚠️ Erro: arquivo sem colunas: {filepath}\")\n",
        "          return None\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ Erro inesperado ao ler CSV: {e}\")\n",
        "          return None\n",
        "\n",
        "  def criar_prediction_log_padrao(filepath=\"/content/prediction_log.csv\"):\n",
        "      import pandas as pd\n",
        "      import os\n",
        "\n",
        "      colunas_padroes = [\n",
        "          \"Asset\", \"Timeframe\", \"Date\", \"Price\", \"Signal\", \"Confidence\", \"AdjustedProb\",\n",
        "          \"TP1\", \"TP2\", \"SL\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\",\n",
        "          \"LSTM_Predicted\", \"TargetPrice\",\n",
        "          \"LSTM_High_Predicted\", \"LSTM_Low_Predicted\",  # ✅ Novas colunas\n",
        "          \"Acertou\", \"Resultado\", \"PrecoSaida\", \"LucroEstimado\", \"DuracaoMin\"\n",
        "      ]\n",
        "\n",
        "      if not os.path.exists(filepath) or os.path.getsize(filepath) == 0:\n",
        "          print(f\"📄 Criando novo prediction_log com colunas padrão em: {filepath}\")\n",
        "          df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "          df_vazio.to_csv(filepath, index=False)\n",
        "      else:\n",
        "          try:\n",
        "              df_existente = pd.read_csv(filepath)\n",
        "              if df_existente.empty or len(df_existente.columns) == 0:\n",
        "                  print(f\"⚠️ Arquivo está corrompido. Recriando...\")\n",
        "                  df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "                  df_vazio.to_csv(filepath, index=False)\n",
        "              else:\n",
        "                  missing_cols = [col for col in colunas_padroes if col not in df_existente.columns]\n",
        "                  if missing_cols:\n",
        "                      print(f\"⚠️ Adicionando colunas faltantes: {missing_cols}\")\n",
        "                      for col in missing_cols:\n",
        "                          df_existente[col] = None\n",
        "                      df_existente.to_csv(filepath, index=False)\n",
        "          except Exception as e:\n",
        "              print(f\"❌ Erro ao validar o log existente. Recriando. Erro: {e}\")\n",
        "              df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "              df_vazio.to_csv(filepath, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 4. INDICADORES TÉCNICOS\n",
        "  # ====================================================\n",
        "def calculate_indicators(data):\n",
        "    data = data.copy().reset_index(drop=True)\n",
        "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
        "        data[col] = data[col].astype(float)\n",
        "\n",
        "    # Indicadores clássicos\n",
        "    try:\n",
        "        data[\"RSI\"] = ta.momentum.RSIIndicator(close=data[\"Close\"], window=14).rsi()\n",
        "        data[\"SMA_50\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=50).sma_indicator()\n",
        "        data[\"SMA_200\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=200).sma_indicator()\n",
        "\n",
        "        macd = ta.trend.MACD(close=data[\"Close\"])\n",
        "        data[\"MACD\"] = macd.macd()\n",
        "        data[\"MACD_Signal\"] = macd.macd_signal()\n",
        "\n",
        "        bb = ta.volatility.BollingerBands(close=data[\"Close\"], window=20)\n",
        "        data[\"Bollinger_Upper\"] = bb.bollinger_hband()\n",
        "        data[\"Bollinger_Lower\"] = bb.bollinger_lband()\n",
        "\n",
        "        adx = ta.trend.ADXIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "        data[\"ADX\"] = adx.adx()\n",
        "\n",
        "        stoch = ta.momentum.StochasticOscillator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "        data[\"Stoch_K\"] = stoch.stoch()\n",
        "        data[\"Stoch_D\"] = stoch.stoch_signal()\n",
        "\n",
        "        # Indicadores adicionais\n",
        "        data[\"ATR\"] = ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"]).average_true_range()\n",
        "        data[\"ROC\"] = ta.momentum.ROCIndicator(close=data[\"Close\"], window=12).roc()\n",
        "        data[\"OBV\"] = ta.volume.OnBalanceVolumeIndicator(close=data[\"Close\"], volume=data[\"Volume\"]).on_balance_volume()\n",
        "        data[\"CCI\"] = ta.trend.CCIIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=20).cci()\n",
        "\n",
        "        ichimoku = ta.trend.IchimokuIndicator(high=data[\"High\"], low=data[\"Low\"], window1=9, window2=26)\n",
        "        data[\"Tenkan_Sen\"] = ichimoku.ichimoku_conversion_line()\n",
        "        data[\"Kijun_Sen\"] = ichimoku.ichimoku_base_line()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao calcular indicadores: {e}\")\n",
        "\n",
        "    # VWAP\n",
        "    try:\n",
        "        data[\"TP\"] = (data[\"High\"] + data[\"Low\"] + data[\"Close\"]) / 3\n",
        "        data[\"VWAP\"] = (data[\"TP\"] * data[\"Volume\"]).cumsum() / (data[\"Volume\"].replace(0, np.nan).cumsum())\n",
        "        data.drop(\"TP\", axis=1, inplace=True)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao calcular VWAP: {e}\")\n",
        "\n",
        "    # Candlestick patterns\n",
        "    try:\n",
        "        data[\"Doji\"] = ((abs(data[\"Close\"] - data[\"Open\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9)) < 0.1).astype(int)\n",
        "        data[\"Engulfing\"] = ((data[\"Open\"].shift(1) > data[\"Close\"].shift(1)) & (data[\"Open\"] < data[\"Close\"]) &\n",
        "                            (data[\"Close\"] > data[\"Open\"].shift(1)) & (data[\"Open\"] < data[\"Close\"].shift(1))).astype(int)\n",
        "        data[\"Hammer\"] = (((data[\"High\"] - data[\"Low\"]) > 3 * abs(data[\"Open\"] - data[\"Close\"])) &\n",
        "                        ((data[\"Close\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6) &\n",
        "                        ((data[\"Open\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6)).astype(int)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao calcular padrões de candle: {e}\")\n",
        "        # Garante que existam\n",
        "        data[\"Doji\"] = 0\n",
        "        data[\"Engulfing\"] = 0\n",
        "        data[\"Hammer\"] = 0\n",
        "\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 4. MODELOS DE MACHINE LEARNING (XGBoost + LSTM)\n",
        "  # ====================================================\n",
        "\n",
        "  def get_feature_columns(df, include_lstm_pred=False):\n",
        "      \"\"\"\n",
        "      Retorna a lista de colunas de features para os modelos.\n",
        "      Se include_lstm_pred=True, inclui a coluna LSTM_PRED para uso no XGBoost.\n",
        "      \"\"\"\n",
        "      base_features = [\n",
        "          'Open', 'High', 'Low', 'Close', 'Volume',\n",
        "          'SMA_5', 'SMA_20', 'EMA_12', 'EMA_26',\n",
        "          'RSI', 'MACD', 'MACD_signal', 'MACD_hist',\n",
        "          'BB_upper', 'BB_middle', 'BB_lower',\n",
        "          'ATR', 'CCI', 'ROC', 'OBV'\n",
        "      ]\n",
        "      if include_lstm_pred:\n",
        "          base_features.append(\"LSTM_PRED\")\n",
        "      return [col for col in base_features if col in df.columns]\n",
        "\n",
        "\n",
        "  def get_lstm_feature_columns():\n",
        "      return [\n",
        "          \"Close\", \"High\", \"Low\",  # 🟢 Agora inclui as três colunas principais como features também\n",
        "          \"RSI\", \"MACD\", \"MACD_Signal\", \"SMA_50\", \"SMA_200\",\n",
        "          \"Bollinger_Upper\", \"Bollinger_Lower\",\n",
        "          \"ADX\", \"Stoch_K\", \"Stoch_D\",\n",
        "          \"ATR\", \"ROC\", \"OBV\", \"CCI\",\n",
        "          \"Tenkan_Sen\", \"Kijun_Sen\", \"VWAP\",\n",
        "          \"Doji\", \"Engulfing\", \"Hammer\"\n",
        "      ]\n",
        "\n",
        "\n",
        "  def prepare_lstm_data(data, feature_cols=None, target_cols=[\"High\", \"Low\", \"Close\"], window_size=20):\n",
        "      if feature_cols is None:\n",
        "          feature_cols = get_lstm_feature_columns()\n",
        "\n",
        "      missing = [col for col in feature_cols + target_cols if col not in data.columns]\n",
        "      if missing:\n",
        "          raise ValueError(f\"❌ Colunas ausentes no DataFrame: {missing}\")\n",
        "\n",
        "      df = data[feature_cols + target_cols].dropna().astype(float)\n",
        "      if len(df) < window_size + 1:\n",
        "          raise ValueError(f\"⚠️ Dados insuficientes: {len(df)} rows, necessário mínimo {window_size + 1}\")\n",
        "\n",
        "      # Escalonamento separado\n",
        "      scaler_x = MinMaxScaler()\n",
        "      scaler_y = MinMaxScaler()\n",
        "\n",
        "      scaled_X = scaler_x.fit_transform(df[feature_cols])\n",
        "      scaled_y = scaler_y.fit_transform(df[target_cols])\n",
        "\n",
        "      X, y = [], []\n",
        "      for i in range(window_size, len(df)):\n",
        "          X.append(scaled_X[i - window_size:i])\n",
        "          y.append(scaled_y[i])  # Previsão para o instante i\n",
        "\n",
        "      X = np.array(X)\n",
        "      y = np.array(y)\n",
        "\n",
        "      print(f\"✅ prepare_lstm_data | X.shape: {X.shape}, y.shape: {y.shape}\")\n",
        "      return X, y, scaler_x, scaler_y\n",
        "\n",
        "\n",
        "\n",
        "  def train_lstm_model(df, *, asset, interval, window_size=20, force_retrain=False):\n",
        "      import os\n",
        "      import numpy as np\n",
        "      import joblib\n",
        "      from tensorflow.keras.models import Sequential\n",
        "      from tensorflow.keras.layers import LSTM, Dense\n",
        "      from tensorflow.keras.callbacks import EarlyStopping\n",
        "      from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "      feature_cols = get_lstm_feature_columns()\n",
        "      target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "      df = df.dropna(subset=feature_cols + target_cols)\n",
        "\n",
        "      if len(df) <= window_size:\n",
        "          raise ValueError(\"Dados insuficientes para treino do LSTM.\")\n",
        "\n",
        "      df_features = df[feature_cols]\n",
        "      df_targets = df[target_cols]\n",
        "\n",
        "      scaler_x = MinMaxScaler()\n",
        "      scaler_y = MinMaxScaler()\n",
        "\n",
        "      scaled_features = scaler_x.fit_transform(df_features)\n",
        "      scaled_targets = scaler_y.fit_transform(df_targets)\n",
        "\n",
        "      X, y = [], []\n",
        "      for i in range(window_size, len(df)):\n",
        "          X.append(scaled_features[i - window_size:i])\n",
        "          y.append(scaled_targets[i])\n",
        "\n",
        "      X = np.array(X)\n",
        "      y = np.array(y)\n",
        "\n",
        "      print(f\"✅ X.shape: {X.shape}, y.shape: {y.shape}\")\n",
        "\n",
        "      model_path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "      meta_path = model_path.replace(\".h5\", \"_meta.pkl\")\n",
        "\n",
        "      if not force_retrain and os.path.exists(model_path):\n",
        "          model = load_lstm_model(asset, interval)\n",
        "          if model and all(hasattr(model, attr) for attr in [\"scaler_x\", \"scaler_y\", \"feature_cols\", \"window_size\", \"target_cols\"]):\n",
        "              return model\n",
        "          else:\n",
        "              print(\"⚠️ Modelo existente não contém atributos. Será refeito.\")\n",
        "\n",
        "      model = Sequential()\n",
        "      model.add(LSTM(64, return_sequences=False, input_shape=(X.shape[1], X.shape[2])))\n",
        "      model.add(Dense(3))  # Prever [High, Low, Close]\n",
        "      model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "      es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "      model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[es], verbose=0)\n",
        "\n",
        "      # Atributos para reuso\n",
        "      model.scaler_x = scaler_x\n",
        "      model.scaler_y = scaler_y\n",
        "      model.scaler = scaler_x  # ✅ Compatibilidade com códigos antigos\n",
        "      model.feature_cols = feature_cols\n",
        "      model.target_cols = target_cols\n",
        "      model.window_size = window_size\n",
        "\n",
        "      model.save(model_path)\n",
        "      joblib.dump({\n",
        "          \"scaler_x\": scaler_x,\n",
        "          \"scaler_y\": scaler_y,\n",
        "          \"feature_cols\": feature_cols,\n",
        "          \"target_cols\": target_cols,\n",
        "          \"window_size\": window_size\n",
        "      }, meta_path)\n",
        "\n",
        "      print(f\"💾 Modelo LSTM salvo em: {model_path}\")\n",
        "      print(f\"📦 Metadados salvos em: {meta_path}\")\n",
        "      return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def train_ml_model(data, asset=None, interval=None, verbose=False):\n",
        "      if asset and interval:\n",
        "          existing_model = load_xgb_model(asset, interval)\n",
        "          if existing_model is not None:\n",
        "              print(f\"✅ Modelo XGBoost já existente para {asset} ({interval}), carregado.\")\n",
        "              return existing_model\n",
        "\n",
        "      if len(data) < 100:\n",
        "          return None\n",
        "\n",
        "      df = data.copy()\n",
        "      df = calculate_indicators(df)\n",
        "\n",
        "      try:\n",
        "          lstm_model = train_lstm_model(df, asset=asset, interval=interval, window_size=20, force_retrain=False)\n",
        "\n",
        "          if lstm_model:\n",
        "              print(\"✅ Features usadas no LSTM:\")\n",
        "              print(lstm_model.feature_cols)\n",
        "\n",
        "              print(\"✅ Últimos dados de entrada:\")\n",
        "              print(df[lstm_model.feature_cols].tail(3))\n",
        "\n",
        "              # ✅ Aqui está a correção do print (substitui 'model.scaler')\n",
        "              print(\"✅ Valores mínimos do scaler X:\")\n",
        "              print(lstm_model.scaler_x.data_min_)\n",
        "              print(\"✅ Valores máximos do scaler X:\")\n",
        "              print(lstm_model.scaler_x.data_max_)\n",
        "\n",
        "          # Previsões com LSTM para gerar LSTM_PRED\n",
        "          if lstm_model is not None:\n",
        "              lstm_preds = []\n",
        "              for i in range(len(df)):\n",
        "                  sub_df = df.iloc[:i+1]\n",
        "                  if len(sub_df) < lstm_model.window_size:\n",
        "                      lstm_preds.append(np.nan)\n",
        "                  else:\n",
        "                      try:\n",
        "                          pred = predict_with_lstm(lstm_model, sub_df)\n",
        "                          lstm_preds.append(pred.get(\"Close\", np.nan))\n",
        "                      except Exception as e:\n",
        "                          print(f\"⚠️ Erro ao prever com LSTM: {e}\")\n",
        "                          lstm_preds.append(np.nan)\n",
        "              df[\"LSTM_PRED\"] = lstm_preds\n",
        "          else:\n",
        "              df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ Erro ao gerar LSTM_PRED: {e}\")\n",
        "          df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "      if \"LSTM_PRED\" not in df.columns:\n",
        "          print(\"❌ Coluna 'LSTM_PRED' não foi gerada. Abortando treino do XGBoost.\")\n",
        "          return None\n",
        "\n",
        "      df[\"Future_Close\"] = df[\"Close\"].shift(-5)\n",
        "      df[\"Future_Return\"] = df[\"Future_Close\"] / df[\"Close\"] - 1\n",
        "      df = df[(df[\"Future_Return\"] > 0.015) | (df[\"Future_Return\"] < -0.015)].copy()\n",
        "      df[\"Signal\"] = np.where(df[\"Future_Return\"] > 0.015, 1, 0)\n",
        "\n",
        "      features = get_feature_columns(df, include_lstm_pred=True)\n",
        "      df.dropna(inplace=True)\n",
        "\n",
        "      missing_features = [f for f in features if f not in df.columns]\n",
        "      if missing_features:\n",
        "          print(f\"❌ Features ausentes: {missing_features}\")\n",
        "          return None\n",
        "\n",
        "      X = df[features]\n",
        "      y = df[\"Signal\"]\n",
        "\n",
        "      if len(np.unique(y)) < 2:\n",
        "          return None\n",
        "\n",
        "      from sklearn.model_selection import TimeSeriesSplit\n",
        "      tscv = TimeSeriesSplit(n_splits=5)\n",
        "      for train_index, val_index in tscv.split(X):\n",
        "          X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "          y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "          break\n",
        "\n",
        "      if len(np.unique(y_train)) < 2:\n",
        "          return None\n",
        "\n",
        "      scale_pos_weight = len(y_train[y_train == 0]) / max(1, len(y_train[y_train == 1]))\n",
        "\n",
        "      model = XGBClassifier(\n",
        "          n_estimators=200,\n",
        "          max_depth=6,\n",
        "          learning_rate=0.1,\n",
        "          use_label_encoder=False,\n",
        "          eval_metric=\"logloss\",\n",
        "          scale_pos_weight=scale_pos_weight,\n",
        "          random_state=42\n",
        "      )\n",
        "\n",
        "      model.fit(\n",
        "          X_train, y_train,\n",
        "          eval_set=[(X_val, y_val)],\n",
        "          early_stopping_rounds=10,\n",
        "          verbose=False\n",
        "      )\n",
        "\n",
        "\n",
        "      from sklearn.metrics import classification_report\n",
        "      y_pred = model.predict(X_val)\n",
        "      report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "      model.validation_score = {\n",
        "          \"accuracy\": report.get(\"accuracy\"),\n",
        "          \"precision\": report.get(\"1\", {}).get(\"precision\"),\n",
        "          \"recall\": report.get(\"1\", {}).get(\"recall\"),\n",
        "          \"f1\": report.get(\"1\", {}).get(\"f1-score\")\n",
        "      }\n",
        "\n",
        "      if asset and interval:\n",
        "          save_xgb_model(model, asset, interval)\n",
        "\n",
        "      return model\n",
        "\n",
        "\n",
        "def predict_with_lstm(model, df, asset=\"N/A\", interval=\"N/A\"):\n",
        "    \"\"\"\n",
        "    Faz a previsão com LSTM usando o último window de dados.\n",
        "    Inclui validações para evitar valores irreais e registra previsões descartadas.\n",
        "    \"\"\"\n",
        "\n",
        "    if not all(hasattr(model, attr) for attr in ['scaler_x', 'scaler_y', 'feature_cols', 'window_size']):\n",
        "        raise AttributeError(\"O modelo LSTM não possui os atributos necessários (scaler_x, scaler_y, feature_cols, window_size).\")\n",
        "\n",
        "    df = df.copy().dropna(subset=model.feature_cols)\n",
        "    if len(df) < model.window_size:\n",
        "        raise ValueError(\"Dados insuficientes para previsão com LSTM.\")\n",
        "\n",
        "    last_window = df[model.feature_cols].values[-model.window_size:]\n",
        "    scaled_window = model.scaler_x.transform(last_window)\n",
        "    X_input = np.expand_dims(scaled_window, axis=0)\n",
        "\n",
        "    pred_scaled = model.predict(X_input, verbose=0)[0].reshape(1, -1)\n",
        "    pred_descaled = model.scaler_y.inverse_transform(pred_scaled)[0]\n",
        "\n",
        "    high, low, close = float(pred_descaled[0]), float(pred_descaled[1]), float(pred_descaled[2])\n",
        "\n",
        "    # 🔒 Correção 1: High deve ser maior ou igual ao Low\n",
        "    if low > high:\n",
        "        print(f\"⚠️ Corrigindo inversão de High/Low na previsão LSTM. High={high:.2f}, Low={low:.2f}\")\n",
        "        high, low = max(high, low), min(high, low)\n",
        "\n",
        "    # 🔒 Correção 2: Close deve ficar entre Low e High\n",
        "    if close < low or close > high:\n",
        "        print(f\"⚠️ Ajustando Close fora da faixa. Antes: {close:.2f}\")\n",
        "        close = max(min(close, high), low)\n",
        "        print(f\"✅ Close ajustado para: {close:.2f}\")\n",
        "\n",
        "    # 🔒 Validação 3: Verifica se o Close projetado é plausível (não explodiu)\n",
        "    preco_atual = df[\"Close\"].iloc[-1]\n",
        "    if preco_atual > 0:\n",
        "        variacao_permitida = 0.5  # 50%\n",
        "        if abs(close - preco_atual) / preco_atual > variacao_permitida:\n",
        "            print(f\"❌ Previsão absurda detectada. Atual={preco_atual:.2f} Previsto={close:.2f}\")\n",
        "            log_previsao_absurda(asset=asset, interval=interval, preco_atual=preco_atual, close_previsto=close)\n",
        "            return {\"High\": None, \"Low\": None, \"Close\": None}\n",
        "\n",
        "    return {\n",
        "        \"High\": round(high, 4),\n",
        "        \"Low\": round(low, 4),\n",
        "        \"Close\": round(close, 4)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def plot_feature_importance(model, feature_names, top_n=15):\n",
        "      import matplotlib.pyplot as plt\n",
        "      importances = model.feature_importances_\n",
        "      indices = np.argsort(importances)[-top_n:]  # top_n mais importantes\n",
        "\n",
        "      plt.figure(figsize=(10, 5))\n",
        "      plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "      plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "      plt.xlabel(\"Importância\")\n",
        "      plt.title(\"🎯 Importância das Features - XGBoost\")\n",
        "      plt.tight_layout()\n",
        "      plt.grid(True)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 5. UTILITÁRIOS\n",
        "  # ====================================================\n",
        "  # ====================================================\n",
        "  # FUNÇÃO GLOBAL DE CONVERSÃO ESCALAR\n",
        "  # ====================================================\n",
        "  def to_scalar(val):\n",
        "      try:\n",
        "          if isinstance(val, pd.Series):\n",
        "              return float(val.iloc[0])\n",
        "          elif isinstance(val, (np.ndarray, list)):\n",
        "              return float(val[0])\n",
        "          elif pd.isna(val):\n",
        "              return np.nan\n",
        "          else:\n",
        "              return float(val)\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Falha ao converter valor escalar: {val} | erro: {e}\")\n",
        "          return np.nan\n",
        "\n",
        "  import os\n",
        "  import glob\n",
        "\n",
        "  def limpar_model_results():\n",
        "      arquivos = glob.glob(\"/content/model_results_*.csv\")\n",
        "      if not arquivos:\n",
        "          print(\"📂 Nenhum arquivo model_results_*.csv encontrado.\")\n",
        "          return\n",
        "\n",
        "  def plot_entrada_lstm(df, feature_cols):\n",
        "      import matplotlib.pyplot as plt\n",
        "      df_plot = df[feature_cols].tail(100).copy()\n",
        "      df_plot.plot(figsize=(12, 5), title=\"📊 Últimas 100 entradas das features LSTM\")\n",
        "      plt.grid(True)\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  def gerar_resumo_ultimos_sinais(asset, interval, n=15, path=\"/content/prediction_log.csv\"):\n",
        "      df_log = safe_read_csv(path)\n",
        "      if df_log is None or df_log.empty:\n",
        "          return \"📭 Sem sinais anteriores registrados.\"\n",
        "\n",
        "      df_log = df_log[(df_log[\"Asset\"] == asset) & (df_log[\"Timeframe\"] == interval)].copy()\n",
        "      df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "      df_log = df_log.sort_values(\"Date\", ascending=False).head(n)\n",
        "\n",
        "      linhas = []\n",
        "      for _, row in df_log.iterrows():\n",
        "          data_str = row[\"Date\"].strftime(\"%d/%m %H:%M\")\n",
        "          sinal = \"COMPRA\" if row[\"Signal\"] == 1 else \"VENDA\" if row[\"Signal\"] == 0 else \"NEUTRO\"\n",
        "          emoji = \"✔️\" if row.get(\"Resultado\") == \"TP1\" else \"❌\" if row.get(\"Resultado\") == \"SL\" else \"➖\"\n",
        "          lucro = row.get(\"LucroEstimado\", \"\")\n",
        "          lucro_str = f\" | Lucro: {lucro:+.2f}\" if pd.notna(lucro) else \"\"\n",
        "          linhas.append(f\"{emoji} {sinal} | {row['Asset']} | {data_str}{lucro_str}\")\n",
        "\n",
        "      # Acurácia dos últimos sinais (apenas TP1 e SL considerados)\n",
        "      df_valid = df_log[df_log[\"Resultado\"].isin([\"TP1\", \"SL\"])]\n",
        "      if not df_valid.empty:\n",
        "          acertos = (df_valid[\"Resultado\"] == \"TP1\").sum()\n",
        "          total = len(df_valid)\n",
        "          acuracia = round(100 * acertos / total, 2)\n",
        "          linhas.append(f\"\\n📈 <b>Acurácia:</b> {acuracia}% ({acertos}/{total})\")\n",
        "\n",
        "      return \"📊 <b>Últimos Sinais:</b>\\n\" + \"\\n\".join(linhas)\n",
        "\n",
        "\n",
        "  def gerar_ranking_lucro(path=\"/content/prediction_log.csv\", top_n=5):\n",
        "      df = safe_read_csv(path)\n",
        "      if df is None or df.empty or \"LucroEstimado\" not in df.columns:\n",
        "          return \"📭 Sem dados de lucro disponíveis.\"\n",
        "\n",
        "      df = df.dropna(subset=[\"Asset\", \"LucroEstimado\"])\n",
        "      df = df[df[\"Resultado\"].isin([\"TP1\", \"SL\", \"Sem alvo\"])]\n",
        "      df_grouped = df.groupby(\"Asset\")[\"LucroEstimado\"].sum().sort_values(ascending=False).head(top_n)\n",
        "\n",
        "      linhas = [\"🏆 <b>Top Ativos por Lucro Total:</b>\"]\n",
        "      for ativo, lucro in df_grouped.items():\n",
        "          emoji = \"🟢\" if lucro > 0 else \"🔴\" if lucro < 0 else \"⚪\"\n",
        "          linhas.append(f\"{emoji} {ativo}: ${lucro:+.2f}\")\n",
        "      return \"\\n\".join(linhas)\n",
        "\n",
        "  def gerar_resumo_por_padrao(asset, interval, path=\"/content/prediction_log.csv\"):\n",
        "      df = safe_read_csv(path)\n",
        "      if df is None or df.empty:\n",
        "          return \"📭 Sem sinais anteriores registrados.\"\n",
        "\n",
        "      df = df[(df[\"Asset\"] == asset) & (df[\"Timeframe\"] == interval)]\n",
        "      subset_cols = [\"Doji\", \"Engulfing\", \"Hammer\"]\n",
        "      subset_cols = [col for col in subset_cols if col in df.columns]\n",
        "      if subset_cols:\n",
        "          df = df.dropna(subset=subset_cols)\n",
        "\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "\n",
        "      ultimos = df.sort_values(\"Date\", ascending=False).head(50)\n",
        "\n",
        "      contagem = {\n",
        "          \"Doji\": ultimos[\"Doji\"].sum() if \"Doji\" in ultimos.columns else 0,\n",
        "          \"Engolfo\": ultimos[\"Engulfing\"].sum() if \"Engulfing\" in ultimos.columns else 0,\n",
        "          \"Martelo\": ultimos[\"Hammer\"].sum() if \"Hammer\" in ultimos.columns else 0\n",
        "      }\n",
        "\n",
        "\n",
        "      linhas = [\"🔎 <b>Padrões Recentes Detectados:</b>\"]\n",
        "      for nome, qtd in contagem.items():\n",
        "          if qtd > 0:\n",
        "              linhas.append(f\"• {nome}: {int(qtd)} ocorrência(s)\")\n",
        "      return \"\\n\".join(linhas) if len(linhas) > 1 else \"⚪ Nenhum padrão técnico detectado recentemente.\"\n",
        "\n",
        "  def generate_explanation(row, prediction, feature_importance=None):\n",
        "      \"\"\"\n",
        "      Gera explicação técnica com base em indicadores e no sinal previsto (compra/venda).\n",
        "      \"\"\"\n",
        "      try:\n",
        "          explicacao = []\n",
        "\n",
        "          if prediction == 1:\n",
        "              explicacao.append(\"🟢 O modelo prevê uma tendência de ALTA (compra).\")\n",
        "          elif prediction == 0:\n",
        "              explicacao.append(\"🔴 O modelo prevê uma tendência de BAIXA (venda).\")\n",
        "          else:\n",
        "              explicacao.append(\"⚪ Tendência neutra — sem sinal claro.\")\n",
        "\n",
        "          # Indicadores clássicos\n",
        "          if \"RSI\" in row:\n",
        "              if row[\"RSI\"] < 30:\n",
        "                  explicacao.append(\"• RSI indica sobrevenda (RSI < 30).\")\n",
        "              elif row[\"RSI\"] > 70:\n",
        "                  explicacao.append(\"• RSI indica sobrecompra (RSI > 70).\")\n",
        "\n",
        "          if \"MACD\" in row and \"MACD_Signal\" in row:\n",
        "              if row[\"MACD\"] > row[\"MACD_Signal\"]:\n",
        "                  explicacao.append(\"• MACD cruzando para cima da linha de sinal (potencial alta).\")\n",
        "              else:\n",
        "                  explicacao.append(\"• MACD abaixo da linha de sinal (potencial queda).\")\n",
        "\n",
        "          if \"SMA_50\" in row and \"SMA_200\" in row:\n",
        "              if row[\"SMA_50\"] > row[\"SMA_200\"]:\n",
        "                  explicacao.append(\"• SMA 50 acima da 200 (tendência de alta no médio prazo).\")\n",
        "              else:\n",
        "                  explicacao.append(\"• SMA 50 abaixo da 200 (tendência de baixa no médio prazo).\")\n",
        "\n",
        "          if \"ADX\" in row and row[\"ADX\"] > 20:\n",
        "              explicacao.append(\"• ADX > 20 (tendência direcional presente).\")\n",
        "\n",
        "          # Padrões de candle\n",
        "          if row.get(\"Doji\") == 1:\n",
        "              explicacao.append(\"• Padrão Doji detectado (possível reversão).\")\n",
        "          if row.get(\"Engulfing\") == 1:\n",
        "              explicacao.append(\"• Padrão de engolfo detectado (reversão possível).\")\n",
        "          if row.get(\"Hammer\") == 1:\n",
        "              explicacao.append(\"• Padrão de martelo identificado (alta possível).\")\n",
        "\n",
        "          # Importância de features (se disponível)\n",
        "          if feature_importance:\n",
        "              explicacao.append(\"\\n📊 Principais influências do modelo:\")\n",
        "              top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "              for name, weight in top_features:\n",
        "                  explicacao.append(f\"• {name}: peso {weight:.3f}\")\n",
        "\n",
        "          return \"\\n\".join(explicacao)\n",
        "\n",
        "      except Exception as e:\n",
        "          return f\"⚠️ Erro ao gerar explicação: {str(e)}\"\n",
        "\n",
        "def enviar_grafico_previsao_futura(df_previsao, timeframe, asset):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import matplotlib.dates as mdates\n",
        "    import os\n",
        "    import pandas as pd\n",
        "\n",
        "    if df_previsao is None or not all(k in df_previsao for k in [\"Date\", \"High\", \"Low\", \"Close\"]):\n",
        "        print(f\"⚠️ Dados de previsão futura incompletos para {asset} ({timeframe})\")\n",
        "        return\n",
        "\n",
        "    df = pd.DataFrame(df_previsao)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df.set_index(\"Date\", inplace=False)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        date = df[\"Date\"].iloc[i]\n",
        "        high = df[\"High\"].iloc[i]\n",
        "        low = df[\"Low\"].iloc[i]\n",
        "        close = df[\"Close\"].iloc[i]\n",
        "\n",
        "        plt.vlines(date, ymin=low, ymax=high, color=\"blue\", linewidth=2, label=\"Projeção\" if i == 0 else \"\")\n",
        "        plt.plot(date, close, marker=\"o\", color=\"blue\")\n",
        "\n",
        "        # Rótulo com valor previsto\n",
        "        plt.annotate(f\"{close:.0f}\", (date, close), xytext=(0, 8),\n",
        "                     textcoords=\"offset points\", ha='center', fontsize=8, color=\"blue\")\n",
        "\n",
        "    plt.title(f\"🔮 Projeção Futura (LSTM) — {asset} ({timeframe})\")\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Preço Projetado\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d/%m %H:%M', tz=BR_TZ))\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    image_path = f\"/tmp/projecao_futura_{asset.replace('-', '')}_{timeframe}.png\"\n",
        "    plt.savefig(image_path)\n",
        "    plt.close()\n",
        "    print(f\"✅ Gráfico de projeção futura salvo: {image_path}\")\n",
        "\n",
        "    # Enviar para Telegram\n",
        "    if os.path.exists(image_path):\n",
        "        with open(image_path, \"rb\") as img:\n",
        "            url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "            files = {\"photo\": img}\n",
        "            data = {\n",
        "                \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                \"caption\": f\"🔮 Projeção Futura — {asset} ({timeframe})\"\n",
        "            }\n",
        "            response = requests.post(url, data=data, files=files)\n",
        "            if response.status_code == 200:\n",
        "                print(\"✅ Gráfico de projeção futura enviado ao Telegram.\")\n",
        "            else:\n",
        "                print(f\"❌ Erro ao enviar gráfico: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "def calculate_targets(price_row, signal, atr_multiplier=0.02):\n",
        "    \"\"\"\n",
        "    Calcula TP e SL com base em Low como entrada e High como alvo.\n",
        "    Usa atr_multiplier para margem no SL.\n",
        "    Retorna Entry, TP1, TP2, SL com validação contra valores inválidos.\n",
        "    \"\"\"\n",
        "    if signal == 1:  # Compra\n",
        "        entry = price_row.get(\"Low\", None)\n",
        "        tp1 = price_row.get(\"High\", None)\n",
        "        sl = entry - (entry * atr_multiplier) if entry is not None else None\n",
        "    elif signal == 0:  # Venda\n",
        "        entry = price_row.get(\"High\", None)\n",
        "        tp1 = price_row.get(\"Low\", None)\n",
        "        sl = entry + (entry * atr_multiplier) if entry is not None else None\n",
        "    else:\n",
        "        return {\"Entry\": None, \"TP1\": None, \"TP2\": None, \"SL\": None}\n",
        "\n",
        "    # Proteção contra valores ausentes ou inválidos\n",
        "    if any(v is None or np.isnan(v) for v in [entry, tp1, sl]):\n",
        "        print(\"⚠️ Targets inválidos detectados — retornando None.\")\n",
        "        return {\"Entry\": None, \"TP1\": None, \"TP2\": None, \"SL\": None}\n",
        "\n",
        "    # Cálculo de TP2 baseado na distância entre Entry e SL\n",
        "    distancia = abs(entry - sl)\n",
        "    tp2 = entry + 2 * distancia if signal == 1 else entry - 2 * distancia\n",
        "\n",
        "    return {\n",
        "        \"Entry\": round(entry, 4),\n",
        "        \"TP1\": round(tp1, 4),\n",
        "        \"TP2\": round(tp2, 4),\n",
        "        \"SL\": round(sl, 4)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "def log_previsao_absurda(asset, interval, preco_atual, close_previsto):\n",
        "    try:\n",
        "        path = \"/content/previsoes_descartadas.csv\"\n",
        "        row = {\n",
        "            \"Data\": datetime.now(BR_TZ).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            \"Asset\": asset,\n",
        "            \"Timeframe\": interval,\n",
        "            \"PrecoAtual\": preco_atual,\n",
        "            \"PrevistoClose\": close_previsto,\n",
        "            \"Variacao(%)\": round((close_previsto - preco_atual) / preco_atual * 100, 2)\n",
        "        }\n",
        "        df = pd.DataFrame([row])\n",
        "        if os.path.exists(path):\n",
        "            df.to_csv(path, mode=\"a\", header=False, index=False)\n",
        "        else:\n",
        "            df.to_csv(path, index=False)\n",
        "        print(f\"🧾 Previsão absurda registrada em: {path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Falha ao logar previsão absurda: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def send_telegram_message(message):\n",
        "      url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "      payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"HTML\"}\n",
        "      response = requests.post(url, json=payload)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "          print(\"📨 Mensagem enviada com sucesso!\")\n",
        "      else:\n",
        "          print(f\"❌ Erro ao enviar mensagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "  def predict_next_closes(data, n_steps=5):\n",
        "      df = data.copy().reset_index(drop=True)\n",
        "      features = get_feature_columns(df)\n",
        "      df.dropna(inplace=True)\n",
        "\n",
        "      X = df[features]\n",
        "      y = df[\"Close\"].shift(-1).dropna()\n",
        "      X = X.loc[y.index]\n",
        "\n",
        "      if len(X) < 100:\n",
        "          return [None] * n_steps\n",
        "\n",
        "      model = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42)\n",
        "      model.fit(X, y)\n",
        "\n",
        "      last_row = df[features].iloc[-1].copy()\n",
        "      preds = []\n",
        "\n",
        "      for step in range(n_steps):\n",
        "          X_input = pd.DataFrame([last_row], columns=features)\n",
        "          next_close = model.predict(X_input)[0]\n",
        "          preds.append(round(next_close, 2))\n",
        "\n",
        "          # Simula avanço do mercado\n",
        "          last_row[\"Close\"] = next_close\n",
        "          if \"SMA_50\" in last_row:\n",
        "              last_row[\"SMA_50\"] = last_row[\"SMA_50\"] * 0.9 + next_close * 0.1\n",
        "          if \"SMA_200\" in last_row:\n",
        "              last_row[\"SMA_200\"] = last_row[\"SMA_200\"] * 0.95 + next_close * 0.05\n",
        "          if \"VWAP\" in last_row:\n",
        "              last_row[\"VWAP\"] = last_row[\"VWAP\"] * 0.95 + next_close * 0.05\n",
        "          if \"RSI\" in last_row:\n",
        "              last_row[\"RSI\"] = min(100, max(0, last_row[\"RSI\"] + np.random.normal(0, 0.5)))\n",
        "          if \"MACD\" in last_row:\n",
        "              last_row[\"MACD\"] += np.random.normal(0, 0.3)\n",
        "          if \"MACD_Signal\" in last_row:\n",
        "              last_row[\"MACD_Signal\"] += np.random.normal(0, 0.2)\n",
        "\n",
        "          last_row = last_row[features]\n",
        "\n",
        "      return preds\n",
        "\n",
        "\n",
        "  def evaluate_past_predictions(results_file=\"/content/prediction_log.csv\", lookahead_candles=5):\n",
        "      import os\n",
        "      import pandas as pd\n",
        "      import yfinance as yf\n",
        "      import matplotlib.pyplot as plt\n",
        "      from datetime import timedelta\n",
        "\n",
        "      df = safe_read_csv(results_file)\n",
        "      if df is None or df.empty:\n",
        "          print(\"📭 Nenhum log de previsão encontrado ou o arquivo está vazio.\")\n",
        "          return\n",
        "\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "      print(f\"📊 Avaliando {len(df)} previsões salvas...\")\n",
        "\n",
        "      evaluation = []\n",
        "\n",
        "\n",
        "      for idx, row in df.iterrows():\n",
        "          asset = row[\"Asset\"]\n",
        "          interval = row[\"Timeframe\"]\n",
        "          prediction_time = row[\"Date\"]\n",
        "          predicted_signal = row[\"Signal\"]\n",
        "          predicted_target = row.get(\"TargetPrice\", None)\n",
        "\n",
        "          try:\n",
        "              candles = yf.download(asset, start=prediction_time, interval=interval, progress=False)\n",
        "              candles = candles[candles.index > prediction_time]\n",
        "\n",
        "              if candles.empty or len(candles) < lookahead_candles:\n",
        "                  continue\n",
        "\n",
        "              candles = candles.head(lookahead_candles)\n",
        "              final_close = candles[\"Close\"].iloc[-1]\n",
        "\n",
        "              if predicted_signal == 1:\n",
        "                  result = \"Acertou\" if final_close >= predicted_target else \"Errou\"\n",
        "              elif predicted_signal == 0:\n",
        "                  result = \"Acertou\" if final_close <= predicted_target else \"Errou\"\n",
        "              else:\n",
        "                  result = \"Neutro\"\n",
        "\n",
        "              if predicted_target:\n",
        "                  perc_change = ((final_close - predicted_target) / predicted_target) * 100\n",
        "                  abs_error = final_close - predicted_target\n",
        "              else:\n",
        "                  perc_change = None\n",
        "                  abs_error = None\n",
        "\n",
        "              acertou = 1 if result == \"Acertou\" else 0\n",
        "\n",
        "              evaluation.append({\n",
        "                  \"Ativo\": asset,\n",
        "                  \"Timeframe\": interval,\n",
        "                  \"Data Previsão\": prediction_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
        "                  \"Sinal Previsto\": \"Compra\" if predicted_signal == 1 else \"Venda\" if predicted_signal == 0 else \"Neutro\",\n",
        "                  \"Valor Projetado (LSTM)\": round(predicted_target, 2) if predicted_target else None,\n",
        "                  \"Resultado\": result,\n",
        "                  \"Valor Real\": round(final_close, 2),\n",
        "                  \"Variação Real\": f\"{perc_change:+.2f}%\" if perc_change is not None else \"N/A\",\n",
        "                  \"Erro Absoluto\": f\"{abs_error:+.2f}\" if abs_error is not None else \"N/A\",\n",
        "                  \"Acertou\": acertou\n",
        "              })\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"⚠️ Erro ao avaliar {asset} em {prediction_time}: {e}\")\n",
        "              continue\n",
        "\n",
        "      df_eval = pd.DataFrame(evaluation)\n",
        "\n",
        "      # 📊 Resumo de acertos e erros\n",
        "      resumo = df_eval.groupby([\"Ativo\", \"Timeframe\", \"Resultado\"]).size().unstack(fill_value=0)\n",
        "      resumo[\"Total\"] = resumo.sum(axis=1)\n",
        "      resumo[\"Acurácia (%)\"] = (resumo.get(\"Acertou\", 0) / resumo[\"Total\"] * 100).round(2)\n",
        "      display(resumo)\n",
        "\n",
        "      # 📈 Gráfico de barras\n",
        "      resumo_plot = resumo[[\"Acertou\", \"Errou\"]] if \"Errou\" in resumo.columns else resumo[[\"Acertou\"]]\n",
        "      resumo_plot.plot(kind=\"bar\", figsize=(10, 5), title=\"📊 Acertos vs Erros por Ativo e Timeframe\")\n",
        "      plt.ylabel(\"Quantidade de Sinais\")\n",
        "      plt.xticks(rotation=45)\n",
        "      plt.grid(axis=\"y\")\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "      # 📄 Tabela completa das previsões\n",
        "      display(df_eval)\n",
        "\n",
        "      # 🔄 Atualizar o prediction_log.csv com a coluna 'Acertou'\n",
        "      try:\n",
        "          df_log = safe_read_csv(results_file)\n",
        "          df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "\n",
        "\n",
        "          for _, row in df_eval.iterrows():\n",
        "              dt = pd.to_datetime(row[\"Data Previsão\"])\n",
        "              mask = (df_log[\"Date\"] == dt) & (df_log[\"Asset\"] == row[\"Ativo\"]) & (df_log[\"Timeframe\"] == row[\"Timeframe\"])\n",
        "              df_log.loc[mask, \"Acertou\"] = row[\"Acertou\"]\n",
        "\n",
        "          df_log.to_csv(results_file, index=False)\n",
        "          print(\"✅ Log de previsões atualizado com coluna 'Acertou'.\")\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Erro ao atualizar o prediction_log.csv com 'Acertou': {e}\")\n",
        "\n",
        "      return df_eval\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def clear_models(model_dir=\"/content/models\"):\n",
        "      import shutil\n",
        "\n",
        "      if os.path.exists(model_dir):\n",
        "          print(f\"🧹 Limpando todos os modelos salvos em: {model_dir}\")\n",
        "          shutil.rmtree(model_dir)\n",
        "          os.makedirs(model_dir, exist_ok=True)\n",
        "          print(\"✅ Modelos deletados com sucesso.\")\n",
        "      else:\n",
        "          print(\"📂 Nenhuma pasta de modelos encontrada para limpar.\")\n",
        "\n",
        "\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  import os\n",
        "\n",
        "  def plot_prediction_performance_por_timeframe(log_path=\"/content/prediction_log.csv\"):\n",
        "      if not os.path.exists(log_path):\n",
        "          print(\"📭 Nenhum log encontrado.\")\n",
        "          return\n",
        "\n",
        "      df = pd.read_csv(log_path)\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "      df = df.dropna(subset=[\"TargetPrice\", \"Price\", \"Timeframe\"])\n",
        "\n",
        "      for timeframe in df[\"Timeframe\"].unique():\n",
        "          df_tf = df[df[\"Timeframe\"] == timeframe].copy()\n",
        "          df_tf[\"Erro\"] = df_tf[\"Price\"] - df_tf[\"TargetPrice\"]\n",
        "          df_tf[\"AbsError\"] = abs(df_tf[\"Erro\"])\n",
        "          df_tf[\"Dia\"] = df_tf[\"Date\"].dt.date\n",
        "\n",
        "          if df_tf.empty:\n",
        "              continue\n",
        "\n",
        "          # Erro absoluto médio por dia\n",
        "          plt.figure(figsize=(8, 4))\n",
        "          df_grouped = df_tf.groupby(\"Dia\")[\"AbsError\"].mean()\n",
        "          plt.plot(df_grouped.index, df_grouped.values, marker=\"o\")\n",
        "          plt.title(f\"📈 Erro Absoluto Médio por Dia - {timeframe}\")\n",
        "          plt.xlabel(\"Data\")\n",
        "          plt.ylabel(\"Erro ($)\")\n",
        "          plt.grid(True)\n",
        "          plt.tight_layout()\n",
        "          plt.savefig(f\"/tmp/erro_absoluto_{timeframe}.png\")\n",
        "          plt.close()\n",
        "\n",
        "          # Dispersão do valor previsto x real\n",
        "          plt.figure(figsize=(8, 4))\n",
        "          plt.scatter(df_tf[\"TargetPrice\"], df_tf[\"Price\"], alpha=0.6)\n",
        "          plt.plot([df_tf[\"TargetPrice\"].min(), df_tf[\"TargetPrice\"].max()],\n",
        "                  [df_tf[\"TargetPrice\"].min(), df_tf[\"TargetPrice\"].max()], 'r--', label=\"Perfeito\")\n",
        "          plt.title(f\"🎯 Previsão LSTM vs Preço Real - {timeframe}\")\n",
        "          plt.xlabel(\"Valor Previsto\")\n",
        "          plt.ylabel(\"Valor Real\")\n",
        "          plt.legend()\n",
        "          plt.grid(True)\n",
        "          plt.tight_layout()\n",
        "          path_img = f\"/tmp/previsao_vs_real_{timeframe}.png\"\n",
        "          plt.savefig(path_img)\n",
        "          plt.close()\n",
        "          print(f\"✅ Gráfico salvo: {path_img}\")\n",
        "\n",
        "  def enviar_graficos_desempenho_por_timeframe():\n",
        "      import glob\n",
        "      from pathlib import Path\n",
        "\n",
        "      timeframes = [\"15m\", \"1h\", \"1d\"]  # Edite se tiver outros\n",
        "      path_base = \"/tmp\"\n",
        "\n",
        "      for tf in timeframes:\n",
        "          # Gráfico 1: Previsão vs Real\n",
        "          grafico_pred = f\"{path_base}/previsao_vs_real_{tf}.png\"\n",
        "          if os.path.exists(grafico_pred):\n",
        "              with open(grafico_pred, \"rb\") as img:\n",
        "                  url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                  files = {\"photo\": img}\n",
        "                  data = {\n",
        "                      \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                      \"caption\": f\"📈 Previsão LSTM vs Real — {tf}\"\n",
        "                  }\n",
        "                  r = requests.post(url, data=data, files=files)\n",
        "                  print(f\"✅ Enviado: previsao_vs_real_{tf}.png\")\n",
        "\n",
        "          # Gráfico 2: Erro absoluto por dia\n",
        "          grafico_erro = f\"{path_base}/erro_absoluto_{tf}.png\"\n",
        "          if os.path.exists(grafico_erro):\n",
        "              with open(grafico_erro, \"rb\") as img:\n",
        "                  url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                  files = {\"photo\": img}\n",
        "                  data = {\n",
        "                      \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                      \"caption\": f\"📊 Erro Absoluto por Dia — {tf}\"\n",
        "                  }\n",
        "                  r = requests.post(url, data=data, files=files)\n",
        "                  print(f\"✅ Enviado: erro_absoluto_{tf}.png\")\n",
        "\n",
        "  def enviar_grafico_lucro_por_confianca(log_path=\"/content/prediction_log.csv\"):\n",
        "      import matplotlib.pyplot as plt\n",
        "\n",
        "      if not os.path.exists(log_path):\n",
        "          print(\"📭 Nenhum log encontrado.\")\n",
        "          return\n",
        "\n",
        "      df = safe_read_csv(log_path)\n",
        "      if \"AdjustedProb\" not in df.columns or \"TP1\" not in df.columns or \"Price\" not in df.columns:\n",
        "          print(\"⚠️ Colunas necessárias não encontradas no log.\")\n",
        "          return\n",
        "\n",
        "      df = df.dropna(subset=[\"AdjustedProb\", \"TP1\", \"Price\"])\n",
        "      df[\"LucroEstimado\"] = df[\"TP1\"] - df[\"Price\"]\n",
        "      df[\"FaixaConfiança\"] = pd.cut(df[\"AdjustedProb\"], bins=[0, 0.6, 0.7, 0.8, 0.9, 1.0], labels=[\"≤60%\", \"60-70%\", \"70-80%\", \"80-90%\", \">90%\"])\n",
        "\n",
        "      lucro_medio = df.groupby(\"FaixaConfiança\")[\"LucroEstimado\"].mean()\n",
        "\n",
        "      plt.figure(figsize=(8, 4))\n",
        "      lucro_medio.plot(kind=\"bar\", color=\"skyblue\")\n",
        "      plt.title(\"📊 Lucro Estimado Médio por Faixa de Confiança\")\n",
        "      plt.ylabel(\"Lucro Estimado ($)\")\n",
        "      plt.xlabel(\"Faixa de Confiança Ajustada\")\n",
        "      plt.grid(True)\n",
        "      plt.tight_layout()\n",
        "\n",
        "      path = \"/tmp/lucro_por_confianca.png\"\n",
        "      plt.savefig(path)\n",
        "      plt.close()\n",
        "\n",
        "      with open(path, \"rb\") as img:\n",
        "          url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "          files = {\"photo\": img}\n",
        "          data = {\n",
        "              \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "              \"caption\": \"📊 Lucro médio estimado por faixa de confiança ajustada\"\n",
        "          }\n",
        "          response = requests.post(url, data=data, files=files)\n",
        "          if response.status_code == 200:\n",
        "              print(\"✅ Gráfico de lucro por confiança enviado.\")\n",
        "          else:\n",
        "              print(f\"❌ Falha ao enviar gráfico: {response.status_code} - {response.text}\")\n",
        "\n",
        "  def adjust_signal_based_on_history(asset, timeframe, max_lookback=20, min_signals=5):\n",
        "      try:\n",
        "          df = safe_read_csv(\"prediction_log.csv\")\n",
        "          if df is None:\n",
        "              print(\"⚠️ Ignorando leitura do prediction_log.csv pois está vazio ou ausente.\")\n",
        "              return 1.0  # Retorna confiança padrão\n",
        "\n",
        "          df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "\n",
        "          df = df[(df[\"Asset\"] == asset) & (df[\"Timeframe\"] == timeframe)]\n",
        "\n",
        "          if len(df) < min_signals or \"Acertou\" not in df.columns:\n",
        "              return 1.0\n",
        "\n",
        "          recent = df.sort_values(\"Date\", ascending=False).head(max_lookback)\n",
        "          acuracia = recent[\"Acertou\"].mean()\n",
        "          return acuracia\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ Erro ao ajustar com histórico: {e}\")\n",
        "          return 1.0\n",
        "\n",
        "  def gerar_grafico_previsao_vs_real(log_path=\"/content/prediction_log.csv\", output_path=\"/tmp/previsao_vs_real.png\"):\n",
        "      import matplotlib.pyplot as plt\n",
        "\n",
        "      df = safe_read_csv(log_path)\n",
        "      if df is None or df.empty or \"TargetPrice\" not in df.columns or \"Price\" not in df.columns:\n",
        "          print(\"⚠️ Log inválido ou colunas ausentes.\")\n",
        "          return None\n",
        "\n",
        "      df = df.dropna(subset=[\"TargetPrice\", \"Price\"]).tail(20)  # últimos 20 sinais\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "      plt.figure(figsize=(10, 4))\n",
        "      plt.plot(df[\"Date\"], df[\"Price\"], label=\"📈 Preço Real\", marker=\"o\")\n",
        "      plt.plot(df[\"Date\"], df[\"TargetPrice\"], label=\"🔮 Previsão LSTM\", marker=\"x\")\n",
        "      plt.title(\"📊 Previsão LSTM vs Preço Real\")\n",
        "      plt.xlabel(\"Data\")\n",
        "      plt.ylabel(\"Preço\")\n",
        "      plt.grid(True)\n",
        "      plt.legend()\n",
        "      plt.tight_layout()\n",
        "      plt.savefig(output_path)\n",
        "      plt.close()\n",
        "      print(f\"✅ Gráfico salvo em: {output_path}\")\n",
        "      return output_path\n",
        "\n",
        "  def enviar_grafico_previsao_real(df, timeframe, asset):\n",
        "      import matplotlib.pyplot as plt\n",
        "      import matplotlib.dates as mdates\n",
        "      import os\n",
        "\n",
        "      df = df[df[\"Asset\"] == asset].copy()\n",
        "      if df.empty:\n",
        "          print(f\"⚠️ Nenhum dado para {asset} ({timeframe}) no gráfico.\")\n",
        "          return\n",
        "\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "\n",
        "      plt.figure(figsize=(12, 5))\n",
        "\n",
        "      for i in range(len(df)):\n",
        "          date = df[\"Date\"].iloc[i]\n",
        "          high = df[\"LSTM_High_Predicted\"].iloc[i]\n",
        "          low = df[\"LSTM_Low_Predicted\"].iloc[i]\n",
        "          close = df[\"TargetPrice\"].iloc[i]\n",
        "          real = df[\"Price\"].iloc[i]\n",
        "\n",
        "          cor = \"green\" if close >= real else \"red\"\n",
        "          plt.vlines(date, ymin=low, ymax=high, color=cor, linewidth=2)\n",
        "          plt.plot(date, close, marker=\"o\", color=cor)\n",
        "\n",
        "          # Rótulos numéricos\n",
        "          plt.annotate(f\"{close:.0f}\", (date, close), xytext=(0, 8),\n",
        "                      textcoords=\"offset points\", ha='center', fontsize=8, color=cor)\n",
        "          plt.annotate(f\"{real:.0f}\", (date, real), xytext=(0, -12),\n",
        "                      textcoords=\"offset points\", ha='center', fontsize=8, color=\"black\")\n",
        "\n",
        "      # Linha contínua do preço real\n",
        "      plt.plot(df[\"Date\"], df[\"Price\"], label=\"📈 Preço Real\", marker=\"x\", color=\"black\")\n",
        "\n",
        "      plt.title(f\"📊 Projeção LSTM (High/Low/Close) — {asset} ({timeframe})\")\n",
        "      plt.xlabel(\"Data\")\n",
        "      plt.ylabel(\"Preço\")\n",
        "      plt.grid(True)\n",
        "      plt.legend()\n",
        "      plt.tight_layout()\n",
        "      plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d/%m %H:%M', tz=BR_TZ))\n",
        "      plt.xticks(rotation=45)\n",
        "\n",
        "      image_path = f\"/tmp/previsao_vs_real_{asset.replace('-', '')}_{timeframe}.png\"\n",
        "      plt.savefig(image_path)\n",
        "      plt.close()\n",
        "\n",
        "      # Enviar para Telegram\n",
        "      if os.path.exists(image_path):\n",
        "          with open(image_path, \"rb\") as img:\n",
        "              url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "              files = {\"photo\": img}\n",
        "              data = {\n",
        "                  \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                  \"caption\": f\"📊 Projeção LSTM (High/Low/Close) — {asset} ({timeframe})\"\n",
        "              }\n",
        "              response = requests.post(url, data=data, files=files)\n",
        "              if response.status_code == 200:\n",
        "                  print(\"✅ Gráfico de candle com rótulos enviado ao Telegram.\")\n",
        "              else:\n",
        "                  print(f\"❌ Erro ao enviar gráfico: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def enviar_grafico_carteira():\n",
        "      image_path = \"/tmp/evolucao_carteira.png\"\n",
        "      if os.path.exists(image_path):\n",
        "          with open(image_path, \"rb\") as img:\n",
        "              url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "              files = {\"photo\": img}\n",
        "              data = {\n",
        "                  \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                  \"caption\": \"💼 Evolução da carteira virtual com base nos sinais do bot\"\n",
        "              }\n",
        "              response = requests.post(url, data=data, files=files)\n",
        "              if response.status_code == 200:\n",
        "                  print(\"✅ Gráfico da carteira enviado ao Telegram.\")\n",
        "              else:\n",
        "                  print(f\"❌ Erro ao enviar imagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "  # 📊 Cálculo automático do atr_multiplier baseado nos últimos candles\n",
        "  def calcular_atr_auto(dataframe, intervalo=\"15m\", n=50, fator_ajuste=1.2):\n",
        "      try:\n",
        "          df_recent = dataframe.tail(n)\n",
        "          if df_recent.empty or not all(col in df_recent.columns for col in [\"High\", \"Low\", \"Close\"]):\n",
        "              return 0.03  # valor padrão caso não tenha dados\n",
        "\n",
        "          # Cálculo da média da variação percentual entre High e Low\n",
        "          media_range_pct = ((df_recent[\"High\"] - df_recent[\"Low\"]) / df_recent[\"Close\"]).mean()\n",
        "          atr_multiplier = round(media_range_pct * fator_ajuste, 4)\n",
        "\n",
        "          # Valor mínimo e máximo para manter limites razoáveis\n",
        "          atr_multiplier = max(0.01, min(atr_multiplier, 0.08))\n",
        "          return atr_multiplier\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"⚠️ Erro no ajuste automático do ATR: {e}\")\n",
        "          return 0.03  # fallback padrão\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 5.1 CARTEIRA VIRTUAL PARA SIMULAÇÃO\n",
        "  # ====================================================\n",
        "  # ====================================================\n",
        "  # 5.1 CARTEIRA VIRTUAL PARA SIMULAÇÃO\n",
        "  # ====================================================\n",
        "\n",
        "  carteira_virtual = {\n",
        "      \"capital_inicial\": 10000.0,\n",
        "      \"capital_atual\": 10000.0,\n",
        "      \"capital_maximo\": 10000.0,  # para cálculo de drawdown\n",
        "      \"historico_capital\": [],    # track evolução do capital\n",
        "      \"em_operacao\": False,\n",
        "  }\n",
        "\n",
        "\n",
        "  def to_scalar(val):\n",
        "      try:\n",
        "          if isinstance(val, pd.Series):\n",
        "              return float(val.iloc[0])\n",
        "          elif isinstance(val, (np.ndarray, list)):\n",
        "              return float(val[0])\n",
        "          elif val is None:\n",
        "              return np.nan\n",
        "          else:\n",
        "              return float(val)\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Falha ao converter valor escalar: {val} | erro: {e}\")\n",
        "          return np.nan\n",
        "\n",
        "\n",
        "  def salvar_carteira_virtual(filepath=\"/content/carteira_virtual.json\"):\n",
        "      with open(filepath, \"w\") as f:\n",
        "          json.dump(carteira_virtual, f)\n",
        "      print(f\"💾 Carteira virtual salva em: {filepath}\")\n",
        "\n",
        "\n",
        "  def carregar_carteira_virtual(filepath=\"/content/carteira_virtual.json\"):\n",
        "      global carteira_virtual\n",
        "      if os.path.exists(filepath):\n",
        "          with open(filepath, \"r\") as f:\n",
        "              carteira_virtual = json.load(f)\n",
        "          print(f\"📂 Carteira virtual carregada de: {filepath}\")\n",
        "      else:\n",
        "          print(f\"⚠️ Arquivo de carteira não encontrado. Usando valores padrões.\")\n",
        "\n",
        "\n",
        "  def simular_trade(row, df):\n",
        "      try:\n",
        "          asset = row[\"Asset\"]\n",
        "          timeframe = row[\"Timeframe\"]\n",
        "          signal_time = pd.to_datetime(row[\"Date\"], utc=True).astimezone(BR_TZ)\n",
        "\n",
        "          preco_entrada = float(row[\"Price\"])\n",
        "          tp1 = float(row[\"TP1\"])\n",
        "          sl = float(row[\"SL\"])\n",
        "\n",
        "          if df.index.tz is None:\n",
        "              df.index = df.index.tz_localize(pytz.UTC).tz_convert(BR_TZ)\n",
        "          else:\n",
        "              df.index = df.index.tz_convert(BR_TZ)\n",
        "\n",
        "          df_future = df[df.index > signal_time]\n",
        "          if df_future.empty or not all(col in df_future.columns for col in [\"High\", \"Low\", \"Close\"]):\n",
        "              raise ValueError(\"Candles futuros indisponíveis ou incompletos.\")\n",
        "\n",
        "          for i, (idx, candle) in enumerate(df_future.iterrows()):\n",
        "              preco_max = float(candle[\"High\"])\n",
        "              preco_min = float(candle[\"Low\"])\n",
        "\n",
        "              if row[\"Signal\"] == 1:\n",
        "                  if preco_min <= sl:\n",
        "                      resultado = \"SL\"\n",
        "                      preco_saida = sl\n",
        "                      break\n",
        "                  elif preco_max >= tp1:\n",
        "                      resultado = \"TP1\"\n",
        "                      preco_saida = tp1\n",
        "                      break\n",
        "              elif row[\"Signal\"] == 0:\n",
        "                  if preco_max >= sl:\n",
        "                      resultado = \"SL\"\n",
        "                      preco_saida = sl\n",
        "                      break\n",
        "                  elif preco_min <= tp1:\n",
        "                      resultado = \"TP1\"\n",
        "                      preco_saida = tp1\n",
        "                      break\n",
        "              else:\n",
        "                  resultado = \"Neutro\"\n",
        "                  preco_saida = df_future[\"Close\"].iloc[-1]\n",
        "                  break\n",
        "          else:\n",
        "              resultado = \"Sem alvo\"\n",
        "              preco_saida = df_future[\"Close\"].iloc[-1]\n",
        "\n",
        "          # 🎯 Cálculo dinâmico de posição baseado no risco (stop loss)\n",
        "          capital_disponivel = carteira_virtual[\"capital_atual\"]\n",
        "          risco_por_trade = 0.01  # 1% de risco da carteira por operação\n",
        "\n",
        "          # Distância até o stop em dólares\n",
        "          if row[\"Signal\"] == 1:\n",
        "              risco_trade = preco_entrada - sl\n",
        "          elif row[\"Signal\"] == 0:\n",
        "              risco_trade = sl - preco_entrada\n",
        "          else:\n",
        "              risco_trade = 0\n",
        "\n",
        "          if risco_trade <= 0:\n",
        "              print(f\"⚠️ Risco inválido calculado para {asset} ({timeframe}). Usando posição mínima.\")\n",
        "              capital_por_trade = capital_disponivel * 0.01  # fallback: 1%\n",
        "          else:\n",
        "              capital_por_trade = (capital_disponivel * risco_por_trade) / risco_trade\n",
        "\n",
        "          # Cálculo final da posição\n",
        "          quantidade = capital_por_trade\n",
        "          if quantidade * preco_entrada > capital_disponivel * 0.10:\n",
        "              quantidade = (capital_disponivel * 0.10) / preco_entrada  # limite de 10% do capital em trade\n",
        "\n",
        "          quantidade = max(quantidade, 0.0001)  # posição mínima para evitar 0\n",
        "\n",
        "          lucro_total = (preco_saida - preco_entrada) * quantidade if row[\"Signal\"] == 1 else (preco_entrada - preco_saida) * quantidade\n",
        "          carteira_virtual[\"capital_atual\"] += lucro_total\n",
        "          carteira_virtual[\"historico_capital\"].append(carteira_virtual[\"capital_atual\"])\n",
        "\n",
        "          if carteira_virtual[\"capital_atual\"] > carteira_virtual[\"capital_maximo\"]:\n",
        "              carteira_virtual[\"capital_maximo\"] = carteira_virtual[\"capital_atual\"]\n",
        "\n",
        "          drawdown = 1 - (carteira_virtual[\"capital_atual\"] / carteira_virtual[\"capital_maximo\"])\n",
        "          roi = (carteira_virtual[\"capital_atual\"] / carteira_virtual[\"capital_inicial\"]) - 1\n",
        "          duracao = (idx - signal_time).total_seconds() / 60\n",
        "\n",
        "          return {\n",
        "              \"Resultado\": resultado,\n",
        "              \"PrecoSaida\": preco_saida,\n",
        "              \"LucroEstimado\": round(lucro_total, 2),\n",
        "              \"DuracaoMin\": round(duracao, 1),\n",
        "              \"Capital Atual\": round(carteira_virtual[\"capital_atual\"], 2),\n",
        "              \"Quantidade\": round(quantidade, 6),\n",
        "              \"ROI\": round(roi * 100, 2),\n",
        "              \"Drawdown\": round(drawdown * 100, 2)\n",
        "          }\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"❌ Erro inesperado na simulação: {e}\")\n",
        "          return {\n",
        "              \"Resultado\": \"Erro\",\n",
        "              \"PrecoSaida\": None,\n",
        "              \"LucroEstimado\": None,\n",
        "              \"DuracaoMin\": None,\n",
        "              \"Capital Atual\": carteira_virtual[\"capital_atual\"],\n",
        "              \"Quantidade\": None,\n",
        "              \"ROI\": None,\n",
        "              \"Drawdown\": None\n",
        "          }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def plotar_grafico_lucro(df):\n",
        "      import matplotlib.pyplot as plt\n",
        "\n",
        "      df_valid = df[df[\"Resultado\"].isin([\"TP1\", \"SL\", \"Sem alvo\"])].copy()\n",
        "      if df_valid.empty:\n",
        "          print(\"⚠️ Nenhum resultado válido para gráfico.\")\n",
        "          return\n",
        "\n",
        "      df_valid[\"FaixaConfiança\"] = pd.cut(\n",
        "          df_valid[\"AdjustedProb\"].fillna(0.5),\n",
        "          bins=[0, 0.6, 0.75, 0.9, 1.01],\n",
        "          labels=[\"<60%\", \"60-75%\", \"75-90%\", \">90%\"]\n",
        "      )\n",
        "\n",
        "      lucro_medio = df_valid.groupby(\"FaixaConfiança\")[\"LucroEstimado\"].mean()\n",
        "\n",
        "      plt.figure(figsize=(8, 5))\n",
        "      lucro_medio.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
        "      plt.title(\"📊 Lucro Médio por Faixa de Confiança\")\n",
        "      plt.ylabel(\"Lucro Estimado\")\n",
        "      plt.xlabel(\"Faixa de Confiança\")\n",
        "      plt.grid(True)\n",
        "      plt.tight_layout()\n",
        "\n",
        "      path = \"lucro_por_faixa.png\"\n",
        "      plt.savefig(path)\n",
        "      plt.close()\n",
        "      print(\"✅ Gráfico de lucro por confiança enviado.\")\n",
        "\n",
        "\n",
        "  def simular_todos_trades(prediction_log_path=\"prediction_log.csv\", df_candles=None, timeframe=\"15m\"):\n",
        "      print(\"📊 Rodando simulação de carteira virtual com sinais do log...\")\n",
        "\n",
        "      if not os.path.exists(prediction_log_path):\n",
        "          print(\"⚠️ Log de previsões não encontrado.\")\n",
        "          return\n",
        "\n",
        "      df_log = safe_read_csv(prediction_log_path)\n",
        "      if df_log is None or df_log.empty:\n",
        "          print(\"⚠️ Log vazio.\")\n",
        "          return\n",
        "\n",
        "      df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "\n",
        "      # Define o tempo necessário para permitir simulação, baseado no timeframe\n",
        "      intervalo_futuro = {\n",
        "          \"15m\": timedelta(minutes=15 * 5),\n",
        "          \"1h\": timedelta(hours=5),\n",
        "          \"4h\": timedelta(hours=20),\n",
        "          \"1d\": timedelta(days=5),\n",
        "          \"1wk\": timedelta(weeks=5)\n",
        "      }.get(timeframe, timedelta(hours=1))\n",
        "\n",
        "      now = datetime.now(BR_TZ)\n",
        "      resultados = []\n",
        "\n",
        "      for _, row in df_log.iterrows():\n",
        "          signal_time = pd.to_datetime(row[\"Date\"], utc=True).tz_convert(BR_TZ)\n",
        "          if (now - signal_time) < intervalo_futuro:\n",
        "              continue  # sinal ainda recente, ignorar\n",
        "\n",
        "          try:\n",
        "              resultado = simular_trade(row, df_candles)\n",
        "              for key, value in resultado.items():\n",
        "                  row[key] = value\n",
        "              resultados.append(row)\n",
        "          except Exception as e:\n",
        "              print(f\"❌ Erro inesperado na simulação: {e}\")\n",
        "              continue\n",
        "\n",
        "      if not resultados:\n",
        "          print(\"📭 Nenhum trade foi simulado (ainda).\")\n",
        "          return\n",
        "\n",
        "      df_resultados = pd.DataFrame(resultados)\n",
        "      df_resultados.to_csv(prediction_log_path, index=False)\n",
        "      salvar_carteira_virtual()\n",
        "      print(f\"📋 Log de previsões atualizado com resultados e capital: {prediction_log_path}\")\n",
        "      plotar_grafico_lucro(df_resultados)\n",
        "\n",
        "\n",
        "\n",
        "  def salvar_grafico_evolucao(log_path=\"prediction_log.csv\"):\n",
        "      import matplotlib.pyplot as plt\n",
        "      import os\n",
        "\n",
        "      if not os.path.exists(log_path):\n",
        "          print(\"❌ Arquivo de log não encontrado.\")\n",
        "          return\n",
        "\n",
        "      df = safe_read_csv(log_path)\n",
        "      if df is None or df.empty:\n",
        "          print(\"⚠️ Log de previsões vazio ou inválido.\")\n",
        "          return\n",
        "\n",
        "      df = df.dropna(subset=[\"Date\", \"Capital Atual\", \"Resultado\"])\n",
        "      df[\"Date\"] = pd.to_datetime(df[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "      df = df[df[\"Resultado\"].isin([\"TP1\", \"SL\", \"Sem alvo\"])]\n",
        "\n",
        "      if df.empty:\n",
        "          print(\"⚠️ Nenhuma simulação válida para exibir no gráfico.\")\n",
        "          return\n",
        "\n",
        "      plt.figure(figsize=(12, 6))\n",
        "\n",
        "      # Cores por tipo de resultado\n",
        "      cor_map = {\"TP1\": \"green\", \"SL\": \"red\", \"Sem alvo\": \"orange\"}\n",
        "      cores = df[\"Resultado\"].map(cor_map).fillna(\"gray\")\n",
        "\n",
        "      # Gráfico de pontos\n",
        "      plt.scatter(df[\"Date\"], df[\"Capital Atual\"], c=cores, edgecolors=\"black\", s=70)\n",
        "\n",
        "      # Linha de evolução do capital\n",
        "      plt.plot(df[\"Date\"], df[\"Capital Atual\"], linestyle=\"--\", color=\"blue\", alpha=0.7)\n",
        "\n",
        "      # Anotações de valores\n",
        "      for idx, row in df.iterrows():\n",
        "          plt.annotate(f\"${row['Capital Atual']:.0f}\", (row[\"Date\"], row[\"Capital Atual\"]),\n",
        "                      textcoords=\"offset points\", xytext=(0, 6), ha='center', fontsize=8)\n",
        "\n",
        "      plt.title(\"💰 Evolução da Carteira Virtual\")\n",
        "      plt.xlabel(\"Data (BR)\")\n",
        "      plt.ylabel(\"Capital ($)\")\n",
        "      plt.xticks(rotation=45)\n",
        "      plt.grid(True)\n",
        "      plt.tight_layout()\n",
        "\n",
        "      path = \"/tmp/evolucao_carteira.png\"\n",
        "      plt.savefig(path)\n",
        "      plt.close()\n",
        "\n",
        "      print(f\"✅ Gráfico da carteira salvo: {path}\")\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 6. EXECUÇÃO DAS ANÁLISES E ALERTAS\n",
        "  # ====================================================\n",
        "\n",
        "  def run_analysis(\n",
        "      selected_timeframes=None,\n",
        "      plot_timeframes=[\"15m\", \"1h\"],\n",
        "      alert_timeframes=[\"15m\", \"1h\", \"1d\"],\n",
        "      retrain_models=False\n",
        "  ):\n",
        "      criar_prediction_log_padrao()\n",
        "      carregar_carteira_virtual()\n",
        "\n",
        "\n",
        "\n",
        "      if selected_timeframes is None:\n",
        "          selected_timeframes = TIMEFRAMES\n",
        "\n",
        "      results = []\n",
        "      houve_alerta = False\n",
        "\n",
        "      for asset in ASSETS:\n",
        "          print(f\"\\n📊 Analisando {asset}...\")\n",
        "          models = {}\n",
        "          lstm_models = {}\n",
        "          data = {}\n",
        "\n",
        "          try:\n",
        "              for tf in selected_timeframes:\n",
        "                  interval = tf['interval']\n",
        "                  period = tf['period']\n",
        "                  df = get_stock_data(asset, interval, period)\n",
        "                  df = calculate_indicators(df)\n",
        "                  data[interval] = df\n",
        "\n",
        "                  if retrain_models:\n",
        "                      models[interval] = train_ml_model(df, asset=asset, interval=interval, verbose=True)\n",
        "                  else:\n",
        "                      models[interval] = load_xgb_model(asset, interval)\n",
        "                      if models[interval] is None:\n",
        "                          models[interval] = train_ml_model(df, asset=asset, interval=interval, verbose=True)\n",
        "\n",
        "                  lstm_models[interval] = train_lstm_model(\n",
        "                      df, asset=asset, interval=interval, window_size=20, force_retrain=retrain_models\n",
        "                  )\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"❌ Erro ao processar {asset}: {e}\")\n",
        "              continue\n",
        "\n",
        "          if all(model is None for model in models.values()):\n",
        "              print(f\"⚠️ Nenhum modelo foi treinado para {asset}.\")\n",
        "              continue\n",
        "\n",
        "          for tf in selected_timeframes:\n",
        "              interval = tf['interval']\n",
        "              latest_data = data[interval].iloc[-1]\n",
        "              current_price = data[interval][\"Close\"].iloc[-1]\n",
        "\n",
        "              predicted_price_lstm = None\n",
        "              pred_high = None\n",
        "              pred_low = None\n",
        "              try:\n",
        "                  lstm_model = lstm_models.get(interval)\n",
        "                  if lstm_model:\n",
        "                      pred_lstm = predict_with_lstm(lstm_model, data[interval], asset=asset, interval=interval)\n",
        "\n",
        "                      # Verifica se a previsão retornou valores válidos\n",
        "                      if pred_lstm is None or any(pred_lstm.get(k) is None for k in [\"High\", \"Low\", \"Close\"]):\n",
        "                          print(f\"⚠️ Previsão LSTM inválida para {asset} ({interval}) — pulando análise.\")\n",
        "                          continue\n",
        "\n",
        "                      predicted_price_lstm = pred_lstm[\"Close\"]\n",
        "                      pred_high = pred_lstm[\"High\"]\n",
        "                      pred_low = pred_lstm[\"Low\"]\n",
        "\n",
        "              except Exception as e:\n",
        "                  print(f\"[!] Erro na previsão LSTM: {e}\")\n",
        "\n",
        "              print(f\"🔍 Preço atual ({interval}): ${current_price:,.2f}\")\n",
        "              if predicted_price_lstm is not None and not np.isnan(predicted_price_lstm):\n",
        "                  variation = round((predicted_price_lstm - current_price) / current_price * 100, 2)\n",
        "                  print(f\"🔮 Previsão LSTM: ${predicted_price_lstm:,.2f}\")\n",
        "                  print(f\"📈 Variação prevista: {variation:+.2f}%\")\n",
        "              else:\n",
        "                  print(\"🔮 Previsão LSTM: Indisponível ou inválida.\")\n",
        "                  variation = 0.0\n",
        "\n",
        "              if predicted_price_lstm and not np.isnan(predicted_price_lstm) and pred_high and pred_low:\n",
        "                  margem = current_price * 0.02\n",
        "                  if pred_high >= current_price + margem:\n",
        "                      prediction = 1  # Compra\n",
        "                  elif pred_low <= current_price - margem:\n",
        "                      prediction = 0  # Venda\n",
        "                  else:\n",
        "                      prediction = -1  # Neutro\n",
        "              else:\n",
        "                  prediction = -1\n",
        "\n",
        "              atr_multiplier = calcular_atr_auto(data[interval], intervalo=interval)\n",
        "              print(f\"🔧 ATR auto-ajustado para {asset} ({interval}): {atr_multiplier}\")\n",
        "              targets = calculate_targets(latest_data, prediction, atr_multiplier)\n",
        "\n",
        "              entry_price = targets.get(\"Entry\")\n",
        "              tp1 = targets.get(\"TP1\")\n",
        "              sl = targets.get(\"SL\")\n",
        "              tp2 = targets.get(\"TP2\")\n",
        "\n",
        "              # Proteção contra valores inválidos\n",
        "              if None in [entry_price, tp1, sl]:\n",
        "                  print(f\"⚠️ Targets incompletos para {asset} ({interval}) — pulando análise.\")\n",
        "                  continue\n",
        "\n",
        "              # Se TP2 não veio calculado, gera um padrão\n",
        "              if tp2 is None:\n",
        "                  tp2 = tp1 + (tp1 - entry_price) if prediction == 1 else tp1 - (entry_price - tp1)\n",
        "\n",
        "\n",
        "              # Risco/Retorno estimado\n",
        "              if prediction == 1 and (entry_price - sl) != 0:\n",
        "                  rr_ratio = round((tp1 - entry_price) / (entry_price - sl), 2)\n",
        "              elif prediction == 0 and (sl - entry_price) != 0:\n",
        "                  rr_ratio = round((entry_price - tp1) / (sl - entry_price), 2)\n",
        "              else:\n",
        "                  rr_ratio = \"-\"\n",
        "\n",
        "              explanation = generate_explanation(latest_data, prediction)\n",
        "              ajuste = adjust_signal_based_on_history(asset, interval)\n",
        "              model_xgb = models.get(interval)\n",
        "              val_score = model_xgb.validation_score if model_xgb and hasattr(model_xgb, \"validation_score\") else {}\n",
        "\n",
        "              result = {\n",
        "                  \"Asset\": asset,\n",
        "                  \"Timeframe\": interval,\n",
        "                  \"Date\": datetime.now(),\n",
        "                  \"Price\": current_price,\n",
        "                  \"Signal\": prediction,\n",
        "                  \"Confidence\": None,\n",
        "                  \"AdjustedProb\": round(ajuste, 2),\n",
        "                  \"TP1\": tp1,\n",
        "                  \"TP2\": tp2,\n",
        "                  \"SL\": sl,\n",
        "                  \"Entry\": entry_price,\n",
        "                  \"Accuracy\": val_score.get(\"accuracy\"),\n",
        "                  \"Precision\": val_score.get(\"precision\"),\n",
        "                  \"Recall\": val_score.get(\"recall\"),\n",
        "                  \"F1\": val_score.get(\"f1\"),\n",
        "                  \"LSTM_Predicted\": predicted_price_lstm,\n",
        "                  \"TargetPrice\": predicted_price_lstm,\n",
        "                  \"LSTM_High_Predicted\": pred_high,\n",
        "                  \"LSTM_Low_Predicted\": pred_low\n",
        "              }\n",
        "\n",
        "\n",
        "              results.append(result)\n",
        "\n",
        "              if interval in alert_timeframes:\n",
        "                  # Verifica se a variação prevista é suficiente para alerta\n",
        "                  variacao_minima = ALERTA_VARIACAO_MINIMA.get(interval, 1.0)\n",
        "                  if abs(variation) < variacao_minima:\n",
        "                      print(f\"⚠️ Variação de {variation:.2f}% insuficiente (< {variacao_minima}%) — alerta não enviado.\")\n",
        "                      continue\n",
        "\n",
        "                  if prediction in [0, 1]:\n",
        "                      # ... aqui continua normalmente com o envio do alerta\n",
        "\n",
        "                      trend_emoji = \"🟢\" if prediction == 1 else \"🔴\"\n",
        "                      trend_text = \"COMPRA\" if prediction == 1 else \"VENDA\"\n",
        "                      # 🔵 Primeiro define validade\n",
        "                      delta_validades = {\n",
        "                          \"15m\": timedelta(minutes=15),\n",
        "                          \"1h\": timedelta(hours=1),\n",
        "                          \"1d\": timedelta(days=1),\n",
        "                          \"1wk\": timedelta(weeks=1)\n",
        "                      }\n",
        "                      validade = datetime.now(BR_TZ) + delta_validades.get(interval, timedelta(hours=1))\n",
        "\n",
        "                      # 🔵 Agora monta a mensagem formatada\n",
        "                      message = f\"\"\"\n",
        "\n",
        "  📢 <b>SINAL DETECTADO</b>\n",
        "\n",
        "  🪙 <b>Ativo:</b> {asset}\n",
        "  🕒 <b>Timeframe:</b> {interval}\n",
        "  {trend_emoji} <b>Tendência (via LSTM):</b> {trend_text}\n",
        "\n",
        "  💰 <b>Preço Atual:</b> ${current_price:,.2f}\n",
        "  🔮 <b>Previsão LSTM (Fechamento):</b> ${predicted_price_lstm:,.2f} ({variation:+.2f}%)\n",
        "  📈 <b>Alta Prevista (High):</b> ${pred_high:,.2f}\n",
        "  📉 <b>Baixa Prevista (Low):</b> ${pred_low:,.2f}\n",
        "  🎯 <b>TP1:</b> ${targets['TP1']:,.2f}\n",
        "  🎯 <b>TP2:</b> ${targets['TP2']:,.2f}\n",
        "  🛑 <b>Stop Loss:</b> ${targets['SL']:,.2f}\n",
        "\n",
        "  📋 <b>Justificativa Técnica:</b>\n",
        "  {explanation}\n",
        "\n",
        "  📊 <b>Risco/Retorno estimado:</b> {rr_ratio}\n",
        "  🧠 <b>Confiança histórica:</b> {ajuste*100:.1f}%\n",
        "  🗓 <b>Válido até:</b> {validade.strftime('%d/%m %H:%M')}\n",
        "  \"\"\"\n",
        "                      message += \"\\n\\n\" + gerar_resumo_ultimos_sinais(asset, interval, n=15)\n",
        "                      message += \"\\n\\n\" + gerar_ranking_lucro()\n",
        "                      message += \"\\n\\n\" + gerar_resumo_por_padrao(asset, interval)\n",
        "\n",
        "\n",
        "                      try:\n",
        "                          send_telegram_message(message)\n",
        "                          print(\"📨 Alerta enviado para o Telegram!\")\n",
        "                      except Exception as e:\n",
        "                          print(f\"❌ Erro ao enviar mensagem: {e}\")\n",
        "\n",
        "                      try:\n",
        "                          df_log = safe_read_csv(\"/content/prediction_log.csv\")\n",
        "                          if df_log is not None:\n",
        "                              df_log = df_log[df_log[\"Timeframe\"] == interval]\n",
        "                              df_log = df_log.dropna(subset=[\"TargetPrice\", \"Price\"])\n",
        "                              df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"])\n",
        "                              df_recent = df_log.sort_values(\"Date\").tail(20)\n",
        "                              enviar_grafico_previsao_real(df_recent, interval, asset)\n",
        "\n",
        "                      except Exception as e:\n",
        "                          print(f\"⚠️ Erro ao enviar gráfico de previsão: {e}\")\n",
        "\n",
        "                      try:\n",
        "                          salvar_grafico_evolucao()\n",
        "                          enviar_grafico_carteira()\n",
        "                      except Exception as e:\n",
        "                          print(f\"⚠️ Erro ao enviar gráfico da carteira: {e}\")\n",
        "\n",
        "                      houve_alerta = True\n",
        "                  else:\n",
        "                      print(\"⛔ Previsão LSTM neutra — alerta não enviado.\")\n",
        "\n",
        "          df_results = pd.DataFrame(results)\n",
        "          timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "          filename = f\"model_results_{timestamp}.csv\"\n",
        "          df_results.to_csv(filename, index=False)\n",
        "          print(f\"\\n📁 Resultados salvos em: {filename}\")\n",
        "\n",
        "          log_path = \"/content/prediction_log.csv\"\n",
        "          df_log_old = safe_read_csv(log_path)\n",
        "\n",
        "          if df_log_old is not None:\n",
        "              df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True).fillna(\"\")\n",
        "              df_log_combined.to_csv(log_path, index=False)\n",
        "              print(f\"📋 Log de previsões atualizado em: {log_path}\")\n",
        "          else:\n",
        "              df_results.to_csv(log_path, index=False)\n",
        "              print(f\"🔄 Log de previsões criado em: {log_path}\")\n",
        "\n",
        "          print(\"✅ Análise completa.\")\n",
        "          salvar_carteira_virtual()\n",
        "\n",
        "          # 👇 Enviar gráfico com apenas 3 projeções caso o histórico esteja vazio\n",
        "          try:\n",
        "              df_log = safe_read_csv(\"/content/prediction_log.csv\")\n",
        "              df_log = df_log[df_log[\"Asset\"] == asset]\n",
        "              df_log = df_log[df_log[\"Timeframe\"] == interval]\n",
        "              df_log = df_log.dropna(subset=[\"TargetPrice\", \"Price\"])\n",
        "              df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], utc=True).dt.tz_convert(BR_TZ)\n",
        "              df_recent = df_log.sort_values(\"Date\").tail(20)\n",
        "\n",
        "              if df_recent.empty and predicted_price_lstm and pred_high and pred_low:\n",
        "                  # ⏳ Enviar gráfico apenas com projeção futura (sem histórico)\n",
        "                  now = datetime.now(BR_TZ)\n",
        "                  # Ajusta intervalo com base no timeframe\n",
        "                  delta_map = {\"15m\": 15, \"1h\": 60, \"1d\": 1440, \"1wk\": 10080}\n",
        "                  delta = timedelta(minutes=delta_map.get(interval, 60))\n",
        "                  previsoes_futuras = {\n",
        "                      \"Date\": [now + delta * i for i in range(1, 4)],\n",
        "                      \"High\": [pred_high] * 3,\n",
        "                      \"Low\": [pred_low] * 3,\n",
        "                      \"Close\": [predicted_price_lstm] * 3\n",
        "                  }\n",
        "                  # Chamada correta, você deve criar ou adaptar essa função para aceitar `df_futuro`\n",
        "                  enviar_grafico_previsao_futura(previsoes_futuras, interval, asset)\n",
        "\n",
        "              else:\n",
        "                  enviar_grafico_previsao_real(df_recent, interval, asset)\n",
        "\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"⚠️ Erro ao enviar gráfico de previsão: {e}\")\n",
        "\n",
        "\n",
        "          try:\n",
        "              df_log = safe_read_csv(log_path)\n",
        "              if df_log is not None and not df_log.empty:\n",
        "                  colunas = [\"Date\", \"Asset\", \"Timeframe\", \"Price\", \"Signal\",\n",
        "                            \"LSTM_High_Predicted\", \"LSTM_Low_Predicted\", \"LSTM_Predicted\",\n",
        "                            \"TP1\", \"TP2\", \"SL\", \"TargetPrice\", \"AdjustedProb\"]\n",
        "                  colunas_disponiveis = [c for c in colunas if c in df_log.columns]\n",
        "                  df_log = df_log[colunas_disponiveis].tail(5)\n",
        "                  print(\"\\n🧪 Últimos sinais registrados no log:\")\n",
        "                  print(df_log.to_string(index=False))\n",
        "              else:\n",
        "                  print(\"🗕 Log de previsões está vazio ou inválido.\")\n",
        "          except Exception as e:\n",
        "              print(f\"⚠️ Erro ao exibir últimos sinais: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # ====================================================\n",
        "  # 7. AGENDAMENTO E EXECUÇÃO AUTOMÁTICA COM THREADS\n",
        "  # ====================================================\n",
        "  import threading\n",
        "\n",
        "  def agendar_analise_timeframe(tf_config):\n",
        "      interval = tf_config[\"interval\"]\n",
        "      while True:\n",
        "          now = datetime.now(BR_TZ)\n",
        "          if is_time_to_run(interval):\n",
        "              print(f\"\\n🚀 Rodando análise para timeframe {interval} - {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "              try:\n",
        "                  run_analysis(\n",
        "                      selected_timeframes=[tf_config],\n",
        "                      plot_timeframes=[\"1h\"],           # Edite conforme necessário\n",
        "                      alert_timeframes=[\"15m\", \"1h\", \"1d\", \"1wk\"]\n",
        "                  )\n",
        "              except Exception as e:\n",
        "                  print(f\"❌ Erro durante a análise de {interval}: {e}\")\n",
        "              time.sleep(60)  # Evita múltiplas execuções no mesmo minuto\n",
        "          else:\n",
        "              print(f\"⏳ [{interval}] Ainda não é hora... {now.strftime('%H:%M:%S')}\")\n",
        "              time.sleep(30)  # Verifica novamente em 30s para ser mais leve\n",
        "\n",
        "  # 🚀 Criar uma thread separada para cada timeframe\n",
        "  if __name__ == \"__main__\":\n",
        "      print(\"🧵 Iniciando threads para cada timeframe...\")\n",
        "\n",
        "      threads = []\n",
        "      for tf in TIMEFRAMES:\n",
        "          t = threading.Thread(target=agendar_analise_timeframe, args=(tf,), daemon=True)\n",
        "          t.start()\n",
        "          threads.append(t)\n",
        "\n",
        "      # Manter o programa rodando\n",
        "      while True:\n",
        "          time.sleep(60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FRgd1-k06BB",
        "outputId": "ae0a531a-01ef-44cf-f9eb-5888ef7cbb18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ [1h] Ainda não é hora... 15:09:22\n",
            "⏳ [1wk] Ainda não é hora... 15:09:22\n",
            "⏳ [1d] Ainda não é hora... 15:09:22\n",
            "🧵 Iniciando threads para cada timeframe...\n",
            "⏳ [15m] Ainda não é hora... 15:09:22\n",
            "⏳ [1h] Ainda não é hora... 15:09:22\n",
            "⏳ [1d] Ainda não é hora... 15:09:22\n",
            "⏳ [1wk] Ainda não é hora... 15:09:22\n",
            "⏳ [15m] Ainda não é hora... 15:09:28\n",
            "⏳ [1h] Ainda não é hora... 15:09:30\n",
            "⏳ [1h] Ainda não é hora... 15:09:30\n",
            "⏳ [1d] Ainda não é hora... 15:09:37\n",
            "⏳ [1wk] Ainda não é hora... 15:09:37\n",
            "⏳ [1d] Ainda não é hora... 15:09:38\n",
            "⏳ [1wk] Ainda não é hora... 15:09:38\n",
            "⏳ [1wk] Ainda não é hora... 15:09:39\n",
            "⏳ [1d] Ainda não é hora... 15:09:39\n",
            "⏳ [1wk] Ainda não é hora... 15:09:41\n",
            "⏳ [1d] Ainda não é hora... 15:09:41\n",
            "⏳ [1d] Ainda não é hora... 15:09:41\n",
            "⏳ [1wk] Ainda não é hora... 15:09:41\n",
            "⏳ [1wk] Ainda não é hora... 15:09:44\n",
            "⏳ [1d] Ainda não é hora... 15:09:44\n",
            "⏳ [1h] Ainda não é hora... 15:09:45\n",
            "⏳ [15m] Ainda não é hora... 15:09:45\n",
            "⏳ [15m] Ainda não é hora... 15:09:45\n",
            "⏳ [1h] Ainda não é hora... 15:09:47\n",
            "⏳ [15m] Ainda não é hora... 15:09:47\n",
            "⏳ [1h] Ainda não é hora... 15:09:48\n",
            "⏳ [15m] Ainda não é hora... 15:09:48\n",
            "⏳ [1h] Ainda não é hora... 15:09:48\n",
            "⏳ [1wk] Ainda não é hora... 15:09:48\n",
            "⏳ [1d] Ainda não é hora... 15:09:48\n",
            "⏳ [15m] Ainda não é hora... 15:09:49\n",
            "⏳ [1h] Ainda não é hora... 15:09:49\n",
            "⏳ [15m] Ainda não é hora... 15:09:49\n",
            "⏳ [15m] Ainda não é hora... 15:09:51\n",
            "⏳ [1h] Ainda não é hora... 15:09:52\n",
            "⏳ [1wk] Ainda não é hora... 15:09:52\n",
            "⏳ [1d] Ainda não é hora... 15:09:52\n",
            "⏳ [15m] Ainda não é hora... 15:09:52\n",
            "⏳ [1h] Ainda não é hora... 15:09:52\n",
            "⏳ [1d] Ainda não é hora... 15:09:52\n",
            "⏳ [1wk] Ainda não é hora... 15:09:52\n",
            "⏳ [15m] Ainda não é hora... 15:09:58\n",
            "⏳ [1h] Ainda não é hora... 15:10:00\n",
            "⏳ [1h] Ainda não é hora... 15:10:00\n",
            "⏳ [1d] Ainda não é hora... 15:10:07\n",
            "⏳ [1wk] Ainda não é hora... 15:10:07\n",
            "⏳ [1d] Ainda não é hora... 15:10:08\n",
            "⏳ [1wk] Ainda não é hora... 15:10:08\n",
            "⏳ [1wk] Ainda não é hora... 15:10:09\n",
            "⏳ [1d] Ainda não é hora... 15:10:09\n",
            "⏳ [1d] Ainda não é hora... 15:10:11⏳ [1wk] Ainda não é hora... 15:10:11\n",
            "\n",
            "⏳ [1d] Ainda não é hora... 15:10:11\n",
            "⏳ [1wk] Ainda não é hora... 15:10:11\n",
            "⏳ [1wk] Ainda não é hora... 15:10:14\n",
            "⏳ [1d] Ainda não é hora... 15:10:14\n",
            "⏳ [1h] Ainda não é hora... 15:10:15\n",
            "⏳ [15m] Ainda não é hora... 15:10:15\n",
            "⏳ [15m] Ainda não é hora... 15:10:15\n",
            "⏳ [1h] Ainda não é hora... 15:10:17\n",
            "⏳ [15m] Ainda não é hora... 15:10:17\n",
            "⏳ [1h] Ainda não é hora... 15:10:18\n",
            "⏳ [15m] Ainda não é hora... 15:10:18\n",
            "⏳ [1wk] Ainda não é hora... 15:10:18\n",
            "⏳ [1h] Ainda não é hora... 15:10:18\n",
            "⏳ [1d] Ainda não é hora... 15:10:18\n",
            "⏳ [15m] Ainda não é hora... 15:10:19\n",
            "⏳ [1h] Ainda não é hora... 15:10:19\n",
            "⏳ [15m] Ainda não é hora... 15:10:19\n",
            "⏳ [15m] Ainda não é hora... 15:10:21\n",
            "⏳ [1h] Ainda não é hora... 15:10:22\n",
            "⏳ [1wk] Ainda não é hora... 15:10:22\n",
            "⏳ [1d] Ainda não é hora... 15:10:22\n",
            "⏳ [15m] Ainda não é hora... 15:10:22\n",
            "⏳ [1h] Ainda não é hora... 15:10:22\n",
            "⏳ [1d] Ainda não é hora... 15:10:22\n",
            "⏳ [1wk] Ainda não é hora... 15:10:22\n",
            "⏳ [15m] Ainda não é hora... 15:10:28\n",
            "⏳ [1h] Ainda não é hora... 15:10:30\n",
            "⏳ [1h] Ainda não é hora... 15:10:30\n",
            "⏳ [1d] Ainda não é hora... 15:10:37\n",
            "⏳ [1wk] Ainda não é hora... 15:10:37\n",
            "⏳ [1d] Ainda não é hora... 15:10:38\n",
            "⏳ [1wk] Ainda não é hora... 15:10:38\n",
            "⏳ [1wk] Ainda não é hora... 15:10:39\n",
            "⏳ [1d] Ainda não é hora... 15:10:39\n",
            "⏳ [1wk] Ainda não é hora... 15:10:41⏳ [1d] Ainda não é hora... 15:10:41\n",
            "\n",
            "⏳ [1d] Ainda não é hora... 15:10:41\n",
            "⏳ [1wk] Ainda não é hora... 15:10:41\n",
            "⏳ [1wk] Ainda não é hora... 15:10:44\n",
            "⏳ [1d] Ainda não é hora... 15:10:44\n",
            "⏳ [1h] Ainda não é hora... 15:10:45\n",
            "⏳ [15m] Ainda não é hora... 15:10:45\n",
            "⏳ [15m] Ainda não é hora... 15:10:45\n",
            "⏳ [1h] Ainda não é hora... 15:10:47\n",
            "⏳ [15m] Ainda não é hora... 15:10:47\n",
            "⏳ [1h] Ainda não é hora... 15:10:48\n",
            "⏳ [15m] Ainda não é hora... 15:10:48\n",
            "⏳ [1wk] Ainda não é hora... 15:10:48\n",
            "⏳ [1h] Ainda não é hora... 15:10:48\n",
            "⏳ [1d] Ainda não é hora... 15:10:48\n",
            "⏳ [15m] Ainda não é hora... 15:10:49\n",
            "⏳ [1h] Ainda não é hora... 15:10:49\n",
            "⏳ [15m] Ainda não é hora... 15:10:49\n",
            "⏳ [15m] Ainda não é hora... 15:10:51\n",
            "⏳ [1h] Ainda não é hora... 15:10:52\n",
            "⏳ [1wk] Ainda não é hora... 15:10:52\n",
            "⏳ [1d] Ainda não é hora... 15:10:52\n",
            "⏳ [15m] Ainda não é hora... 15:10:52⏳ [1h] Ainda não é hora... 15:10:52\n",
            "\n",
            "⏳ [1d] Ainda não é hora... 15:10:52\n",
            "⏳ [1wk] Ainda não é hora... 15:10:52\n",
            "⏳ [15m] Ainda não é hora... 15:10:58\n",
            "⏳ [1h] Ainda não é hora... 15:11:00\n",
            "⏳ [1h] Ainda não é hora... 15:11:00\n",
            "⏳ [1d] Ainda não é hora... 15:11:07\n",
            "⏳ [1wk] Ainda não é hora... 15:11:07\n",
            "⏳ [1d] Ainda não é hora... 15:11:08\n",
            "⏳ [1wk] Ainda não é hora... 15:11:08\n",
            "⏳ [1wk] Ainda não é hora... 15:11:09\n",
            "⏳ [1d] Ainda não é hora... 15:11:09\n",
            "⏳ [1d] Ainda não é hora... 15:11:11⏳ [1wk] Ainda não é hora... 15:11:11\n",
            "\n",
            "⏳ [1d] Ainda não é hora... 15:11:11\n",
            "⏳ [1wk] Ainda não é hora... 15:11:11\n",
            "⏳ [1wk] Ainda não é hora... 15:11:14\n",
            "⏳ [1d] Ainda não é hora... 15:11:14\n",
            "⏳ [1h] Ainda não é hora... 15:11:15\n",
            "⏳ [15m] Ainda não é hora... 15:11:15\n",
            "⏳ [15m] Ainda não é hora... 15:11:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[\n",
        "        {\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02}\n",
        "    ],\n",
        "    plot_timeframes=[\"15m\"],\n",
        "    alert_timeframes=[\"15m\"],\n",
        "    retrain_models=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "4s5E__BYpdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[\n",
        "        {\"interval\": \"1h\", \"period\": \"120d\", \"atr\": 0.03}\n",
        "    ],\n",
        "    plot_timeframes=[\"1h\"],\n",
        "    alert_timeframes=[\"1h\"],\n",
        "    retrain_models=False\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lZAmWtI3rf7",
        "outputId": "b2678076-7afe-42f9-a3bc-6ea7eeb784a6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏳ [1wk] Ainda não é hora... 14:58:22\n",
            "⏳ [1d] Ainda não é hora... 14:58:22\n",
            "⏳ [1h] Ainda não é hora... 14:58:22\n",
            "📂 Carteira virtual carregada de: /content/carteira_virtual.json\n",
            "\n",
            "📊 Analisando BTC-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_1h.joblib\n",
            "✅ X.shape: (1244, 20, 23), y.shape: (1244, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_BTCUSD_1h_meta.pkl\n",
            "⏳ [15m] Ainda não é hora... 14:58:23\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=93882.48, Low=94297.27\n",
            "🔍 Preço atual (1h): $94,452.95\n",
            "🔮 Previsão LSTM: $94,262.73\n",
            "📈 Variação prevista: -0.20%\n",
            "🔧 ATR auto-ajustado para BTC-USD (1h): 0.01\n",
            "⚠️ Targets incompletos para BTC-USD (1h) — pulando análise.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-23.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date       Asset Timeframe    Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted  TP1  TP2   SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:00:24.705858     DOT-USD        1h 4.311836       0             4.278980            4.190414        4.190414 4.25 4.20 4.37     4.190414           1.0\n",
            "2025-04-25 17:00:26.356465    NEAR-USD        1h 2.618429      -1             2.579555            2.568507        2.579555  NaN  NaN  NaN     2.579555           1.0\n",
            "2025-04-25 17:00:27.036627     ADA-USD        1h 0.725094      -1             0.734654            0.718570        0.718570  NaN  NaN  NaN     0.718570           1.0\n",
            "2025-04-25 17:02:20.772675 VIRTUAL-USD        1h 0.923559       0             0.899056            0.850257        0.875388 0.90 0.88 0.95     0.875388           1.0\n",
            "2025-04-25 17:04:04.460450  PENDLE-USD        1h 3.717534       0             3.724842            3.611524        3.653865 3.64 3.57 3.79     3.653865           1.0\n",
            "\n",
            "📊 Analisando ETH-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_ETHUSD_1h.joblib\n",
            "✅ X.shape: (1281, 20, 23), y.shape: (1281, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_ETHUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_ETHUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=1865.71, Low=1906.07\n",
            "🔍 Preço atual (1h): $1,786.10\n",
            "🔮 Previsão LSTM: $1,901.16\n",
            "📈 Variação prevista: +6.44%\n",
            "🔧 ATR auto-ajustado para ETH-USD (1h): 0.013\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-25.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date       Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:00:26.356465    NEAR-USD        1h    2.618429      -1             2.579555            2.568507        2.579555       NaN       NaN       NaN     2.579555           1.0\n",
            "2025-04-25 17:00:27.036627     ADA-USD        1h    0.725094      -1             0.734654            0.718570        0.718570       NaN       NaN       NaN     0.718570           1.0\n",
            "2025-04-25 17:02:20.772675 VIRTUAL-USD        1h    0.923559       0             0.899056            0.850257        0.875388    0.9000    0.8800    0.9500     0.875388           1.0\n",
            "2025-04-25 17:04:04.460450  PENDLE-USD        1h    3.717534       0             3.724842            3.611524        3.653865    3.6400    3.5700    3.7900     3.653865           1.0\n",
            "2025-04-25 17:58:24.762577     ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "\n",
            "📊 Analisando SOL-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_SOLUSD_1h.joblib\n",
            "✅ X.shape: (1250, 20, 23), y.shape: (1250, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_SOLUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_SOLUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=148.24, Low=150.97\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 147.82\n",
            "✅ Close ajustado para: 148.24\n",
            "🔍 Preço atual (1h): $150.83\n",
            "🔮 Previsão LSTM: $148.24\n",
            "📈 Variação prevista: -1.71%\n",
            "🔧 ATR auto-ajustado para SOL-USD (1h): 0.0132\n",
            "⚠️ Targets incompletos para SOL-USD (1h) — pulando análise.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-27.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date       Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:00:27.036627     ADA-USD        1h    0.725094      -1             0.734654            0.718570        0.718570       NaN       NaN       NaN     0.718570           1.0\n",
            "2025-04-25 17:02:20.772675 VIRTUAL-USD        1h    0.923559       0             0.899056            0.850257        0.875388    0.9000    0.8800    0.9500     0.875388           1.0\n",
            "2025-04-25 17:04:04.460450  PENDLE-USD        1h    3.717534       0             3.724842            3.611524        3.653865    3.6400    3.5700    3.7900     3.653865           1.0\n",
            "2025-04-25 17:58:24.762577     ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:24.762577     ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "\n",
            "📊 Analisando XRP-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_XRPUSD_1h.joblib\n",
            "✅ X.shape: (1230, 20, 23), y.shape: (1230, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_XRPUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_XRPUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=2.21, Low=2.31\n",
            "🔍 Preço atual (1h): $2.19\n",
            "🔮 Previsão LSTM: $2.26\n",
            "📈 Variação prevista: +3.28%\n",
            "🔧 ATR auto-ajustado para XRP-USD (1h): 0.0119\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-30.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date      Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:04:04.460450 PENDLE-USD        1h    3.717534       0             3.724842            3.611524        3.653865    3.6400    3.5700    3.7900     3.653865           1.0\n",
            "2025-04-25 17:58:24.762577    ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:24.762577    ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:24.762577    ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963    XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "\n",
            "📊 Analisando AVAX-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_AVAXUSD_1h.joblib\n",
            "✅ X.shape: (1288, 20, 23), y.shape: (1288, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_AVAXUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_AVAXUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=20.68, Low=22.41\n",
            "🔍 Preço atual (1h): $22.38\n",
            "🔮 Previsão LSTM: $21.86\n",
            "📈 Variação prevista: -2.34%\n",
            "🔧 ATR auto-ajustado para AVAX-USD (1h): 0.0163\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-32.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date    Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:24.762577  ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:24.762577  ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h   22.382565       0            22.412140           20.675095       21.858902   22.3667   22.0227   23.1359    21.858902           1.0\n",
            "\n",
            "📊 Analisando AAVE-USD...\n",
            "⏳ [15m] Ainda não é hora... 14:58:37\n",
            "⏳ [1d] Ainda não é hora... 14:58:37\n",
            "⏳ [1wk] Ainda não é hora... 14:58:37\n",
            "⏳ [1h] Ainda não é hora... 14:58:37\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_AAVEUSD_1h.joblib\n",
            "✅ X.shape: (1291, 20, 23), y.shape: (1291, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_AAVEUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_AAVEUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=142.36, Low=158.17\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 159.10\n",
            "✅ Close ajustado para: 158.17\n",
            "🔍 Preço atual (1h): $166.68\n",
            "🔮 Previsão LSTM: $158.17\n",
            "📈 Variação prevista: -5.11%\n",
            "🔧 ATR auto-ajustado para AAVE-USD (1h): 0.0154\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-38.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "⏳ [15m] Ainda não é hora... 14:58:38⏳ [1wk] Ainda não é hora... 14:58:38\n",
            "⏳ [1h] Ainda não é hora... 14:58:38\n",
            "⏳ [1d] Ainda não é hora... 14:58:38\n",
            "\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date    Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h   22.382565       0            22.412140           20.675095       21.858902   22.3667   22.0227   23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:24.762577  ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h   22.382565       0            22.412140           20.675095       21.858902   22.3667   22.0227   23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:37.494236 AAVE-USD        1h  166.682205       0           158.167862          142.357361      158.167862  166.5779  165.0825  172.9517   158.167862           1.0\n",
            "\n",
            "📊 Analisando DOT-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_DOTUSD_1h.joblib\n",
            "✅ X.shape: (1279, 20, 23), y.shape: (1279, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_DOTUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_DOTUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=4.18, Low=4.26\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 4.27\n",
            "✅ Close ajustado para: 4.26\n",
            "🔍 Preço atual (1h): $4.27\n",
            "🔮 Previsão LSTM: $4.26\n",
            "📈 Variação prevista: -0.18%\n",
            "🔧 ATR auto-ajustado para DOT-USD (1h): 0.0133\n",
            "⚠️ Targets incompletos para DOT-USD (1h) — pulando análise.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-40.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "⏳ [1wk] Ainda não é hora... 14:58:40\n",
            "⏳ [1d] Ainda não é hora... 14:58:40\n",
            "⏳ [1h] Ainda não é hora... 14:58:40\n",
            "⏳ [15m] Ainda não é hora... 14:58:40\n",
            "⏳ [1h] Ainda não é hora... 14:58:41\n",
            "⏳ [1d] Ainda não é hora... 14:58:41\n",
            "⏳ [1wk] Ainda não é hora... 14:58:41\n",
            "⏳ [15m] Ainda não é hora... 14:58:41\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date    Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:37.494236 AAVE-USD        1h  166.682205       0           158.167862          142.357361      158.167862  166.5779  165.0825  172.9517   158.167862           1.0\n",
            "2025-04-25 17:58:24.762577  ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h   22.382565       0            22.412140           20.675095       21.858902   22.3667   22.0227   23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:37.494236 AAVE-USD        1h  166.682205       0           158.167862          142.357361      158.167862  166.5779  165.0825  172.9517   158.167862           1.0\n",
            "\n",
            "📊 Analisando NEAR-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_NEARUSD_1h.joblib\n",
            "✅ X.shape: (1263, 20, 23), y.shape: (1263, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_NEARUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_NEARUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=2.59, Low=2.67\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 2.87\n",
            "✅ Close ajustado para: 2.67\n",
            "🔍 Preço atual (1h): $2.59\n",
            "🔮 Previsão LSTM: $2.67\n",
            "📈 Variação prevista: +2.93%\n",
            "🔧 ATR auto-ajustado para NEAR-USD (1h): 0.0151\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-42.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "✅ Gráfico de candle com rótulos enviado ao Telegram.\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date    Asset Timeframe       Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted       TP1       TP2        SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:24.762577  ETH-USD        1h 1786.098511       1          1906.068359         1865.705566     1901.161499 1811.2809 1831.1452 1761.5403  1901.161499           1.0\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h    2.188083       1             2.310895            2.214182        2.259922    2.2093    2.2388    2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h   22.382565       0            22.412140           20.675095       21.858902   22.3667   22.0227   23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:37.494236 AAVE-USD        1h  166.682205       0           158.167862          142.357361      158.167862  166.5779  165.0825  172.9517   158.167862           1.0\n",
            "2025-04-25 17:58:41.759008 NEAR-USD        1h    2.591279       1             2.667318            2.590780        2.667318    2.6290    2.6621    2.5450     2.667318           1.0\n",
            "\n",
            "📊 Analisando ADA-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_ADAUSD_1h.joblib\n",
            "✅ X.shape: (1223, 20, 23), y.shape: (1223, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_ADAUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_ADAUSD_1h_meta.pkl\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 0.67\n",
            "✅ Close ajustado para: 0.69\n",
            "🔍 Preço atual (1h): $0.72\n",
            "🔮 Previsão LSTM: $0.69\n",
            "📈 Variação prevista: -4.50%\n",
            "🔧 ATR auto-ajustado para ADA-USD (1h): 0.0152\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "⚠️ Nenhum dado para ADA-USD (1h) no gráfico.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-44.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "⏳ [15m] Ainda não é hora... 14:58:44\n",
            "⏳ [1d] Ainda não é hora... 14:58:44\n",
            "⏳ [1wk] Ainda não é hora... 14:58:44\n",
            "⏳ [1h] Ainda não é hora... 14:58:44\n",
            "❌ Erro ao enviar gráfico: 429 - {\"ok\":false,\"error_code\":429,\"description\":\"Too Many Requests: retry after 18\",\"parameters\":{\"retry_after\":18}}\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date    Asset Timeframe      Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:29.544963  XRP-USD        1h   2.188083       1             2.310895            2.214182        2.259922   2.2093   2.2388   2.1607     2.259922           1.0\n",
            "2025-04-25 17:58:32.036811 AVAX-USD        1h  22.382565       0            22.412140           20.675095       21.858902  22.3667  22.0227  23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:37.494236 AAVE-USD        1h 166.682205       0           158.167862          142.357361      158.167862 166.5779 165.0825 172.9517   158.167862           1.0\n",
            "2025-04-25 17:58:41.759008 NEAR-USD        1h   2.591279       1             2.667318            2.590780        2.667318   2.6290   2.6621   2.5450     2.667318           1.0\n",
            "2025-04-25 17:58:44.114027  ADA-USD        1h   0.717381       0             0.699809            0.685103        0.685103   0.7154   0.7056   0.7387     0.685103           1.0\n",
            "\n",
            "📊 Analisando VIRTUAL-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_VIRTUALUSD_1h.joblib\n",
            "✅ X.shape: (1270, 20, 23), y.shape: (1270, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_VIRTUALUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_VIRTUALUSD_1h_meta.pkl\n",
            "⚠️ Corrigindo inversão de High/Low na previsão LSTM. High=0.66, Low=0.82\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 0.86\n",
            "✅ Close ajustado para: 0.82\n",
            "🔍 Preço atual (1h): $0.91\n",
            "🔮 Previsão LSTM: $0.82\n",
            "📈 Variação prevista: -10.00%\n",
            "🔧 ATR auto-ajustado para VIRTUAL-USD (1h): 0.0244\n",
            "❌ Erro ao enviar mensagem: 429 - {\"ok\":false,\"error_code\":429,\"description\":\"Too Many Requests: retry after 17\",\"parameters\":{\"retry_after\":17}}\n",
            "📨 Alerta enviado para o Telegram!\n",
            "⚠️ Nenhum dado para VIRTUAL-USD (1h) no gráfico.\n",
            "⚠️ Erro ao enviar gráfico da carteira: ['Capital Atual']\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-46.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "❌ Erro ao enviar gráfico: 429 - {\"ok\":false,\"error_code\":429,\"description\":\"Too Many Requests: retry after 16\",\"parameters\":{\"retry_after\":16}}\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date       Asset Timeframe      Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:32.036811    AVAX-USD        1h  22.382565       0            22.412140           20.675095       21.858902  22.3667  22.0227  23.1359    21.858902           1.0\n",
            "2025-04-25 17:58:37.494236    AAVE-USD        1h 166.682205       0           158.167862          142.357361      158.167862 166.5779 165.0825 172.9517   158.167862           1.0\n",
            "2025-04-25 17:58:41.759008    NEAR-USD        1h   2.591279       1             2.667318            2.590780        2.667318   2.6290   2.6621   2.5450     2.667318           1.0\n",
            "2025-04-25 17:58:44.114027     ADA-USD        1h   0.717381       0             0.699809            0.685103        0.685103   0.7154   0.7056   0.7387     0.685103           1.0\n",
            "2025-04-25 17:58:45.856132 VIRTUAL-USD        1h   0.912932       0             0.821628            0.660385        0.821628   0.9129   0.8942   0.9630     0.821628           1.0\n",
            "\n",
            "📊 Analisando PENDLE-USD...\n",
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_PENDLEUSD_1h.joblib\n",
            "✅ X.shape: (1313, 20, 23), y.shape: (1313, 3)\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_PENDLEUSD_1h.h5\n",
            "📦 Metadados carregados de: /content/models/lstm_model_PENDLEUSD_1h_meta.pkl\n",
            "⚠️ Ajustando Close fora da faixa. Antes: 3.69\n",
            "✅ Close ajustado para: 3.69\n",
            "🔍 Preço atual (1h): $3.66\n",
            "🔮 Previsão LSTM: $3.69\n",
            "📈 Variação prevista: +0.92%\n",
            "🔧 ATR auto-ajustado para PENDLE-USD (1h): 0.0206\n",
            "⚠️ Variação de 0.92% insuficiente (< 2.0%) — alerta não enviado.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-25_17-58-47.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "✅ Análise completa.\n",
            "💾 Carteira virtual salva em: /content/carteira_virtual.json\n",
            "❌ Erro ao enviar gráfico: 429 - {\"ok\":false,\"error_code\":429,\"description\":\"Too Many Requests: retry after 14\",\"parameters\":{\"retry_after\":14}}\n",
            "\n",
            "🧪 Últimos sinais registrados no log:\n",
            "                      Date       Asset Timeframe      Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-25 17:58:37.494236    AAVE-USD        1h 166.682205       0           158.167862          142.357361      158.167862 166.5779 165.0825 172.9517   158.167862           1.0\n",
            "2025-04-25 17:58:41.759008    NEAR-USD        1h   2.591279       1             2.667318            2.590780        2.667318   2.6290   2.6621   2.5450     2.667318           1.0\n",
            "2025-04-25 17:58:44.114027     ADA-USD        1h   0.717381       0             0.699809            0.685103        0.685103   0.7154   0.7056   0.7387     0.685103           1.0\n",
            "2025-04-25 17:58:45.856132 VIRTUAL-USD        1h   0.912932       0             0.821628            0.660385        0.821628   0.9129   0.8942   0.9630     0.821628           1.0\n",
            "2025-04-25 17:58:47.890549  PENDLE-USD        1h   3.657374       1             3.769496            3.690976        3.690976   3.7457   3.8032   3.5774     3.690976           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_models(\"/content/models\")\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def limpar_model_results():\n",
        "    arquivos = glob.glob(\"/content/model_results_*.csv\")\n",
        "    if not arquivos:\n",
        "        print(\"📂 Nenhum arquivo model_results_*.csv encontrado.\")\n",
        "        return\n",
        "\n",
        "    for arquivo in arquivos:\n",
        "        try:\n",
        "            os.remove(arquivo)\n",
        "            print(f\"🧹 Arquivo deletado: {arquivo}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao deletar {arquivo}: {e}\")\n",
        "\n",
        "    print(\"✅ Todos os arquivos model_results_*.csv foram removidos.\")\n",
        "\n",
        "limpar_model_results()\n",
        "def limpar_prediction_log(path=\"prediction_log.csv\"):\n",
        "    if not os.path.exists(path):\n",
        "        print(\"⚠️ Arquivo de log não encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.dropna(subset=[\"Date\"])\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "    df = df[df[\"Date\"].dt.year >= 2000]\n",
        "    df.to_csv(path, index=False)\n",
        "    print(\"✅ Log limpo com sucesso. Entradas de 1970 removidas!\")\n",
        "\n",
        "limpar_prediction_log()\n",
        "import os\n",
        "os.remove(\"/content/prediction_log.csv\")\n",
        "import os\n",
        "if os.path.exists(\"prediction_log.csv\"):\n",
        "    os.remove(\"prediction_log.csv\")\n",
        "    print(\"🧹 Carteira virtual resetada com sucesso.\")"
      ],
      "metadata": {
        "id": "ctphA5Oq6AQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/prediction_log.csv\n",
        "!rm -f /content/model_results_*.csv\n"
      ],
      "metadata": {
        "id": "-TAnU-WJ730p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}