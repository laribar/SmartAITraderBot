{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laribar/SmartAITraderBot/blob/main/Bot_Funcional_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB9bgc2g7glZ",
        "outputId": "cefcdfce-17b5-423d-80b6-f51781299d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Collecting python-binance\n",
            "  Downloading python_binance-1.0.28-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-binance) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from python-binance) (1.17.0)\n",
            "Collecting dateparser (from python-binance)\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from python-binance) (3.11.14)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from python-binance) (15.0.1)\n",
            "Collecting pycryptodome (from python-binance)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2025.1.31)\n",
            "Downloading python_binance-1.0.28-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome, dateparser, python-binance\n",
            "Successfully installed dateparser-1.2.1 pycryptodome-3.22.0 python-binance-1.0.28\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "!pip install yfinance\n",
        "!pip install xgboost\n",
        "!pip install python-binance\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 1. IMPORTAÇÕES\n",
        "# ====================================================\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ta\n",
        "import requests\n",
        "import time  # Para usar time.sleep()\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=4,                 # menor profundidade = menos overfitting\n",
        "    subsample=0.8,               # usa 80% dos dados por árvore\n",
        "    colsample_bytree=0.8,        # usa 80% das features por árvore\n",
        "    learning_rate=0.05,          # suaviza o aprendizado\n",
        "    early_stopping_rounds=10,    # para de treinar se não melhorar\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# ====================================================\n",
        "# BLOCO 1 - CONFIGURAÇÃO DE PASTAS E IMPORTS EXTRA\n",
        "# ====================================================\n",
        "import os\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Criar pasta onde os modelos serão salvos\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "# ====================================================\n",
        "# BLOCO 2 - SALVAR E CARREGAR MODELOS TREINADOS\n",
        "# ====================================================\n",
        "def get_model_path(asset, interval, model_type=\"xgb\"):\n",
        "    asset_clean = asset.replace(\"-\", \"\")\n",
        "    ext = \"joblib\" if model_type == \"xgb\" else \"h5\"\n",
        "    return f\"/content/models/{model_type}_model_{asset_clean}_{interval}.{ext}\"\n",
        "\n",
        "# --- XGBoost ---\n",
        "def save_xgb_model(model, asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "    joblib.dump(model, path)\n",
        "    print(f\"💾 Modelo XGBoost salvo em: {path}\")\n",
        "\n",
        "def load_xgb_model(asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "    if os.path.exists(path):\n",
        "        print(f\"📂 Modelo XGBoost carregado de: {path}\")\n",
        "        return joblib.load(path)\n",
        "    return None\n",
        "\n",
        "# --- LSTM ---\n",
        "def save_lstm_model(model, asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "    model.save(path)\n",
        "    print(f\"💾 Modelo LSTM salvo em: {path}\")\n",
        "\n",
        "def load_lstm_model(asset, interval, data=None, window_size=20):\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "    if os.path.exists(path):\n",
        "        print(f\"📂 Modelo LSTM encontrado em: {path}\")\n",
        "        try:\n",
        "            model = load_model(path)\n",
        "            print(f\"✅ Modelo LSTM carregado com sucesso para {asset} ({interval})\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Falha ao carregar modelo LSTM: {e}\")\n",
        "            return None\n",
        "\n",
        "        model.window_size = window_size\n",
        "\n",
        "        if data is not None:\n",
        "            try:\n",
        "                _, _, scaler = prepare_lstm_data(data, window_size=window_size)\n",
        "                model.scaler = scaler\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Erro ao aplicar scaler ao LSTM carregado: {e}\")\n",
        "                model.scaler = None\n",
        "        else:\n",
        "            print(\"⚠️ Atenção: LSTM carregado sem dados para gerar o scaler!\")\n",
        "            model.scaler = None\n",
        "\n",
        "        return model\n",
        "    else:\n",
        "        print(f\"🚫 Modelo LSTM NÃO encontrado em: {path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 2. CONFIGURAÇÕES\n",
        "# ====================================================\n",
        "ASSETS = [\"BTC-USD\"] #, \"ETH-USD\", \"BNB-USD\", \"SOL-USD\", \"XRP-USD\", \"AVAX-USD\", \"AAVE-USD\", \"DOT-USD\", \"NEAR-USD\", \"ADA-USD\"\n",
        "\n",
        "\n",
        "TIMEFRAMES = [\n",
        "    {\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02},\n",
        "    {\"interval\": \"1h\", \"period\": \"90d\", \"atr\": 0.03},\n",
        "    {\"interval\": \"1d\", \"period\": \"1000d\", \"atr\": 0.05}\n",
        "]\n",
        "\n",
        "TELEGRAM_TOKEN = \"8044593190:AAFtUWYHd3uqd-AtQi3uqg42F9G6uV95v8k\"\n",
        "TELEGRAM_CHAT_ID = \"-4744645054\"\n",
        "\n",
        "# ====================================================\n",
        "# 3. COLETA DE DADOS\n",
        "# ====================================================\n",
        "def get_stock_data(asset, interval=\"15m\", period=\"700d\"):\n",
        "    data = yf.download(asset, period=period, interval=interval, progress=False, auto_adjust=False)\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        data.columns = data.columns.get_level_values(0)\n",
        "    data.columns = [col.split()[-1] if \" \" in col else col for col in data.columns]\n",
        "    data = data.loc[:, ~data.columns.duplicated()]\n",
        "    col_map = {col: std_col for col in data.columns for std_col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"] if std_col.lower() in col.lower()}\n",
        "    data = data.rename(columns=col_map)\n",
        "    data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    if not all(col in data.columns for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]):\n",
        "        raise ValueError(f\"⚠️ Dados de {asset} não possuem todas as colunas necessárias.\")\n",
        "    return data\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 4. INDICADORES TÉCNICOS\n",
        "# ====================================================\n",
        "def calculate_indicators(data):\n",
        "    data = data.copy().reset_index(drop=True)\n",
        "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
        "        data[col] = data[col].astype(float)\n",
        "\n",
        "    # Indicadores Clássicos\n",
        "    data[\"RSI\"] = ta.momentum.RSIIndicator(close=data[\"Close\"], window=14).rsi()\n",
        "    data[\"SMA_50\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=50).sma_indicator()\n",
        "    data[\"SMA_200\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=200).sma_indicator()\n",
        "\n",
        "    macd = ta.trend.MACD(close=data[\"Close\"])\n",
        "    data[\"MACD\"] = macd.macd()\n",
        "    data[\"MACD_Signal\"] = macd.macd_signal()\n",
        "\n",
        "    bb = ta.volatility.BollingerBands(close=data[\"Close\"], window=20)\n",
        "    data[\"Bollinger_Upper\"] = bb.bollinger_hband()\n",
        "    data[\"Bollinger_Lower\"] = bb.bollinger_lband()\n",
        "\n",
        "    adx = ta.trend.ADXIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"ADX\"] = adx.adx()\n",
        "\n",
        "    stoch = ta.momentum.StochasticOscillator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"Stoch_K\"] = stoch.stoch()\n",
        "    data[\"Stoch_D\"] = stoch.stoch_signal()\n",
        "\n",
        "    # Indicadores adicionais\n",
        "    data[\"ATR\"] = ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"]).average_true_range()\n",
        "    data[\"ROC\"] = ta.momentum.ROCIndicator(close=data[\"Close\"], window=12).roc()\n",
        "    data[\"OBV\"] = ta.volume.OnBalanceVolumeIndicator(close=data[\"Close\"], volume=data[\"Volume\"]).on_balance_volume()\n",
        "    data[\"CCI\"] = ta.trend.CCIIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=20).cci()\n",
        "\n",
        "    ichimoku = ta.trend.IchimokuIndicator(high=data[\"High\"], low=data[\"Low\"], window1=9, window2=26)\n",
        "    data[\"Tenkan_Sen\"] = ichimoku.ichimoku_conversion_line()\n",
        "    data[\"Kijun_Sen\"] = ichimoku.ichimoku_base_line()\n",
        "\n",
        "    # VWAP e Candles\n",
        "    data[\"TP\"] = (data[\"High\"] + data[\"Low\"] + data[\"Close\"]) / 3\n",
        "    data[\"VWAP\"] = (data[\"TP\"] * data[\"Volume\"]).cumsum() / (data[\"Volume\"].replace(0, np.nan).cumsum())\n",
        "    data.drop(\"TP\", axis=1, inplace=True)\n",
        "\n",
        "    data[\"Doji\"] = ((abs(data[\"Close\"] - data[\"Open\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9)) < 0.1).astype(int)\n",
        "    data[\"Engulfing\"] = ((data[\"Open\"].shift(1) > data[\"Close\"].shift(1)) & (data[\"Open\"] < data[\"Close\"]) &\n",
        "                         (data[\"Close\"] > data[\"Open\"].shift(1)) & (data[\"Open\"] < data[\"Close\"].shift(1))).astype(int)\n",
        "    data[\"Hammer\"] = (((data[\"High\"] - data[\"Low\"]) > 3 * abs(data[\"Open\"] - data[\"Close\"])) &\n",
        "                      ((data[\"Close\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6) &\n",
        "                      ((data[\"Open\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6)).astype(int)\n",
        "\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 4. MODELOS DE MACHINE LEARNING (XGBoost + LSTM)\n",
        "# ====================================================\n",
        "\n",
        "def get_feature_columns():\n",
        "    return [\n",
        "        \"RSI\", \"MACD\", \"MACD_Signal\", \"SMA_50\", \"SMA_200\", \"Bollinger_Upper\",\n",
        "        \"Bollinger_Lower\", \"ADX\", \"Stoch_K\", \"Stoch_D\", \"ATR\", \"ROC\", \"OBV\", \"CCI\",\n",
        "        \"Tenkan_Sen\", \"Kijun_Sen\", \"VWAP\", \"Doji\", \"Engulfing\", \"Hammer\", \"LSTM_PRED\"\n",
        "    ]\n",
        "\n",
        "\n",
        "def prepare_lstm_data(data, feature_col=\"Close\", window_size=20):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    values = df[feature_col].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled = scaler.fit_transform(values)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(scaled)):\n",
        "        X.append(scaled[i - window_size:i, 0])\n",
        "        y.append(scaled[i, 0])\n",
        "\n",
        "    X, y = np.array(X), np.array(y)\n",
        "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "    return X, y, scaler\n",
        "\n",
        "def train_lstm_model(data, asset=None, interval=None, window_size=20, verbose=False, force_retrain=False):\n",
        "    if asset and interval and not force_retrain:\n",
        "        model = load_lstm_model(asset, interval, data=data, window_size=window_size)\n",
        "        if model is not None:\n",
        "            print(f\"✅ LSTM carregado para {asset} ({interval})\")\n",
        "            return model  # ⚠️ Modelo já salvo, não treina novamente\n",
        "\n",
        "    if len(data) < window_size + 20:\n",
        "        print(f\"⚠️ Dados insuficientes para treinar LSTM em {asset} ({interval})\")\n",
        "        return None\n",
        "\n",
        "    print(f\"🚀 Treinando LSTM para {asset} ({interval})...\")\n",
        "\n",
        "    X, y, scaler = prepare_lstm_data(data, window_size=window_size)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(units=50))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    model.fit(X, y, epochs=10, batch_size=32, verbose=0 if not verbose else 1)\n",
        "\n",
        "    model.scaler = scaler\n",
        "    model.window_size = window_size\n",
        "\n",
        "    if asset and interval:\n",
        "        save_lstm_model(model, asset, interval)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_with_lstm(model, data, use_dynamic_calibration=True):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    values = df[\"Close\"].values.reshape(-1, 1)\n",
        "\n",
        "    if not hasattr(model, \"scaler\") or model.scaler is None:\n",
        "        raise ValueError(\"❌ LSTM carregado sem scaler.\")\n",
        "\n",
        "    scaled = model.scaler.transform(values)\n",
        "    last_sequence = scaled[-model.window_size:]\n",
        "    X_pred = np.reshape(last_sequence, (1, model.window_size, 1))\n",
        "    predicted_scaled = model.predict(X_pred)[0][0]\n",
        "    predicted_price = model.scaler.inverse_transform([[predicted_scaled]])[0][0]\n",
        "\n",
        "    # 🔁 Ajuste dinâmico com base no histórico (se ativado)\n",
        "    if use_dynamic_calibration:\n",
        "        try:\n",
        "            df_log = pd.read_csv(\"/content/prediction_log.csv\")\n",
        "            df_log = df_log.dropna(subset=[\"TargetPrice\", \"Price\"])\n",
        "            df_log[\"Erro\"] = df_log[\"Price\"] - df_log[\"TargetPrice\"]\n",
        "            if len(df_log) >= 10:  # só aplica se tiver histórico suficiente\n",
        "                calibration_factor = 1 - (df_log[\"Erro\"].mean() / df_log[\"TargetPrice\"].mean())\n",
        "                predicted_price *= calibration_factor\n",
        "                print(f\"🔧 Calibração dinâmica aplicada: fator {calibration_factor:.5f}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro ao aplicar calibração dinâmica: {e}\")\n",
        "\n",
        "    return round(predicted_price, 2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_ml_model(data, asset=None, interval=None, verbose=False):\n",
        "    # ✅ Verifica se modelo já existe\n",
        "    if asset and interval:\n",
        "        existing_model = load_xgb_model(asset, interval)\n",
        "        if existing_model is not None:\n",
        "            print(f\"✅ Modelo XGBoost já existente para {asset} ({interval}), carregado.\")\n",
        "            return existing_model\n",
        "\n",
        "    if len(data) < 100:\n",
        "        return None\n",
        "\n",
        "    df = data.copy()\n",
        "\n",
        "    # ✅ Tenta carregar LSTM salvo (sem forçar re-treino)\n",
        "    try:\n",
        "        lstm_model = train_lstm_model(data, asset=asset, interval=interval, force_retrain=False)\n",
        "        lstm_preds = []\n",
        "        for i in range(len(df)):\n",
        "            sub_df = df.iloc[:i+1]\n",
        "            if len(sub_df) < 20:\n",
        "                lstm_preds.append(np.nan)\n",
        "            else:\n",
        "                pred = predict_with_lstm(lstm_model, sub_df)\n",
        "                lstm_preds.append(pred)\n",
        "        df[\"LSTM_PRED\"] = lstm_preds\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao gerar LSTM_PRED: {e}\")\n",
        "        df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "    # Geração do alvo\n",
        "    df[\"Future_Close\"] = df[\"Close\"].shift(-5)\n",
        "    df[\"Future_Return\"] = df[\"Future_Close\"] / df[\"Close\"] - 1\n",
        "    df = df[(df[\"Future_Return\"] > 0.015) | (df[\"Future_Return\"] < -0.015)].copy()\n",
        "    df[\"Signal\"] = np.where(df[\"Future_Return\"] > 0.015, 1, 0)\n",
        "\n",
        "    features = get_feature_columns()\n",
        "    df.dropna(inplace=True)\n",
        "    X = df[features]\n",
        "    y = df[\"Signal\"]\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        return None\n",
        "\n",
        "    # ✅ Validação com TimeSeriesSplit (primeira divisão)\n",
        "    from sklearn.model_selection import TimeSeriesSplit\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    for train_index, val_index in tscv.split(X):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "        break\n",
        "\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        return None\n",
        "\n",
        "    # Ajuste de peso de classe (para desbalanceamento)\n",
        "    scale_pos_weight = len(y_train[y_train == 0]) / max(1, len(y_train[y_train == 1]))\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "    model.validation_score = {\n",
        "        \"accuracy\": report.get(\"accuracy\"),\n",
        "        \"precision\": report.get(\"1\", {}).get(\"precision\"),\n",
        "        \"recall\": report.get(\"1\", {}).get(\"recall\"),\n",
        "        \"f1\": report.get(\"1\", {}).get(\"f1-score\")\n",
        "    }\n",
        "\n",
        "    if asset and interval:\n",
        "        save_xgb_model(model, asset, interval)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def plot_feature_importance(model, feature_names, top_n=15):\n",
        "    import matplotlib.pyplot as plt\n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)[-top_n:]  # top_n mais importantes\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel(\"Importância\")\n",
        "    plt.title(\"🎯 Importância das Features - XGBoost\")\n",
        "    plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 5. UTILITÁRIOS\n",
        "# ====================================================\n",
        "\n",
        "def generate_explanation(row, prediction):\n",
        "    explanation = []\n",
        "    if prediction == 1:\n",
        "        explanation.append(\"🟢 O modelo prevê uma tendência de ALTA.\")\n",
        "    elif prediction == 0:\n",
        "        explanation.append(\"🔴 O modelo prevê uma tendência de BAIXA.\")\n",
        "    else:\n",
        "        explanation.append(\"⚪ Sinal neutro.\")\n",
        "\n",
        "    if row[\"RSI\"] < 30:\n",
        "        explanation.append(\"🔽 RSI abaixo de 30 indica sobrevenda.\")\n",
        "    elif row[\"RSI\"] > 70:\n",
        "        explanation.append(\"🔼 RSI acima de 70 indica sobrecompra.\")\n",
        "\n",
        "    if row[\"SMA_50\"] > row[\"SMA_200\"]:\n",
        "        explanation.append(\"📈 SMA 50 acima da 200, tendência de alta.\")\n",
        "    else:\n",
        "        explanation.append(\"📉 SMA 50 abaixo da 200, tendência de baixa.\")\n",
        "\n",
        "    if row[\"MACD\"] > row[\"MACD_Signal\"]:\n",
        "        explanation.append(\"💹 MACD cruzando para cima, possível reversão positiva.\")\n",
        "    else:\n",
        "        explanation.append(\"🔻 MACD abaixo da linha de sinal.\")\n",
        "\n",
        "    if row[\"Doji\"] == 1:\n",
        "        explanation.append(\"⚠️ Padrão de candle Doji detectado (possível reversão).\")\n",
        "\n",
        "    if row[\"Engulfing\"] == 1:\n",
        "        explanation.append(\"📊 Padrão de engolfo detectado (sinal forte de reversão).\")\n",
        "\n",
        "    return \"\\n\".join(explanation)\n",
        "\n",
        "def calculate_targets(current_price, direction, atr=0.02):\n",
        "    if direction == 1:\n",
        "        return {\n",
        "            \"TP1\": round(current_price * (1 + atr * 0.5), 2),\n",
        "            \"TP2\": round(current_price * (1 + atr * 1.0), 2),\n",
        "            \"SL\": round(current_price * (1 - atr * 0.5), 2)\n",
        "        }\n",
        "    elif direction == 0:\n",
        "        return {\n",
        "            \"TP1\": round(current_price * (1 - atr * 0.5), 2),\n",
        "            \"TP2\": round(current_price * (1 - atr * 1.0), 2),\n",
        "            \"SL\": round(current_price * (1 + atr * 0.5), 2)\n",
        "        }\n",
        "    else:\n",
        "        return {\"TP1\": None, \"TP2\": None, \"SL\": None}\n",
        "\n",
        "def send_telegram_message(message):\n",
        "    url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "    payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"HTML\"}\n",
        "    response = requests.post(url, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"📨 Mensagem enviada com sucesso!\")\n",
        "    else:\n",
        "        print(f\"❌ Erro ao enviar mensagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "def predict_next_closes(data, n_steps=5):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    features = get_feature_columns()\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[\"Close\"].shift(-1).dropna()\n",
        "    X = X.loc[y.index]\n",
        "\n",
        "    if len(X) < 100:\n",
        "        return [None] * n_steps\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    last_row = df[features].iloc[-1].copy()\n",
        "    preds = []\n",
        "\n",
        "    for step in range(n_steps):\n",
        "        X_input = pd.DataFrame([last_row], columns=features)\n",
        "        next_close = model.predict(X_input)[0]\n",
        "        preds.append(round(next_close, 2))\n",
        "\n",
        "        # Simula avanço do mercado\n",
        "        last_row[\"Close\"] = next_close\n",
        "        if \"SMA_50\" in last_row:\n",
        "            last_row[\"SMA_50\"] = last_row[\"SMA_50\"] * 0.9 + next_close * 0.1\n",
        "        if \"SMA_200\" in last_row:\n",
        "            last_row[\"SMA_200\"] = last_row[\"SMA_200\"] * 0.95 + next_close * 0.05\n",
        "        if \"VWAP\" in last_row:\n",
        "            last_row[\"VWAP\"] = last_row[\"VWAP\"] * 0.95 + next_close * 0.05\n",
        "        if \"RSI\" in last_row:\n",
        "            last_row[\"RSI\"] = min(100, max(0, last_row[\"RSI\"] + np.random.normal(0, 0.5)))\n",
        "        if \"MACD\" in last_row:\n",
        "            last_row[\"MACD\"] += np.random.normal(0, 0.3)\n",
        "        if \"MACD_Signal\" in last_row:\n",
        "            last_row[\"MACD_Signal\"] += np.random.normal(0, 0.2)\n",
        "\n",
        "        last_row = last_row[features]\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def evaluate_past_predictions(results_file=\"/content/prediction_log.csv\", lookahead_candles=5):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import yfinance as yf\n",
        "    import matplotlib.pyplot as plt\n",
        "    from datetime import timedelta\n",
        "\n",
        "    if not os.path.exists(results_file):\n",
        "        print(\"📭 Nenhum log de previsão encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(results_file)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "    print(f\"📊 Avaliando {len(df)} previsões salvas...\")\n",
        "\n",
        "    evaluation = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        asset = row[\"Asset\"]\n",
        "        interval = row[\"Timeframe\"]\n",
        "        prediction_time = row[\"Date\"]\n",
        "        predicted_signal = row[\"Signal\"]\n",
        "        predicted_target = row.get(\"TargetPrice\", None)\n",
        "\n",
        "        try:\n",
        "            candles = yf.download(asset, start=prediction_time, interval=interval, progress=False)\n",
        "            candles = candles[candles.index > prediction_time]\n",
        "\n",
        "            if candles.empty or len(candles) < lookahead_candles:\n",
        "                continue\n",
        "\n",
        "            candles = candles.head(lookahead_candles)\n",
        "            final_close = candles[\"Close\"].iloc[-1]\n",
        "\n",
        "            if predicted_signal == 1:\n",
        "                result = \"Acertou\" if final_close >= predicted_target else \"Errou\"\n",
        "            elif predicted_signal == 0:\n",
        "                result = \"Acertou\" if final_close <= predicted_target else \"Errou\"\n",
        "            else:\n",
        "                result = \"Neutro\"\n",
        "\n",
        "            if predicted_target:\n",
        "                perc_change = ((final_close - predicted_target) / predicted_target) * 100\n",
        "                abs_error = final_close - predicted_target\n",
        "            else:\n",
        "                perc_change = None\n",
        "                abs_error = None\n",
        "\n",
        "            acertou = 1 if result == \"Acertou\" else 0\n",
        "\n",
        "            evaluation.append({\n",
        "                \"Ativo\": asset,\n",
        "                \"Timeframe\": interval,\n",
        "                \"Data Previsão\": prediction_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
        "                \"Sinal Previsto\": \"Compra\" if predicted_signal == 1 else \"Venda\" if predicted_signal == 0 else \"Neutro\",\n",
        "                \"Valor Projetado (LSTM)\": round(predicted_target, 2) if predicted_target else None,\n",
        "                \"Resultado\": result,\n",
        "                \"Valor Real\": round(final_close, 2),\n",
        "                \"Variação Real\": f\"{perc_change:+.2f}%\" if perc_change is not None else \"N/A\",\n",
        "                \"Erro Absoluto\": f\"{abs_error:+.2f}\" if abs_error is not None else \"N/A\",\n",
        "                \"Acertou\": acertou\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Erro ao avaliar {asset} em {prediction_time}: {e}\")\n",
        "            continue\n",
        "\n",
        "    df_eval = pd.DataFrame(evaluation)\n",
        "\n",
        "    # 📊 Resumo de acertos e erros\n",
        "    resumo = df_eval.groupby([\"Ativo\", \"Timeframe\", \"Resultado\"]).size().unstack(fill_value=0)\n",
        "    resumo[\"Total\"] = resumo.sum(axis=1)\n",
        "    resumo[\"Acurácia (%)\"] = (resumo.get(\"Acertou\", 0) / resumo[\"Total\"] * 100).round(2)\n",
        "    display(resumo)\n",
        "\n",
        "    # 📈 Gráfico de barras\n",
        "    resumo_plot = resumo[[\"Acertou\", \"Errou\"]] if \"Errou\" in resumo.columns else resumo[[\"Acertou\"]]\n",
        "    resumo_plot.plot(kind=\"bar\", figsize=(10, 5), title=\"📊 Acertos vs Erros por Ativo e Timeframe\")\n",
        "    plt.ylabel(\"Quantidade de Sinais\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis=\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 📄 Tabela completa das previsões\n",
        "    display(df_eval)\n",
        "\n",
        "    # 🔄 Atualizar o prediction_log.csv com a coluna 'Acertou'\n",
        "    try:\n",
        "        df_log = pd.read_csv(results_file)\n",
        "        df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"])\n",
        "\n",
        "        for _, row in df_eval.iterrows():\n",
        "            dt = pd.to_datetime(row[\"Data Previsão\"])\n",
        "            mask = (df_log[\"Date\"] == dt) & (df_log[\"Asset\"] == row[\"Ativo\"]) & (df_log[\"Timeframe\"] == row[\"Timeframe\"])\n",
        "            df_log.loc[mask, \"Acertou\"] = row[\"Acertou\"]\n",
        "\n",
        "        df_log.to_csv(results_file, index=False)\n",
        "        print(\"✅ Log de previsões atualizado com coluna 'Acertou'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao atualizar o prediction_log.csv com 'Acertou': {e}\")\n",
        "\n",
        "    return df_eval\n",
        "\n",
        "\n",
        "\n",
        "def clear_models(model_dir=\"/content/models\"):\n",
        "    import shutil\n",
        "\n",
        "    if os.path.exists(model_dir):\n",
        "        print(f\"🧹 Limpando todos os modelos salvos em: {model_dir}\")\n",
        "        shutil.rmtree(model_dir)\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        print(\"✅ Modelos deletados com sucesso.\")\n",
        "    else:\n",
        "        print(\"📂 Nenhuma pasta de modelos encontrada para limpar.\")\n",
        "\n",
        "\n",
        "def plot_prediction_performance(log_path=\"/content/prediction_log.csv\"):\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "    from datetime import timedelta\n",
        "    import os\n",
        "\n",
        "    if not os.path.exists(log_path):\n",
        "        print(\"📭 Nenhum log encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(log_path)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "    # Apenas linhas com TargetPrice válido\n",
        "    df = df.dropna(subset=[\"TargetPrice\"])\n",
        "    df[\"Erro\"] = df[\"Price\"] - df[\"TargetPrice\"]\n",
        "    df[\"AbsError\"] = abs(df[\"Erro\"])\n",
        "    df[\"Dia\"] = df[\"Date\"].dt.date\n",
        "\n",
        "    print(f\"📊 Total de previsões com valor previsto: {len(df)}\")\n",
        "\n",
        "    # 🔹 Erro absoluto médio por dia\n",
        "    df_grouped = df.groupby(\"Dia\")[\"AbsError\"].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(df_grouped.index, df_grouped.values, marker=\"o\")\n",
        "    plt.title(\"📈 Erro Absoluto Médio por Dia\")\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Erro ($)\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 🔹 Dispersão do valor previsto x real\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.scatter(df[\"TargetPrice\"], df[\"Price\"], alpha=0.6)\n",
        "    plt.plot([df[\"TargetPrice\"].min(), df[\"TargetPrice\"].max()],\n",
        "             [df[\"TargetPrice\"].min(), df[\"TargetPrice\"].max()], 'r--', label=\"Perfeito\")\n",
        "    plt.title(\"🎯 Valor Previsto (LSTM) vs Real\")\n",
        "    plt.xlabel(\"Valor Previsto\")\n",
        "    plt.ylabel(\"Valor Real\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 🔹 Distribuição de erro\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    df[\"Erro\"].hist(bins=30)\n",
        "    plt.title(\"📊 Distribuição dos Erros\")\n",
        "    plt.xlabel(\"Erro (Preço Real - Previsto)\")\n",
        "    plt.ylabel(\"Frequência\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def enviar_grafico_lucro_por_confianca(log_path=\"/content/prediction_log.csv\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if not os.path.exists(log_path):\n",
        "        print(\"📭 Nenhum log encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(log_path)\n",
        "    if \"AdjustedProb\" not in df.columns or \"TP1\" not in df.columns or \"Price\" not in df.columns:\n",
        "        print(\"⚠️ Colunas necessárias não encontradas no log.\")\n",
        "        return\n",
        "\n",
        "    df = df.dropna(subset=[\"AdjustedProb\", \"TP1\", \"Price\"])\n",
        "    df[\"LucroEstimado\"] = df[\"TP1\"] - df[\"Price\"]\n",
        "    df[\"FaixaConfiança\"] = pd.cut(df[\"AdjustedProb\"], bins=[0, 0.6, 0.7, 0.8, 0.9, 1.0], labels=[\"≤60%\", \"60-70%\", \"70-80%\", \"80-90%\", \">90%\"])\n",
        "\n",
        "    lucro_medio = df.groupby(\"FaixaConfiança\")[\"LucroEstimado\"].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    lucro_medio.plot(kind=\"bar\", color=\"skyblue\")\n",
        "    plt.title(\"📊 Lucro Estimado Médio por Faixa de Confiança\")\n",
        "    plt.ylabel(\"Lucro Estimado ($)\")\n",
        "    plt.xlabel(\"Faixa de Confiança Ajustada\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = \"/tmp/lucro_por_confianca.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "    with open(path, \"rb\") as img:\n",
        "        url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "        files = {\"photo\": img}\n",
        "        data = {\n",
        "            \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "            \"caption\": \"📊 Lucro médio estimado por faixa de confiança ajustada\"\n",
        "        }\n",
        "        response = requests.post(url, data=data, files=files)\n",
        "        if response.status_code == 200:\n",
        "            print(\"✅ Gráfico de lucro por confiança enviado.\")\n",
        "        else:\n",
        "            print(f\"❌ Falha ao enviar gráfico: {response.status_code} - {response.text}\")\n",
        "\n",
        "def adjust_signal_based_on_history(asset, timeframe, max_lookback=20, min_signals=5):\n",
        "    try:\n",
        "        df = pd.read_csv(\"prediction_log.csv\")\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        df = df[(df[\"Asset\"] == asset) & (df[\"Timeframe\"] == timeframe)]\n",
        "\n",
        "        if len(df) < min_signals or \"Acertou\" not in df.columns:\n",
        "            return 1.0  # Sem histórico confiável, mantém 100% do sinal original\n",
        "\n",
        "        recent = df.sort_values(\"Date\", ascending=False).head(max_lookback)\n",
        "        acuracia = recent[\"Acertou\"].mean()\n",
        "        return acuracia  # Ex: 0.6 = 60% de confiança histórica recente\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao ajustar com histórico: {e}\")\n",
        "        return 1.0\n",
        "\n",
        "\n",
        "def enviar_grafico_carteira():\n",
        "    image_path = \"/tmp/evolucao_carteira.png\"\n",
        "    if os.path.exists(image_path):\n",
        "        with open(image_path, \"rb\") as img:\n",
        "            url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "            files = {\"photo\": img}\n",
        "            data = {\n",
        "                \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                \"caption\": \"💼 Evolução da carteira virtual com base nos sinais do bot\"\n",
        "            }\n",
        "            response = requests.post(url, data=data, files=files)\n",
        "            if response.status_code == 200:\n",
        "                print(\"✅ Gráfico da carteira enviado ao Telegram.\")\n",
        "            else:\n",
        "                print(f\"❌ Erro ao enviar imagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 5.1 CARTEIRA VIRTUAL PARA SIMULAÇÃO\n",
        "# ====================================================\n",
        "# ====================================================\n",
        "# 5.1 CARTEIRA VIRTUAL PARA SIMULAÇÃO\n",
        "# ====================================================\n",
        "\n",
        "carteira_virtual = {\n",
        "    \"capital_inicial\": 10000.0,\n",
        "    \"capital_atual\": 10000.0,\n",
        "    \"em_operacao\": False,\n",
        "    \"ativo\": None,\n",
        "    \"entrada\": 0.0,\n",
        "    \"quantidade\": 0.0,\n",
        "    \"tipo\": None,\n",
        "    \"data_entrada\": None\n",
        "}\n",
        "\n",
        "def simular_trade(row, lookahead_candles=5, taxa=0.001, slippage=0.002):\n",
        "    import yfinance as yf\n",
        "\n",
        "    print(\"\\n🚨 Entrando na função simular_trade()\")\n",
        "    print(f\"🔍 Linha completa:\\n{row}\\n\")\n",
        "\n",
        "    if not isinstance(row, pd.Series):\n",
        "        print(\"⚠️ Linha recebida não é Series, foi:\", type(row))\n",
        "        return None\n",
        "\n",
        "    if pd.isna(row[\"Date\"]):\n",
        "        print(\"⚠️ Entrada ignorada por data inválida:\", row[\"Date\"])\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        data_entrada = pd.to_datetime(row[\"Date\"])\n",
        "        if data_entrada.tzinfo is not None:\n",
        "            data_entrada = data_entrada.tz_localize(None)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao converter data: {e}\")\n",
        "        return None\n",
        "\n",
        "    asset = row[\"Asset\"]\n",
        "    interval = row[\"Timeframe\"]\n",
        "\n",
        "    try:\n",
        "        # Conversão segura usando to_scalar universal\n",
        "        entrada = to_scalar(row[\"Price\"])\n",
        "        tp1 = to_scalar(row[\"TP1\"])\n",
        "        sl = to_scalar(row[\"SL\"])\n",
        "        signal = int(to_scalar(row[\"Signal\"]))\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro ao converter valores numéricos: {e}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"📌 entrada: {entrada} ({type(entrada)})\")\n",
        "    print(f\"📌 TP1: {tp1} ({type(tp1)})\")\n",
        "    print(f\"📌 SL: {sl} ({type(sl)})\")\n",
        "    print(f\"📌 Signal: {signal} ({type(signal)})\")\n",
        "\n",
        "    try:\n",
        "        df_future = yf.download(asset, interval=interval, start=data_entrada, progress=False)\n",
        "\n",
        "        df_future.index = pd.to_datetime(df_future.index)\n",
        "        if df_future.index.tz is not None:\n",
        "            df_future.index = df_future.index.tz_localize(None)\n",
        "\n",
        "        df_future = df_future[df_future.index > data_entrada].head(lookahead_candles)\n",
        "\n",
        "        # 🔧 Garantir colunas limpas\n",
        "        df_future = df_future.copy()\n",
        "        df_future = df_future.loc[:, ~df_future.columns.duplicated()]\n",
        "        df_future.columns = [str(col) for col in df_future.columns]\n",
        "\n",
        "        if df_future.empty:\n",
        "            print(f\"⚠️ Sem candles futuros para {asset} em {interval}\")\n",
        "            return None\n",
        "\n",
        "        saida = None\n",
        "        resultado = \"Indefinido\"\n",
        "        def to_scalar(val):\n",
        "            try:\n",
        "                if isinstance(val, pd.Series):\n",
        "                    return float(val.iloc[0])\n",
        "                elif isinstance(val, (np.ndarray, list)):\n",
        "                    return float(val[0])\n",
        "                else:\n",
        "                    return float(val)\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Falha ao converter valor escalar: {val} | erro: {e}\")\n",
        "            return np.nan\n",
        "        for _, candle in df_future.iterrows():\n",
        "            try:\n",
        "                preco_max = to_scalar(candle.get(\"High\"))\n",
        "                preco_min = to_scalar(candle.get(\"Low\"))\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro ao extrair preços: {e}\\nHigh={candle['High']} | Low={candle['Low']}\")\n",
        "                continue\n",
        "\n",
        "            print(f\"🧪 Comparando: preco_max={preco_max}, preco_min={preco_min}, tp1={tp1}, sl={sl}\")\n",
        "\n",
        "            if any(pd.isna(x) for x in [preco_max, preco_min, tp1, sl]):\n",
        "                print(\"⚠️ Valores nulos detectados — ignorando candle.\")\n",
        "                continue\n",
        "            print(f\"🔍 Tipos: High={type(preco_max)}, Low={type(preco_min)}, valores: {preco_max}, {preco_min}\")\n",
        "\n",
        "            if signal == 1:\n",
        "                if preco_max >= tp1:\n",
        "                    saida = tp1\n",
        "                    resultado = \"TP1\"\n",
        "                    break\n",
        "                elif preco_min <= sl:\n",
        "                    saida = sl\n",
        "                    resultado = \"SL\"\n",
        "                    break\n",
        "            elif signal == 0:\n",
        "                if preco_min <= tp1:\n",
        "                    saida = tp1\n",
        "                    resultado = \"TP1\"\n",
        "                    break\n",
        "                elif preco_max >= sl:\n",
        "                    saida = sl\n",
        "                    resultado = \"SL\"\n",
        "                    break\n",
        "\n",
        "        if saida is None:\n",
        "            saida = df_future[\"Close\"].iloc[-1]\n",
        "            resultado = \"Sem alvo\"\n",
        "\n",
        "        entrada_real = entrada * (1 + taxa + slippage)\n",
        "        saida_real = saida * (1 - taxa - slippage)\n",
        "        quantidade = carteira_virtual[\"capital_atual\"] / entrada_real\n",
        "\n",
        "        if any(pd.isna(x) for x in [saida_real, entrada_real, quantidade]):\n",
        "            print(\"⚠️ Valores inválidos detectados — trade ignorado.\")\n",
        "            return None\n",
        "\n",
        "        lucro = (saida_real - entrada_real) * quantidade if signal == 1 else (entrada_real - saida_real) * quantidade\n",
        "        carteira_virtual[\"capital_atual\"] += lucro\n",
        "\n",
        "        return {\n",
        "            \"Ativo\": asset,\n",
        "            \"Timeframe\": interval,\n",
        "            \"Data Entrada\": data_entrada.strftime(\"%Y-%m-%d %H:%M\"),\n",
        "            \"Entrada\": round(entrada_real, 2),\n",
        "            \"Saída\": round(saida_real, 2),\n",
        "            \"Resultado\": resultado,\n",
        "            \"Lucro ($)\": round(lucro, 2),\n",
        "            \"Capital Atual\": round(carteira_virtual[\"capital_atual\"], 2)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Erro inesperado na simulação: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def simular_todos_trades(path_log=\"prediction_log.csv\"):\n",
        "    import os\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    if not os.path.exists(path_log):\n",
        "        print(\"❌ Arquivo de log não encontrado.\")\n",
        "        return\n",
        "\n",
        "    df_log = pd.read_csv(path_log)\n",
        "    df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], errors=\"coerce\")\n",
        "    df_log = df_log[df_log[\"Date\"].dt.year >= 2000]\n",
        "    df_log = df_log.dropna(subset=[\"Asset\", \"Timeframe\", \"Price\", \"TP1\", \"SL\", \"Signal\"])\n",
        "    df_log = df_log[df_log[\"Signal\"].isin([0, 1])]  # Ignora sinais neutros\n",
        "\n",
        "    # 🔒 Garante que os valores estejam no formato correto\n",
        "    df_log[\"Price\"] = pd.to_numeric(df_log[\"Price\"], errors=\"coerce\")\n",
        "    df_log[\"TP1\"] = pd.to_numeric(df_log[\"TP1\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\")\n",
        "    df_log[\"SL\"] = pd.to_numeric(df_log[\"SL\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\")\n",
        "    df_log[\"Signal\"] = pd.to_numeric(df_log[\"Signal\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\", downcast=\"integer\")\n",
        "\n",
        "    # ⏳ Filtra trades muito recentes (ainda sem candles futuros disponíveis)\n",
        "    intervalo_map = {\"15m\": timedelta(minutes=15), \"1h\": timedelta(hours=1), \"1d\": timedelta(days=1)}\n",
        "    df_log = df_log[df_log[\"Date\"] < datetime.utcnow() - df_log[\"Timeframe\"].map(intervalo_map)]\n",
        "\n",
        "    sim_results = []\n",
        "\n",
        "    for idx, row in df_log.iterrows():\n",
        "        try:\n",
        "            res = simular_trade(row)\n",
        "            if res:\n",
        "                sim_results.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao simular linha {idx}: {e}\")\n",
        "\n",
        "    if not sim_results:\n",
        "        print(\"⚠️ Nenhuma simulação válida foi executada.\")\n",
        "        return\n",
        "\n",
        "    df_trades = pd.DataFrame(sim_results)\n",
        "    df_trades[\"Capital Atual\"] = pd.to_numeric(df_trades[\"Capital Atual\"], errors=\"coerce\")\n",
        "    df_trades.to_csv(\"trades_simulados.csv\", index=False)\n",
        "    print(\"✅ Simulação concluída. Resultados salvos em trades_simulados.csv\")\n",
        "\n",
        "    try:\n",
        "        capital_final = df_trades[\"Capital Atual\"].dropna().values[-1]\n",
        "        print(f\"💰 Capital final: ${float(capital_final):,.2f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao exibir capital final: {e}\")\n",
        "        if len(df_trades[\"Capital Atual\"].dropna()) > 0:\n",
        "            print(f\"🧪 Valor bruto: {df_trades['Capital Atual'].dropna().values[-1]}\")\n",
        "        else:\n",
        "            print(\"🧪 Nenhum valor válido de capital atual encontrado.\")\n",
        "\n",
        "    return df_trades\n",
        "\n",
        "\n",
        "def salvar_grafico_evolucao():\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if not os.path.exists(\"trades_simulados.csv\"):\n",
        "        print(\"❌ Arquivo de simulação não encontrado.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(\"trades_simulados.csv\")\n",
        "        if df.empty or \"Data Entrada\" not in df.columns:\n",
        "            print(\"⚠️ Arquivo vazio ou colunas ausentes.\")\n",
        "            return\n",
        "\n",
        "        df[\"Data Entrada\"] = pd.to_datetime(df[\"Data Entrada\"], errors=\"coerce\")\n",
        "        df = df[df[\"Data Entrada\"].dt.year >= 2000]\n",
        "\n",
        "        if df.empty:\n",
        "            print(\"⚠️ Nenhum dado recente disponível para o gráfico.\")\n",
        "            return\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(df[\"Data Entrada\"], df[\"Capital Atual\"], marker=\"o\")\n",
        "        plt.title(\"💰 Evolução da Carteira Virtual\")\n",
        "        plt.xlabel(\"Data\")\n",
        "        plt.ylabel(\"Capital ($)\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        image_path = \"/tmp/evolucao_carteira.png\"\n",
        "        plt.savefig(image_path)\n",
        "        plt.close()\n",
        "        print(\"✅ Gráfico salvo em:\", image_path)\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"⚠️ trades_simulados.csv está vazio.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 6. EXECUÇÃO DAS ANÁLISES E ALERTAS\n",
        "# ====================================================\n",
        "\n",
        "def run_analysis(\n",
        "    selected_timeframes=None,\n",
        "    plot_timeframes=[\"15m\", \"1h\"],\n",
        "    alert_timeframes=[\"15m\", \"1h\", \"1d\"]\n",
        "):\n",
        "    if selected_timeframes is None:\n",
        "        selected_timeframes = TIMEFRAMES\n",
        "\n",
        "    results = []\n",
        "    houve_alerta = False\n",
        "\n",
        "    for asset in ASSETS:\n",
        "        print(f\"\\n📊 Analisando {asset}...\")\n",
        "        models = {}\n",
        "        lstm_models = {}\n",
        "        data = {}\n",
        "\n",
        "        try:\n",
        "            for tf in selected_timeframes:\n",
        "                interval = tf['interval']\n",
        "                period = tf['period']\n",
        "                data[interval] = calculate_indicators(get_stock_data(asset, interval, period))\n",
        "                models[interval] = train_ml_model(data[interval], asset=asset, interval=interval, verbose=True)\n",
        "                lstm_models[interval] = train_lstm_model(data[interval], asset=asset, interval=interval, window_size=20, force_retrain=False)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao processar {asset}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if all(model is None for model in models.values()):\n",
        "            print(f\"⚠️ Nenhum modelo foi treinado para {asset}.\")\n",
        "            continue\n",
        "\n",
        "        current_price = data.get(\"15m\", data[list(data.keys())[0]])[\"Close\"].iloc[-1]\n",
        "\n",
        "        for tf in selected_timeframes:\n",
        "            interval = tf['interval']\n",
        "            latest_data = data[interval].iloc[-1]\n",
        "            features = get_feature_columns()\n",
        "\n",
        "            predicted_price_lstm = None\n",
        "            try:\n",
        "                lstm_model = lstm_models.get(interval)\n",
        "                if lstm_model:\n",
        "                    predicted_price_lstm = predict_with_lstm(lstm_model, data[interval])\n",
        "            except Exception as e:\n",
        "                print(f\"[!] Erro na previsão LSTM: {e}\")\n",
        "\n",
        "            if predicted_price_lstm and current_price:\n",
        "                if predicted_price_lstm > current_price * 1.005:\n",
        "                    prediction = 1\n",
        "                elif predicted_price_lstm < current_price * 0.995:\n",
        "                    prediction = 0\n",
        "                else:\n",
        "                    prediction = -1\n",
        "            else:\n",
        "                prediction = -1\n",
        "\n",
        "            targets = calculate_targets(current_price, prediction, tf['atr'])\n",
        "            explanation = generate_explanation(latest_data, prediction)\n",
        "\n",
        "            variation = round((predicted_price_lstm - current_price) / current_price * 100, 2) if predicted_price_lstm else 0.0\n",
        "            rr_ratio = round((targets['TP1'] - current_price) / (current_price - targets['SL']), 2) if prediction == 1 else \\\n",
        "                       round((current_price - targets['TP1']) / (targets['SL'] - current_price), 2) if prediction == 0 else \"-\"\n",
        "\n",
        "            trend_emoji = \"🟢\" if prediction == 1 else \"🔴\" if prediction == 0 else \"⚪\"\n",
        "            trend_text = \"COMPRA\" if prediction == 1 else \"VENDA\" if prediction == 0 else \"NEUTRO\"\n",
        "            interval_map = {\"15m\": timedelta(minutes=15), \"1h\": timedelta(hours=1), \"1d\": timedelta(days=1)}\n",
        "            valid_until = (datetime.now() + interval_map.get(interval, timedelta(minutes=15))).strftime(\"%d/%m %H:%M\")\n",
        "\n",
        "            # ✅ Formatação segura para evitar erro com None\n",
        "            lstm_value_str = f\"${predicted_price_lstm:,.2f}\" if predicted_price_lstm is not None else \"N/A\"\n",
        "            variation_str = f\"{variation:+.2f}%\" if predicted_price_lstm is not None else \"N/A\"\n",
        "            tp1_str = f\"${targets['TP1']:,.2f}\" if targets['TP1'] else \"N/A\"\n",
        "            tp2_str = f\"${targets['TP2']:,.2f}\" if targets['TP2'] else \"N/A\"\n",
        "            sl_str = f\"${targets['SL']:,.2f}\" if targets['SL'] else \"N/A\"\n",
        "\n",
        "            message = f\"\"\"\n",
        "📢 <b>SINAL DETECTADO</b>\n",
        "\n",
        "🪙 <b>Ativo:</b> {asset}\n",
        "🕒 <b>Timeframe:</b> {interval}\n",
        "{trend_emoji} <b>Tendência (via LSTM):</b> {trend_text}\n",
        "\n",
        "💰 <b>Preço Atual:</b> ${current_price:,.2f}\n",
        "🔮 <b>Projeção LSTM:</b> {lstm_value_str} ({variation_str})\n",
        "🎯 <b>TP1:</b> {tp1_str}\n",
        "🎯 <b>TP2:</b> {tp2_str}\n",
        "🛑 <b>Stop Loss:</b> {sl_str}\n",
        "\n",
        "📋 <b>Justificativa Técnica:</b>\n",
        "{explanation}\n",
        "\n",
        "📊 <b>Risco/Retorno estimado:</b> {rr_ratio}\n",
        "🗓 <b>Válido até:</b> {valid_until}\n",
        "\"\"\"\n",
        "\n",
        "            result = {\n",
        "                \"Asset\": asset,\n",
        "                \"Timeframe\": interval,\n",
        "                \"Date\": datetime.now(),\n",
        "                \"Price\": current_price,\n",
        "                \"Signal\": prediction,\n",
        "                \"Confidence\": None,\n",
        "                \"AdjustedProb\": None,\n",
        "                \"TP1\": targets['TP1'],\n",
        "                \"TP2\": targets['TP2'],\n",
        "                \"SL\": targets['SL'],\n",
        "                \"Accuracy\": None,\n",
        "                \"Precision\": None,\n",
        "                \"Recall\": None,\n",
        "                \"F1\": None,\n",
        "                \"LSTM_Predicted\": predicted_price_lstm,\n",
        "                \"TargetPrice\": predicted_price_lstm\n",
        "            }\n",
        "            results.append(result)\n",
        "\n",
        "            if interval in alert_timeframes:\n",
        "                if prediction in [0, 1]:\n",
        "                    send_telegram_message(message)\n",
        "                    houve_alerta = True\n",
        "                    print(\"📨 Alerta enviado para o Telegram!\")\n",
        "                else:\n",
        "                    print(\"⛔ Previsão LSTM neutra — alerta não enviado.\")\n",
        "            else:\n",
        "                print(\"⛔ Timeframe fora da lista de alertas.\")\n",
        "\n",
        "    # ✅ Salva resultados e atualiza log\n",
        "    df_results = pd.DataFrame(results)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"model_results_{timestamp}.csv\"\n",
        "    df_results.to_csv(filename, index=False)\n",
        "    print(f\"\\n📁 Resultados salvos em: {filename}\")\n",
        "\n",
        "    log_path = \"/content/prediction_log.csv\"\n",
        "    if os.path.exists(log_path):\n",
        "        df_log_old = pd.read_csv(log_path)\n",
        "        common_cols = list(set(df_log_old.columns) & set(df_results.columns))\n",
        "        df_results = df_results[common_cols]\n",
        "        df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True)\n",
        "        df_log_combined.to_csv(log_path, index=False)\n",
        "        print(f\"📋 Log de previsões atualizado em: {log_path}\")\n",
        "    else:\n",
        "        df_results.to_csv(log_path, index=False)\n",
        "        print(f\"🔃 Log de previsões criado em: {log_path}\")\n",
        "\n",
        "    print(\"📊 Rodando simulação de carteira virtual com sinais do log...\")\n",
        "    carteira_virtual[\"capital_atual\"] = carteira_virtual[\"capital_inicial\"]\n",
        "    simular_todos_trades(log_path)\n",
        "    from pathlib import Path\n",
        "    Path(\"/tmp/evolucao_carteira.png\").unlink(missing_ok=True)\n",
        "    salvar_grafico_evolucao()\n",
        "    enviar_grafico_carteira()\n",
        "\n",
        "    if houve_alerta:\n",
        "        enviar_grafico_lucro_por_confianca(log_path)\n",
        "\n",
        "    print(\"✅ Análise completa.\")\n",
        "\n",
        "    try:\n",
        "        df_log = pd.read_csv(\"/content/prediction_log.csv\")\n",
        "        df_log = df_log[df_log[\"Signal\"].isin([0, 1])]\n",
        "        df_log = df_log[[\"Date\", \"Asset\", \"Timeframe\", \"Price\", \"Signal\", \"TP1\", \"SL\", \"TargetPrice\"]].tail(5)\n",
        "        print(\"\\n🧪 Últimos sinais válidos registrados no log:\")\n",
        "        print(df_log.to_string(index=False))\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao exibir últimos sinais válidos: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 7. AGENDAMENTO E EXECUÇÃO AUTOMÁTICA\n",
        "# ====================================================\n",
        "\n",
        "def is_time_to_run(interval):\n",
        "    now = datetime.now()\n",
        "    if interval == \"15m\":\n",
        "        return now.minute % 15 == 0\n",
        "    elif interval == \"1h\":\n",
        "        return now.minute == 0\n",
        "    elif interval == \"1d\":\n",
        "        return now.hour == 8 and now.minute == 0\n",
        "    return False\n",
        "\n",
        "# 🚀 Execução contínua: Verifica os timeframes a cada minuto\n",
        "while True:\n",
        "    now = datetime.now()\n",
        "    print(f\"\\n⏰ Verificando timeframes - {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    for tf in TIMEFRAMES:\n",
        "        interval = tf[\"interval\"]\n",
        "        if is_time_to_run(interval):\n",
        "            print(f\"\\n🚀 Rodando análise para timeframe {interval}...\")\n",
        "            try:\n",
        "                run_analysis(\n",
        "                    selected_timeframes=[tf],\n",
        "                    plot_timeframes=[\"1h\"],           # Gráficos apenas para timeframes desejados\n",
        "                    alert_timeframes=[\"15m\", \"1h\", \"1d\"]\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"❌ Erro durante a análise de {interval}: {e}\")\n",
        "        else:\n",
        "            print(f\"⏳ Ainda não é hora para {interval}...\")\n",
        "\n",
        "    time.sleep(60)  # Espera 1 minuto antes de verificar de novo\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LnV2_pGz7tDp",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fffeeaef-d309-43aa-960a-f77ff0cda402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:30:36\n",
            "\n",
            "🚀 Rodando análise para timeframe 15m...\n",
            "\n",
            "📊 Analisando BTC-USD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_15m.joblib\n",
            "✅ Modelo XGBoost já existente para BTC-USD (15m), carregado.\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "✅ Modelo LSTM carregado com sucesso para BTC-USD (15m)\n",
            "✅ LSTM carregado para BTC-USD (15m)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step\n",
            "⛔ Previsão LSTM neutra — alerta não enviado.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-03_19-30-36.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "📊 Rodando simulação de carteira virtual com sinais do log...\n",
            "⚠️ Nenhuma simulação válida foi executada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-2945642209b6>:1140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True)\n",
            "<ipython-input-81-2945642209b6>:984: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-81-2945642209b6>:986: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(image_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico salvo em: /tmp/evolucao_carteira.png\n",
            "✅ Gráfico da carteira enviado ao Telegram.\n",
            "✅ Análise completa.\n",
            "\n",
            "🧪 Últimos sinais válidos registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal      TP1       SL  TargetPrice\n",
            "2025-04-03 19:00:29.476612 BTC-USD        1h 82002.414062       1 83232.45 80772.38     82674.42\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:31:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:32:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:33:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:34:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:35:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:36:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:37:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:38:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:39:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:40:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:41:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:42:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:43:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:44:37\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:45:37\n",
            "\n",
            "🚀 Rodando análise para timeframe 15m...\n",
            "\n",
            "📊 Analisando BTC-USD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_15m.joblib\n",
            "✅ Modelo XGBoost já existente para BTC-USD (15m), carregado.\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "✅ Modelo LSTM carregado com sucesso para BTC-USD (15m)\n",
            "✅ LSTM carregado para BTC-USD (15m)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step\n",
            "⛔ Previsão LSTM neutra — alerta não enviado.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-03_19-45-38.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "📊 Rodando simulação de carteira virtual com sinais do log...\n",
            "⚠️ Nenhuma simulação válida foi executada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-2945642209b6>:1140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True)\n",
            "<ipython-input-81-2945642209b6>:984: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-81-2945642209b6>:986: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(image_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico salvo em: /tmp/evolucao_carteira.png\n",
            "✅ Gráfico da carteira enviado ao Telegram.\n",
            "✅ Análise completa.\n",
            "\n",
            "🧪 Últimos sinais válidos registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal      TP1       SL  TargetPrice\n",
            "2025-04-03 19:00:29.476612 BTC-USD        1h 82002.414062       1 83232.45 80772.38     82674.42\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:46:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:47:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:48:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:49:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:50:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:51:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:52:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:53:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:54:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:55:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:56:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:57:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:58:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 19:59:39\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 20:00:39\n",
            "\n",
            "🚀 Rodando análise para timeframe 15m...\n",
            "\n",
            "📊 Analisando BTC-USD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_15m.joblib\n",
            "✅ Modelo XGBoost já existente para BTC-USD (15m), carregado.\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "✅ Modelo LSTM carregado com sucesso para BTC-USD (15m)\n",
            "✅ LSTM carregado para BTC-USD (15m)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
            "⛔ Previsão LSTM neutra — alerta não enviado.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-03_20-00-40.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "📊 Rodando simulação de carteira virtual com sinais do log...\n",
            "\n",
            "🚨 Entrando na função simular_trade()\n",
            "🔍 Linha completa:\n",
            "Asset                                BTC-USD\n",
            "Timeframe                                 1h\n",
            "Date              2025-04-03 19:00:29.476612\n",
            "Price                           82002.414062\n",
            "Signal                                     1\n",
            "Confidence                               NaN\n",
            "AdjustedProb                             NaN\n",
            "TP1                                 83232.45\n",
            "TP2                                 84462.49\n",
            "SL                                  80772.38\n",
            "Accuracy                                 NaN\n",
            "Precision                                NaN\n",
            "Recall                                   NaN\n",
            "F1                                       NaN\n",
            "LSTM_Predicted                      82674.42\n",
            "TargetPrice                         82674.42\n",
            "Name: 1, dtype: object\n",
            "\n",
            "❌ Erro ao converter valores numéricos: cannot access local variable 'to_scalar' where it is not associated with a value\n",
            "⚠️ Nenhuma simulação válida foi executada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-2945642209b6>:1140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True)\n",
            "<ipython-input-81-2945642209b6>:984: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-81-2945642209b6>:986: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(image_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico salvo em: /tmp/evolucao_carteira.png\n",
            "✅ Gráfico da carteira enviado ao Telegram.\n",
            "✅ Análise completa.\n",
            "\n",
            "🧪 Últimos sinais válidos registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal      TP1       SL  TargetPrice\n",
            "2025-04-03 19:00:29.476612 BTC-USD        1h 82002.414062       1 83232.45 80772.38     82674.42\n",
            "\n",
            "🚀 Rodando análise para timeframe 1h...\n",
            "\n",
            "📊 Analisando BTC-USD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_1h.joblib\n",
            "✅ Modelo XGBoost já existente para BTC-USD (1h), carregado.\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_1h.h5\n",
            "✅ Modelo LSTM carregado com sucesso para BTC-USD (1h)\n",
            "✅ LSTM carregado para BTC-USD (1h)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step\n",
            "📨 Mensagem enviada com sucesso!\n",
            "📨 Alerta enviado para o Telegram!\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-03_20-00-42.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "📊 Rodando simulação de carteira virtual com sinais do log...\n",
            "\n",
            "🚨 Entrando na função simular_trade()\n",
            "🔍 Linha completa:\n",
            "Asset                                BTC-USD\n",
            "Timeframe                                 1h\n",
            "Date              2025-04-03 19:00:29.476612\n",
            "Price                           82002.414062\n",
            "Signal                                     1\n",
            "Confidence                               NaN\n",
            "AdjustedProb                             NaN\n",
            "TP1                                 83232.45\n",
            "TP2                                 84462.49\n",
            "SL                                  80772.38\n",
            "Accuracy                                 NaN\n",
            "Precision                                NaN\n",
            "Recall                                   NaN\n",
            "F1                                       NaN\n",
            "LSTM_Predicted                      82674.42\n",
            "TargetPrice                         82674.42\n",
            "Name: 1, dtype: object\n",
            "\n",
            "❌ Erro ao converter valores numéricos: cannot access local variable 'to_scalar' where it is not associated with a value\n",
            "⚠️ Nenhuma simulação válida foi executada.\n",
            "✅ Gráfico salvo em: /tmp/evolucao_carteira.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-2945642209b6>:984: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-81-2945642209b6>:986: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(image_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico da carteira enviado ao Telegram.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-81-2945642209b6>:681: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
            "  lucro_medio = df.groupby(\"FaixaConfiança\")[\"LucroEstimado\"].mean()\n",
            "<ipython-input-81-2945642209b6>:689: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-81-2945642209b6>:692: UserWarning: Glyph 128202 (\\N{BAR CHART}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico de lucro por confiança enviado.\n",
            "✅ Análise completa.\n",
            "\n",
            "🧪 Últimos sinais válidos registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal      TP1       SL  TargetPrice\n",
            "2025-04-03 19:00:29.476612 BTC-USD        1h 82002.414062       1 83232.45 80772.38     82674.42\n",
            "2025-04-03 20:00:42.524553 BTC-USD        1h 82035.960938       1 83266.50 80805.42     82539.73\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 20:01:44\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 20:02:44\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 20:03:44\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n",
            "\n",
            "⏰ Verificando timeframes - 2025-04-03 20:04:44\n",
            "⏳ Ainda não é hora para 15m...\n",
            "⏳ Ainda não é hora para 1h...\n",
            "⏳ Ainda não é hora para 1d...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clear_models(\"/content/models\")"
      ],
      "metadata": {
        "id": "OYHdrwgMk3L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_performance(\"/content/prediction_log.csv\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dCRJ6Dcsg4l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction_performance()"
      ],
      "metadata": {
        "id": "U9zUDBjSUSHH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[{\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02}],\n",
        "    plot_timeframes=[\"15m\"],\n",
        "    alert_timeframes=[\"15m\"]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNs9WU77_fGw",
        "outputId": "f00c2308-c3f3-487a-d3c8-8e27c787583c"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Analisando BTC-USD...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Modelo XGBoost carregado de: /content/models/xgb_model_BTCUSD_15m.joblib\n",
            "✅ Modelo XGBoost já existente para BTC-USD (15m), carregado.\n",
            "📂 Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "✅ Modelo LSTM carregado com sucesso para BTC-USD (15m)\n",
            "✅ LSTM carregado para BTC-USD (15m)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step\n",
            "⛔ Previsão LSTM neutra — alerta não enviado.\n",
            "\n",
            "📁 Resultados salvos em: model_results_2025-04-03_19-21-56.csv\n",
            "📋 Log de previsões atualizado em: /content/prediction_log.csv\n",
            "📊 Rodando simulação de carteira virtual com sinais do log...\n",
            "⚠️ Nenhuma simulação válida foi executada.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-2945642209b6>:1140: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True)\n",
            "<ipython-input-79-2945642209b6>:984: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-79-2945642209b6>:986: UserWarning: Glyph 128176 (\\N{MONEY BAG}) missing from font(s) DejaVu Sans.\n",
            "  plt.savefig(image_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Gráfico salvo em: /tmp/evolucao_carteira.png\n",
            "✅ Gráfico da carteira enviado ao Telegram.\n",
            "✅ Análise completa.\n",
            "\n",
            "🧪 Últimos sinais válidos registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal      TP1       SL  TargetPrice\n",
            "2025-04-03 19:00:29.476612 BTC-USD        1h 82002.414062       1 83232.45 80772.38     82674.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_log.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TJ9oavKFbT7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limpar_prediction_log()\n"
      ],
      "metadata": {
        "id": "tIYWuDfy-1Ud",
        "outputId": "e7c5976c-04f0-413e-8455-b5970d0b14eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Log limpo com sucesso. Entradas de 1970 removidas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"prediction_log.csv\")\n",
        "for i in range(5):\n",
        "    print(f\"Tipo de Signal linha {i}: {type(df.iloc[i]['Signal'])}, valor: {df.iloc[i]['Signal']}\")\n"
      ],
      "metadata": {
        "id": "NX251oPM6hEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpar_prediction_log(path=\"prediction_log.csv\"):\n",
        "    if not os.path.exists(path):\n",
        "        print(\"⚠️ Arquivo de log não encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.dropna(subset=[\"Date\"])\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
        "    df = df[df[\"Date\"].dt.year >= 2000]\n",
        "    df.to_csv(path, index=False)\n",
        "    print(\"✅ Log limpo com sucesso. Entradas de 1970 removidas!\")\n",
        "\n",
        "limpar_prediction_log()\n",
        "\n"
      ],
      "metadata": {
        "id": "OacbK7wJ7SPK",
        "outputId": "eac52ecf-6b3e-4134-e7aa-38e9e8333eac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Log limpo com sucesso. Entradas de 1970 removidas!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(\"/content/prediction_log.csv\"):\n",
        "    os.remove(\"/content/prediction_log.csv\")\n",
        "    print(\"🧹 prediction_log.csv deletado com sucesso.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4_Ab9Xh_w2J",
        "outputId": "91e07778-e4dd-4e4d-dfcb-f6b5a5bbd57c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 prediction_log.csv deletado com sucesso.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove(\"/content/prediction_log.csv\")"
      ],
      "metadata": {
        "id": "sFJIjTmjc9IX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simular_todos_trades(path_log=\"prediction_log.csv\"):\n",
        "    if not os.path.exists(path_log):\n",
        "        print(\"❌ Arquivo de log não encontrado.\")\n",
        "        return\n",
        "\n",
        "    df_log = pd.read_csv(path_log)\n",
        "    df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"], errors=\"coerce\")\n",
        "    df_log = df_log[df_log[\"Date\"].dt.year >= 2000]\n",
        "    df_log = df_log.dropna(subset=[\"Asset\", \"Timeframe\", \"Price\", \"TP1\", \"SL\", \"Signal\"])\n",
        "\n",
        "    # ✅ Ignora sinais neutros\n",
        "    df_log = df_log[df_log[\"Signal\"].isin([0, 1])]\n",
        "\n",
        "    # 🔧 Garante que os valores sejam escalares\n",
        "    df_log[\"Price\"] = pd.to_numeric(df_log[\"Price\"], errors=\"coerce\")\n",
        "    df_log[\"TP1\"] = pd.to_numeric(df_log[\"TP1\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\")\n",
        "    df_log[\"SL\"] = pd.to_numeric(df_log[\"SL\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\")\n",
        "    df_log[\"Signal\"] = pd.to_numeric(df_log[\"Signal\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and x.startswith(\"[\") else x), errors=\"coerce\", downcast=\"integer\")\n",
        "\n",
        "    sim_results = []\n",
        "\n",
        "    for idx, row in df_log.iterrows():\n",
        "        try:\n",
        "            res = simular_trade(row)\n",
        "            if res:\n",
        "                sim_results.append(res)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Erro ao simular linha {idx}: {e}\")\n",
        "\n",
        "    if not sim_results:\n",
        "        print(\"⚠️ Nenhuma simulação válida foi executada.\")\n",
        "        return\n",
        "\n",
        "    df_trades = pd.DataFrame(sim_results)\n",
        "    df_trades[\"Capital Atual\"] = pd.to_numeric(df_trades[\"Capital Atual\"], errors=\"coerce\")\n",
        "    df_trades.to_csv(\"trades_simulados.csv\", index=False)\n",
        "    print(\"✅ Simulação concluída. Resultados salvos em trades_simulados.csv\")\n",
        "\n",
        "    # ✅ Diagnóstico final\n",
        "    print(f\"📊 Total de trades simulados: {len(df_trades)}\")\n",
        "    try:\n",
        "        capital_final = df_trades[\"Capital Atual\"].iloc[-1]\n",
        "        if isinstance(capital_final, pd.Series):\n",
        "            capital_final = capital_final.squeeze()\n",
        "        capital_final = float(capital_final)\n",
        "        print(f\"💰 Capital final: ${capital_final:,.2f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Erro ao exibir capital final: {e}\")\n",
        "        print(f\"🧪 Valor bruto: {df_trades['Capital Atual'].iloc[-1]}\")\n",
        "\n",
        "    return df_trades\n"
      ],
      "metadata": {
        "id": "ACSFNFUDEiMB"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}