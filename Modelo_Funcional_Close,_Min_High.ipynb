{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxHRA4dVBJr6VuX02YXMh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laribar/SmartAITraderBot/blob/main/Modelo_Funcional_Close%2C_Min_High.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzDCUpKv0IhK",
        "outputId": "50332371-4174-4387-c6c4-50ee6b235977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->ta) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=a7efd5741981c513973d39096f87eb1e81f2b8955c32b3577fdcd07693847c0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Collecting python-binance\n",
            "  Downloading python_binance-1.0.28-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from python-binance) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from python-binance) (1.17.0)\n",
            "Collecting dateparser (from python-binance)\n",
            "  Downloading dateparser-1.2.1-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from python-binance) (3.11.15)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from python-binance) (15.0.1)\n",
            "Collecting pycryptodome (from python-binance)\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->python-binance) (1.19.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2025.2)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,>=2015.06.24 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.11/dist-packages (from dateparser->python-binance) (5.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->python-binance) (2025.1.31)\n",
            "Downloading python_binance-1.0.28-py2.py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dateparser-1.2.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m295.7/295.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome, dateparser, python-binance\n",
            "Successfully installed dateparser-1.2.1 pycryptodome-3.22.0 python-binance-1.0.28\n"
          ]
        }
      ],
      "source": [
        "!pip install ta\n",
        "!pip install yfinance\n",
        "!pip install xgboost\n",
        "!pip install python-binance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "# 1. IMPORTA√á√ïES\n",
        "# ====================================================\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ta\n",
        "import requests\n",
        "import time  # Para usar time.sleep()\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import pytz\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=4,                 # menor profundidade = menos overfitting\n",
        "    subsample=0.8,               # usa 80% dos dados por √°rvore\n",
        "    colsample_bytree=0.8,        # usa 80% das features por √°rvore\n",
        "    learning_rate=0.05,          # suaviza o aprendizado\n",
        "    early_stopping_rounds=10,    # para de treinar se n√£o melhorar\n",
        "    eval_metric=\"mlogloss\",\n",
        "    use_label_encoder=False,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "# ====================================================\n",
        "# BLOCO 1 - CONFIGURA√á√ÉO DE PASTAS E IMPORTS EXTRA\n",
        "# ====================================================\n",
        "import os\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Criar pasta onde os modelos ser√£o salvos\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "# ====================================================\n",
        "# BLOCO 2 - SALVAR E CARREGAR MODELOS TREINADOS\n",
        "# ====================================================\n",
        "def get_model_path(asset, interval, model_type=\"xgb\"):\n",
        "    asset_clean = asset.replace(\"-\", \"\")\n",
        "    ext = \"joblib\" if model_type == \"xgb\" else \"h5\"\n",
        "    return f\"/content/models/{model_type}_model_{asset_clean}_{interval}.{ext}\"\n",
        "\n",
        "# --- XGBoost ---\n",
        "def save_xgb_model(model, asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "    joblib.dump(model, path)\n",
        "    print(f\"üíæ Modelo XGBoost salvo em: {path}\")\n",
        "\n",
        "def load_xgb_model(asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"xgb\")\n",
        "    if os.path.exists(path):\n",
        "        print(f\"üìÇ Modelo XGBoost carregado de: {path}\")\n",
        "        return joblib.load(path)\n",
        "    return None\n",
        "\n",
        "# --- LSTM ---\n",
        "def save_lstm_model(model, asset, interval):\n",
        "    path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "    model.save(path)\n",
        "    print(f\"üíæ Modelo LSTM salvo em: {path}\")\n",
        "\n",
        "    # Salvar metadados no novo formato\n",
        "    meta_path = path.replace(\".h5\", \"_meta.pkl\").replace(\".keras\", \"_meta.pkl\")\n",
        "    joblib.dump({\n",
        "        \"scaler_x\": model.scaler_x,\n",
        "        \"scaler_y\": model.scaler_y,\n",
        "        \"feature_cols\": model.feature_cols,\n",
        "        \"target_cols\": model.target_cols,\n",
        "        \"window_size\": model.window_size\n",
        "    }, meta_path)\n",
        "    print(f\"üì¶ Metadados salvos em: {meta_path}\")\n",
        "\n",
        "\n",
        "\n",
        "def load_lstm_model(asset, interval, window_size=20):\n",
        "    from tensorflow.keras.models import load_model\n",
        "    import joblib\n",
        "    import os\n",
        "\n",
        "    model_path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "    meta_path = model_path.replace(\".h5\", \"_meta.pkl\").replace(\".keras\", \"_meta.pkl\")\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"üö´ Modelo LSTM N√ÉO encontrado em: {model_path}\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        model = load_model(model_path, compile=False)\n",
        "        print(f\"üìÇ Modelo LSTM encontrado em: {model_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao carregar modelo LSTM de {model_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Carrega os metadados\n",
        "    if os.path.exists(meta_path):\n",
        "        try:\n",
        "            meta = joblib.load(meta_path)\n",
        "            model.scaler_x = meta.get(\"scaler_x\")\n",
        "            model.scaler_y = meta.get(\"scaler_y\")\n",
        "            model.feature_cols = meta.get(\"feature_cols\")\n",
        "            model.target_cols = meta.get(\"target_cols\", [\"High\", \"Low\", \"Close\"])\n",
        "            model.window_size = meta.get(\"window_size\", window_size)\n",
        "\n",
        "            # ‚úÖ Compatibilidade com c√≥digos antigos\n",
        "            model.scaler = model.scaler_x\n",
        "\n",
        "            print(f\"üì¶ Metadados carregados de: {meta_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro ao carregar metadados de {meta_path}: {e}\")\n",
        "            model.scaler_x = None\n",
        "            model.scaler_y = None\n",
        "            model.scaler = None\n",
        "            model.feature_cols = None\n",
        "            model.target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "            model.window_size = window_size\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Metadados n√£o encontrados em: {meta_path}\")\n",
        "        model.scaler_x = None\n",
        "        model.scaler_y = None\n",
        "        model.scaler = None\n",
        "        model.feature_cols = None\n",
        "        model.target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "        model.window_size = window_size\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 2. CONFIGURA√á√ïES\n",
        "# ====================================================\n",
        "ASSETS = [\"BTC-USD\"] #, \"ETH-USD\", \"BNB-USD\", \"SOL-USD\", \"XRP-USD\", \"AVAX-USD\", \"AAVE-USD\", \"DOT-USD\", \"NEAR-USD\", \"ADA-USD\"\n",
        "\n",
        "\n",
        "TIMEFRAMES = [\n",
        "    {\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02},\n",
        "    {\"interval\": \"1h\", \"period\": \"90d\", \"atr\": 0.03},\n",
        "    {\"interval\": \"1d\", \"period\": \"1000d\", \"atr\": 0.05},\n",
        "    {\"interval\": \"1wk\", \"period\": \"max\", \"atr\": 0.08}  # üëà Adicionado o semanal\n",
        "]\n",
        "\n",
        "TELEGRAM_TOKEN = \"8044593190:AAFtUWYHd3uqd-AtQi3uqg42F9G6uV95v8k\"\n",
        "TELEGRAM_CHAT_ID = \"-4744645054\"\n",
        "\n",
        "# ====================================================\n",
        "# 3. COLETA DE DADOS\n",
        "# ====================================================\n",
        "def get_stock_data(asset, interval=\"15m\", period=\"700d\"):\n",
        "    data = yf.download(asset, period=period, interval=interval, progress=False, auto_adjust=False)\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        data.columns = data.columns.get_level_values(0)\n",
        "    data.columns = [col.split()[-1] if \" \" in col else col for col in data.columns]\n",
        "    data = data.loc[:, ~data.columns.duplicated()]\n",
        "    col_map = {col: std_col for col in data.columns for std_col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"] if std_col.lower() in col.lower()}\n",
        "    data = data.rename(columns=col_map)\n",
        "    data = data[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
        "    if not all(col in data.columns for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]):\n",
        "        raise ValueError(f\"‚ö†Ô∏è Dados de {asset} n√£o possuem todas as colunas necess√°rias.\")\n",
        "    return data\n",
        "\n",
        "\n",
        "def safe_read_csv(filepath):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"‚ö†Ô∏è Arquivo n√£o encontrado: {filepath}\")\n",
        "        return None\n",
        "    if os.path.getsize(filepath) == 0:\n",
        "        print(f\"‚ö†Ô∏è Arquivo est√° vazio: {filepath}\")\n",
        "        return None\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        if df.empty or len(df.columns) == 0:\n",
        "            print(f\"‚ö†Ô∏è Arquivo inv√°lido (sem colunas): {filepath}\")\n",
        "            return None\n",
        "        return df\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"‚ö†Ô∏è Erro: arquivo sem colunas: {filepath}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro inesperado ao ler CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "def criar_prediction_log_padrao(filepath=\"/content/prediction_log.csv\"):\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    colunas_padroes = [\n",
        "        \"Asset\", \"Timeframe\", \"Date\", \"Price\", \"Signal\", \"Confidence\", \"AdjustedProb\",\n",
        "        \"TP1\", \"TP2\", \"SL\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\",\n",
        "        \"LSTM_Predicted\", \"TargetPrice\",\n",
        "        \"LSTM_High_Predicted\", \"LSTM_Low_Predicted\",  # ‚úÖ Novas colunas\n",
        "        \"Acertou\", \"Resultado\", \"PrecoSaida\", \"LucroEstimado\", \"DuracaoMin\"\n",
        "    ]\n",
        "\n",
        "    if not os.path.exists(filepath) or os.path.getsize(filepath) == 0:\n",
        "        print(f\"üìÑ Criando novo prediction_log com colunas padr√£o em: {filepath}\")\n",
        "        df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "        df_vazio.to_csv(filepath, index=False)\n",
        "    else:\n",
        "        try:\n",
        "            df_existente = pd.read_csv(filepath)\n",
        "            if df_existente.empty or len(df_existente.columns) == 0:\n",
        "                print(f\"‚ö†Ô∏è Arquivo est√° corrompido. Recriando...\")\n",
        "                df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "                df_vazio.to_csv(filepath, index=False)\n",
        "            else:\n",
        "                missing_cols = [col for col in colunas_padroes if col not in df_existente.columns]\n",
        "                if missing_cols:\n",
        "                    print(f\"‚ö†Ô∏è Adicionando colunas faltantes: {missing_cols}\")\n",
        "                    for col in missing_cols:\n",
        "                        df_existente[col] = None\n",
        "                    df_existente.to_csv(filepath, index=False)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao validar o log existente. Recriando. Erro: {e}\")\n",
        "            df_vazio = pd.DataFrame(columns=colunas_padroes)\n",
        "            df_vazio.to_csv(filepath, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 4. INDICADORES T√âCNICOS\n",
        "# ====================================================\n",
        "def calculate_indicators(data):\n",
        "    data = data.copy().reset_index(drop=True)\n",
        "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
        "        data[col] = data[col].astype(float)\n",
        "\n",
        "    # Indicadores Cl√°ssicos\n",
        "    data[\"RSI\"] = ta.momentum.RSIIndicator(close=data[\"Close\"], window=14).rsi()\n",
        "    data[\"SMA_50\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=50).sma_indicator()\n",
        "    data[\"SMA_200\"] = ta.trend.SMAIndicator(close=data[\"Close\"], window=200).sma_indicator()\n",
        "\n",
        "    macd = ta.trend.MACD(close=data[\"Close\"])\n",
        "    data[\"MACD\"] = macd.macd()\n",
        "    data[\"MACD_Signal\"] = macd.macd_signal()\n",
        "\n",
        "    bb = ta.volatility.BollingerBands(close=data[\"Close\"], window=20)\n",
        "    data[\"Bollinger_Upper\"] = bb.bollinger_hband()\n",
        "    data[\"Bollinger_Lower\"] = bb.bollinger_lband()\n",
        "\n",
        "    adx = ta.trend.ADXIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"ADX\"] = adx.adx()\n",
        "\n",
        "    stoch = ta.momentum.StochasticOscillator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=14)\n",
        "    data[\"Stoch_K\"] = stoch.stoch()\n",
        "    data[\"Stoch_D\"] = stoch.stoch_signal()\n",
        "\n",
        "    # Indicadores adicionais\n",
        "    data[\"ATR\"] = ta.volatility.AverageTrueRange(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"]).average_true_range()\n",
        "    data[\"ROC\"] = ta.momentum.ROCIndicator(close=data[\"Close\"], window=12).roc()\n",
        "    data[\"OBV\"] = ta.volume.OnBalanceVolumeIndicator(close=data[\"Close\"], volume=data[\"Volume\"]).on_balance_volume()\n",
        "    data[\"CCI\"] = ta.trend.CCIIndicator(high=data[\"High\"], low=data[\"Low\"], close=data[\"Close\"], window=20).cci()\n",
        "\n",
        "    ichimoku = ta.trend.IchimokuIndicator(high=data[\"High\"], low=data[\"Low\"], window1=9, window2=26)\n",
        "    data[\"Tenkan_Sen\"] = ichimoku.ichimoku_conversion_line()\n",
        "    data[\"Kijun_Sen\"] = ichimoku.ichimoku_base_line()\n",
        "\n",
        "    # VWAP e Candles\n",
        "    data[\"TP\"] = (data[\"High\"] + data[\"Low\"] + data[\"Close\"]) / 3\n",
        "    data[\"VWAP\"] = (data[\"TP\"] * data[\"Volume\"]).cumsum() / (data[\"Volume\"].replace(0, np.nan).cumsum())\n",
        "    data.drop(\"TP\", axis=1, inplace=True)\n",
        "\n",
        "    data[\"Doji\"] = ((abs(data[\"Close\"] - data[\"Open\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9)) < 0.1).astype(int)\n",
        "    data[\"Engulfing\"] = ((data[\"Open\"].shift(1) > data[\"Close\"].shift(1)) & (data[\"Open\"] < data[\"Close\"]) &\n",
        "                         (data[\"Close\"] > data[\"Open\"].shift(1)) & (data[\"Open\"] < data[\"Close\"].shift(1))).astype(int)\n",
        "    data[\"Hammer\"] = (((data[\"High\"] - data[\"Low\"]) > 3 * abs(data[\"Open\"] - data[\"Close\"])) &\n",
        "                      ((data[\"Close\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6) &\n",
        "                      ((data[\"Open\"] - data[\"Low\"]) / (data[\"High\"] - data[\"Low\"] + 1e-9) > 0.6)).astype(int)\n",
        "\n",
        "    data.dropna(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 4. MODELOS DE MACHINE LEARNING (XGBoost + LSTM)\n",
        "# ====================================================\n",
        "\n",
        "def get_feature_columns(df, include_lstm_pred=False):\n",
        "    \"\"\"\n",
        "    Retorna a lista de colunas de features para os modelos.\n",
        "    Se include_lstm_pred=True, inclui a coluna LSTM_PRED para uso no XGBoost.\n",
        "    \"\"\"\n",
        "    base_features = [\n",
        "        'Open', 'High', 'Low', 'Close', 'Volume',\n",
        "        'SMA_5', 'SMA_20', 'EMA_12', 'EMA_26',\n",
        "        'RSI', 'MACD', 'MACD_signal', 'MACD_hist',\n",
        "        'BB_upper', 'BB_middle', 'BB_lower',\n",
        "        'ATR', 'CCI', 'ROC', 'OBV'\n",
        "    ]\n",
        "    if include_lstm_pred:\n",
        "        base_features.append(\"LSTM_PRED\")\n",
        "    return [col for col in base_features if col in df.columns]\n",
        "\n",
        "\n",
        "def get_lstm_feature_columns():\n",
        "    return [\n",
        "        \"Close\", \"High\", \"Low\",  # üü¢ Agora inclui as tr√™s colunas principais como features tamb√©m\n",
        "        \"RSI\", \"MACD\", \"MACD_Signal\", \"SMA_50\", \"SMA_200\",\n",
        "        \"Bollinger_Upper\", \"Bollinger_Lower\",\n",
        "        \"ADX\", \"Stoch_K\", \"Stoch_D\",\n",
        "        \"ATR\", \"ROC\", \"OBV\", \"CCI\",\n",
        "        \"Tenkan_Sen\", \"Kijun_Sen\", \"VWAP\",\n",
        "        \"Doji\", \"Engulfing\", \"Hammer\"\n",
        "    ]\n",
        "\n",
        "\n",
        "def prepare_lstm_data(data, feature_cols=None, target_cols=[\"High\", \"Low\", \"Close\"], window_size=20):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = get_lstm_feature_columns()\n",
        "\n",
        "    missing = [col for col in feature_cols + target_cols if col not in data.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"‚ùå Colunas ausentes no DataFrame: {missing}\")\n",
        "\n",
        "    df = data[feature_cols + target_cols].dropna().astype(float)\n",
        "    if len(df) < window_size + 1:\n",
        "        raise ValueError(f\"‚ö†Ô∏è Dados insuficientes: {len(df)} rows, necess√°rio m√≠nimo {window_size + 1}\")\n",
        "\n",
        "    # Escalonamento separado\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_X = scaler_x.fit_transform(df[feature_cols])\n",
        "    scaled_y = scaler_y.fit_transform(df[target_cols])\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(df)):\n",
        "        X.append(scaled_X[i - window_size:i])\n",
        "        y.append(scaled_y[i])  # Previs√£o para o instante i\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"‚úÖ prepare_lstm_data | X.shape: {X.shape}, y.shape: {y.shape}\")\n",
        "    return X, y, scaler_x, scaler_y\n",
        "\n",
        "\n",
        "\n",
        "def train_lstm_model(df, *, asset, interval, window_size=20, force_retrain=False):\n",
        "    import os\n",
        "    import numpy as np\n",
        "    import joblib\n",
        "    from tensorflow.keras.models import Sequential\n",
        "    from tensorflow.keras.layers import LSTM, Dense\n",
        "    from tensorflow.keras.callbacks import EarlyStopping\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    feature_cols = get_lstm_feature_columns()\n",
        "    target_cols = [\"High\", \"Low\", \"Close\"]\n",
        "    df = df.dropna(subset=feature_cols + target_cols)\n",
        "\n",
        "    if len(df) <= window_size:\n",
        "        raise ValueError(\"Dados insuficientes para treino do LSTM.\")\n",
        "\n",
        "    df_features = df[feature_cols]\n",
        "    df_targets = df[target_cols]\n",
        "\n",
        "    scaler_x = MinMaxScaler()\n",
        "    scaler_y = MinMaxScaler()\n",
        "\n",
        "    scaled_features = scaler_x.fit_transform(df_features)\n",
        "    scaled_targets = scaler_y.fit_transform(df_targets)\n",
        "\n",
        "    X, y = [], []\n",
        "    for i in range(window_size, len(df)):\n",
        "        X.append(scaled_features[i - window_size:i])\n",
        "        y.append(scaled_targets[i])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"‚úÖ X.shape: {X.shape}, y.shape: {y.shape}\")\n",
        "\n",
        "    model_path = get_model_path(asset, interval, model_type=\"lstm\")\n",
        "    meta_path = model_path.replace(\".h5\", \"_meta.pkl\")\n",
        "\n",
        "    if not force_retrain and os.path.exists(model_path):\n",
        "        model = load_lstm_model(asset, interval)\n",
        "        if model and all(hasattr(model, attr) for attr in [\"scaler_x\", \"scaler_y\", \"feature_cols\", \"window_size\", \"target_cols\"]):\n",
        "            return model\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Modelo existente n√£o cont√©m atributos. Ser√° refeito.\")\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(64, return_sequences=False, input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dense(3))  # Prever [High, Low, Close]\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "    model.fit(X, y, epochs=100, batch_size=32, validation_split=0.2, callbacks=[es], verbose=0)\n",
        "\n",
        "    # Atributos para reuso\n",
        "    model.scaler_x = scaler_x\n",
        "    model.scaler_y = scaler_y\n",
        "    model.scaler = scaler_x  # ‚úÖ Compatibilidade com c√≥digos antigos\n",
        "    model.feature_cols = feature_cols\n",
        "    model.target_cols = target_cols\n",
        "    model.window_size = window_size\n",
        "\n",
        "    model.save(model_path)\n",
        "    joblib.dump({\n",
        "        \"scaler_x\": scaler_x,\n",
        "        \"scaler_y\": scaler_y,\n",
        "        \"feature_cols\": feature_cols,\n",
        "        \"target_cols\": target_cols,\n",
        "        \"window_size\": window_size\n",
        "    }, meta_path)\n",
        "\n",
        "    print(f\"üíæ Modelo LSTM salvo em: {model_path}\")\n",
        "    print(f\"üì¶ Metadados salvos em: {meta_path}\")\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_ml_model(data, asset=None, interval=None, verbose=False):\n",
        "    if asset and interval:\n",
        "        existing_model = load_xgb_model(asset, interval)\n",
        "        if existing_model is not None:\n",
        "            print(f\"‚úÖ Modelo XGBoost j√° existente para {asset} ({interval}), carregado.\")\n",
        "            return existing_model\n",
        "\n",
        "    if len(data) < 100:\n",
        "        return None\n",
        "\n",
        "    df = data.copy()\n",
        "    df = calculate_indicators(df)\n",
        "\n",
        "    try:\n",
        "        lstm_model = train_lstm_model(df, asset=asset, interval=interval, window_size=20, force_retrain=False)\n",
        "\n",
        "        if lstm_model:\n",
        "            print(\"‚úÖ Features usadas no LSTM:\")\n",
        "            print(lstm_model.feature_cols)\n",
        "\n",
        "            print(\"‚úÖ √öltimos dados de entrada:\")\n",
        "            print(df[lstm_model.feature_cols].tail(3))\n",
        "\n",
        "            # ‚úÖ Aqui est√° a corre√ß√£o do print (substitui 'model.scaler')\n",
        "            print(\"‚úÖ Valores m√≠nimos do scaler X:\")\n",
        "            print(lstm_model.scaler_x.data_min_)\n",
        "            print(\"‚úÖ Valores m√°ximos do scaler X:\")\n",
        "            print(lstm_model.scaler_x.data_max_)\n",
        "\n",
        "        # Previs√µes com LSTM para gerar LSTM_PRED\n",
        "        if lstm_model is not None:\n",
        "            lstm_preds = []\n",
        "            for i in range(len(df)):\n",
        "                sub_df = df.iloc[:i+1]\n",
        "                if len(sub_df) < lstm_model.window_size:\n",
        "                    lstm_preds.append(np.nan)\n",
        "                else:\n",
        "                    try:\n",
        "                        pred = predict_with_lstm(lstm_model, sub_df)\n",
        "                        lstm_preds.append(pred.get(\"Close\", np.nan))\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Erro ao prever com LSTM: {e}\")\n",
        "                        lstm_preds.append(np.nan)\n",
        "            df[\"LSTM_PRED\"] = lstm_preds\n",
        "        else:\n",
        "            df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao gerar LSTM_PRED: {e}\")\n",
        "        df[\"LSTM_PRED\"] = np.nan\n",
        "\n",
        "    if \"LSTM_PRED\" not in df.columns:\n",
        "        print(\"‚ùå Coluna 'LSTM_PRED' n√£o foi gerada. Abortando treino do XGBoost.\")\n",
        "        return None\n",
        "\n",
        "    df[\"Future_Close\"] = df[\"Close\"].shift(-5)\n",
        "    df[\"Future_Return\"] = df[\"Future_Close\"] / df[\"Close\"] - 1\n",
        "    df = df[(df[\"Future_Return\"] > 0.015) | (df[\"Future_Return\"] < -0.015)].copy()\n",
        "    df[\"Signal\"] = np.where(df[\"Future_Return\"] > 0.015, 1, 0)\n",
        "\n",
        "    features = get_feature_columns(df, include_lstm_pred=True)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    missing_features = [f for f in features if f not in df.columns]\n",
        "    if missing_features:\n",
        "        print(f\"‚ùå Features ausentes: {missing_features}\")\n",
        "        return None\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[\"Signal\"]\n",
        "\n",
        "    if len(np.unique(y)) < 2:\n",
        "        return None\n",
        "\n",
        "    from sklearn.model_selection import TimeSeriesSplit\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    for train_index, val_index in tscv.split(X):\n",
        "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "        break\n",
        "\n",
        "    if len(np.unique(y_train)) < 2:\n",
        "        return None\n",
        "\n",
        "    scale_pos_weight = len(y_train[y_train == 0]) / max(1, len(y_train[y_train == 1]))\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\",\n",
        "        scale_pos_weight=scale_pos_weight,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    y_pred = model.predict(X_val)\n",
        "    report = classification_report(y_val, y_pred, output_dict=True, zero_division=0)\n",
        "\n",
        "    model.validation_score = {\n",
        "        \"accuracy\": report.get(\"accuracy\"),\n",
        "        \"precision\": report.get(\"1\", {}).get(\"precision\"),\n",
        "        \"recall\": report.get(\"1\", {}).get(\"recall\"),\n",
        "        \"f1\": report.get(\"1\", {}).get(\"f1-score\")\n",
        "    }\n",
        "\n",
        "    if asset and interval:\n",
        "        save_xgb_model(model, asset, interval)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_with_lstm(model, df):\n",
        "    import numpy as np\n",
        "\n",
        "    # Verifica√ß√£o robusta de atributos obrigat√≥rios\n",
        "    if not all(hasattr(model, attr) for attr in ['scaler_x', 'scaler_y', 'feature_cols', 'target_cols', 'window_size']):\n",
        "        raise AttributeError(\"O modelo LSTM n√£o possui os atributos necess√°rios.\")\n",
        "\n",
        "    df = df.copy().dropna(subset=model.feature_cols)\n",
        "\n",
        "    if len(df) < model.window_size:\n",
        "        raise ValueError(\"Dados insuficientes para previs√£o com LSTM.\")\n",
        "\n",
        "    # Prepara a √∫ltima janela de entrada\n",
        "    last_window = df[model.feature_cols].values[-model.window_size:]\n",
        "    scaled_window = model.scaler_x.transform(last_window)\n",
        "    X_input = np.expand_dims(scaled_window, axis=0)\n",
        "\n",
        "    # Previs√£o escalada\n",
        "    pred_scaled = model.predict(X_input, verbose=0)[0].reshape(1, -1)\n",
        "\n",
        "    # Desescalonamento da previs√£o\n",
        "    pred_descaled = model.scaler_y.inverse_transform(pred_scaled)[0]\n",
        "\n",
        "    # Retorna dicion√°rio com os targets previstos\n",
        "    return {target: float(pred_descaled[i]) for i, target in enumerate(model.target_cols)}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_feature_importance(model, feature_names, top_n=15):\n",
        "    import matplotlib.pyplot as plt\n",
        "    importances = model.feature_importances_\n",
        "    indices = np.argsort(importances)[-top_n:]  # top_n mais importantes\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "    plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
        "    plt.xlabel(\"Import√¢ncia\")\n",
        "    plt.title(\"üéØ Import√¢ncia das Features - XGBoost\")\n",
        "    plt.tight_layout()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 5. UTILIT√ÅRIOS\n",
        "# ====================================================\n",
        "# ====================================================\n",
        "# FUN√á√ÉO GLOBAL DE CONVERS√ÉO ESCALAR\n",
        "# ====================================================\n",
        "def to_scalar(val):\n",
        "    try:\n",
        "        if isinstance(val, pd.Series):\n",
        "            return float(val.iloc[0])\n",
        "        elif isinstance(val, (np.ndarray, list)):\n",
        "            return float(val[0])\n",
        "        elif pd.isna(val):\n",
        "            return np.nan\n",
        "        else:\n",
        "            return float(val)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Falha ao converter valor escalar: {val} | erro: {e}\")\n",
        "        return np.nan\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def limpar_model_results():\n",
        "    arquivos = glob.glob(\"/content/model_results_*.csv\")\n",
        "    if not arquivos:\n",
        "        print(\"üìÇ Nenhum arquivo model_results_*.csv encontrado.\")\n",
        "        return\n",
        "\n",
        "def plot_entrada_lstm(df, feature_cols):\n",
        "    import matplotlib.pyplot as plt\n",
        "    df_plot = df[feature_cols].tail(100).copy()\n",
        "    df_plot.plot(figsize=(12, 5), title=\"üìä √öltimas 100 entradas das features LSTM\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def generate_explanation(row, prediction, feature_importance=None):\n",
        "    try:\n",
        "        explicacao = []\n",
        "\n",
        "        if prediction == 1:\n",
        "            explicacao.append(\"üü¢ O modelo prev√™ uma tend√™ncia de ALTA.\")\n",
        "        elif prediction == 0:\n",
        "            explicacao.append(\"üî¥ O modelo prev√™ uma tend√™ncia de BAIXA.\")\n",
        "        else:\n",
        "            explicacao.append(\"‚ö™ Sinal neutro.\")\n",
        "\n",
        "        # Mapas de interpreta√ß√£o t√©cnica\n",
        "        if row[\"RSI\"] < 30:\n",
        "            explicacao.append(\"RSI em sobrevenda (abaixo de 30).\")\n",
        "        elif row[\"RSI\"] > 70:\n",
        "            explicacao.append(\"RSI em sobrecompra (acima de 70).\")\n",
        "\n",
        "        if row[\"MACD\"] > row[\"MACD_Signal\"]:\n",
        "            explicacao.append(\"MACD cruzando para cima da linha de sinal.\")\n",
        "        else:\n",
        "            explicacao.append(\"MACD abaixo da linha de sinal.\")\n",
        "\n",
        "        if row[\"SMA_50\"] > row[\"SMA_200\"]:\n",
        "            explicacao.append(\"SMA 50 acima da 200 (tend√™ncia de alta).\")\n",
        "        else:\n",
        "            explicacao.append(\"SMA 50 abaixo da 200 (tend√™ncia de baixa).\")\n",
        "\n",
        "        if row[\"ADX\"] > 20:\n",
        "            explicacao.append(\"ADX acima de 20 (tend√™ncia definida).\")\n",
        "\n",
        "        if row[\"Doji\"] == 1:\n",
        "            explicacao.append(\"Padr√£o Doji detectado (potencial revers√£o).\")\n",
        "        if row[\"Engulfing\"] == 1:\n",
        "            explicacao.append(\"Padr√£o de engolfo detectado.\")\n",
        "        if row[\"Hammer\"] == 1:\n",
        "            explicacao.append(\"Padr√£o de candle martelo identificado.\")\n",
        "\n",
        "        if feature_importance:\n",
        "            top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:3]\n",
        "            explicacao.append(\"\\nüìä Principais influ√™ncias do modelo:\")\n",
        "            for name, weight in top_features:\n",
        "                explicacao.append(f\"‚Ä¢ {name}: peso {weight:.3f}\")\n",
        "\n",
        "        return \"\\n\".join(explicacao)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"‚ö†Ô∏è Erro ao gerar explica√ß√£o: {str(e)}\"\n",
        "\n",
        "def calculate_targets(price, signal, atr_multiplier=0.02):\n",
        "    atr = price * atr_multiplier\n",
        "    if signal == 1:\n",
        "        tp1 = price + atr\n",
        "        tp2 = price + 2 * atr\n",
        "        sl = price - atr\n",
        "    elif signal == -1 or signal == 0:\n",
        "        tp1 = price - atr\n",
        "        tp2 = price - 2 * atr\n",
        "        sl = price + atr\n",
        "    else:\n",
        "        return {\"TP1\": None, \"TP2\": None, \"SL\": None}\n",
        "\n",
        "    return {\n",
        "        \"TP1\": round(tp1, 2),\n",
        "        \"TP2\": round(tp2, 2),\n",
        "        \"SL\": round(sl, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def send_telegram_message(message):\n",
        "    url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage\"\n",
        "    payload = {\"chat_id\": TELEGRAM_CHAT_ID, \"text\": message, \"parse_mode\": \"HTML\"}\n",
        "    response = requests.post(url, json=payload)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"üì® Mensagem enviada com sucesso!\")\n",
        "    else:\n",
        "        print(f\"‚ùå Erro ao enviar mensagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "def predict_next_closes(data, n_steps=5):\n",
        "    df = data.copy().reset_index(drop=True)\n",
        "    features = get_feature_columns(df)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    X = df[features]\n",
        "    y = df[\"Close\"].shift(-1).dropna()\n",
        "    X = X.loc[y.index]\n",
        "\n",
        "    if len(X) < 100:\n",
        "        return [None] * n_steps\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=42)\n",
        "    model.fit(X, y)\n",
        "\n",
        "    last_row = df[features].iloc[-1].copy()\n",
        "    preds = []\n",
        "\n",
        "    for step in range(n_steps):\n",
        "        X_input = pd.DataFrame([last_row], columns=features)\n",
        "        next_close = model.predict(X_input)[0]\n",
        "        preds.append(round(next_close, 2))\n",
        "\n",
        "        # Simula avan√ßo do mercado\n",
        "        last_row[\"Close\"] = next_close\n",
        "        if \"SMA_50\" in last_row:\n",
        "            last_row[\"SMA_50\"] = last_row[\"SMA_50\"] * 0.9 + next_close * 0.1\n",
        "        if \"SMA_200\" in last_row:\n",
        "            last_row[\"SMA_200\"] = last_row[\"SMA_200\"] * 0.95 + next_close * 0.05\n",
        "        if \"VWAP\" in last_row:\n",
        "            last_row[\"VWAP\"] = last_row[\"VWAP\"] * 0.95 + next_close * 0.05\n",
        "        if \"RSI\" in last_row:\n",
        "            last_row[\"RSI\"] = min(100, max(0, last_row[\"RSI\"] + np.random.normal(0, 0.5)))\n",
        "        if \"MACD\" in last_row:\n",
        "            last_row[\"MACD\"] += np.random.normal(0, 0.3)\n",
        "        if \"MACD_Signal\" in last_row:\n",
        "            last_row[\"MACD_Signal\"] += np.random.normal(0, 0.2)\n",
        "\n",
        "        last_row = last_row[features]\n",
        "\n",
        "    return preds\n",
        "\n",
        "\n",
        "def evaluate_past_predictions(results_file=\"/content/prediction_log.csv\", lookahead_candles=5):\n",
        "    import os\n",
        "    import pandas as pd\n",
        "    import yfinance as yf\n",
        "    import matplotlib.pyplot as plt\n",
        "    from datetime import timedelta\n",
        "\n",
        "    df = safe_read_csv(results_file)\n",
        "    if df is None or df.empty:\n",
        "        print(\"üì≠ Nenhum log de previs√£o encontrado ou o arquivo est√° vazio.\")\n",
        "        return\n",
        "\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    print(f\"üìä Avaliando {len(df)} previs√µes salvas...\")\n",
        "\n",
        "    evaluation = []\n",
        "\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        asset = row[\"Asset\"]\n",
        "        interval = row[\"Timeframe\"]\n",
        "        prediction_time = row[\"Date\"]\n",
        "        predicted_signal = row[\"Signal\"]\n",
        "        predicted_target = row.get(\"TargetPrice\", None)\n",
        "\n",
        "        try:\n",
        "            candles = yf.download(asset, start=prediction_time, interval=interval, progress=False)\n",
        "            candles = candles[candles.index > prediction_time]\n",
        "\n",
        "            if candles.empty or len(candles) < lookahead_candles:\n",
        "                continue\n",
        "\n",
        "            candles = candles.head(lookahead_candles)\n",
        "            final_close = candles[\"Close\"].iloc[-1]\n",
        "\n",
        "            if predicted_signal == 1:\n",
        "                result = \"Acertou\" if final_close >= predicted_target else \"Errou\"\n",
        "            elif predicted_signal == 0:\n",
        "                result = \"Acertou\" if final_close <= predicted_target else \"Errou\"\n",
        "            else:\n",
        "                result = \"Neutro\"\n",
        "\n",
        "            if predicted_target:\n",
        "                perc_change = ((final_close - predicted_target) / predicted_target) * 100\n",
        "                abs_error = final_close - predicted_target\n",
        "            else:\n",
        "                perc_change = None\n",
        "                abs_error = None\n",
        "\n",
        "            acertou = 1 if result == \"Acertou\" else 0\n",
        "\n",
        "            evaluation.append({\n",
        "                \"Ativo\": asset,\n",
        "                \"Timeframe\": interval,\n",
        "                \"Data Previs√£o\": prediction_time.strftime(\"%Y-%m-%d %H:%M\"),\n",
        "                \"Sinal Previsto\": \"Compra\" if predicted_signal == 1 else \"Venda\" if predicted_signal == 0 else \"Neutro\",\n",
        "                \"Valor Projetado (LSTM)\": round(predicted_target, 2) if predicted_target else None,\n",
        "                \"Resultado\": result,\n",
        "                \"Valor Real\": round(final_close, 2),\n",
        "                \"Varia√ß√£o Real\": f\"{perc_change:+.2f}%\" if perc_change is not None else \"N/A\",\n",
        "                \"Erro Absoluto\": f\"{abs_error:+.2f}\" if abs_error is not None else \"N/A\",\n",
        "                \"Acertou\": acertou\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro ao avaliar {asset} em {prediction_time}: {e}\")\n",
        "            continue\n",
        "\n",
        "    df_eval = pd.DataFrame(evaluation)\n",
        "\n",
        "    # üìä Resumo de acertos e erros\n",
        "    resumo = df_eval.groupby([\"Ativo\", \"Timeframe\", \"Resultado\"]).size().unstack(fill_value=0)\n",
        "    resumo[\"Total\"] = resumo.sum(axis=1)\n",
        "    resumo[\"Acur√°cia (%)\"] = (resumo.get(\"Acertou\", 0) / resumo[\"Total\"] * 100).round(2)\n",
        "    display(resumo)\n",
        "\n",
        "    # üìà Gr√°fico de barras\n",
        "    resumo_plot = resumo[[\"Acertou\", \"Errou\"]] if \"Errou\" in resumo.columns else resumo[[\"Acertou\"]]\n",
        "    resumo_plot.plot(kind=\"bar\", figsize=(10, 5), title=\"üìä Acertos vs Erros por Ativo e Timeframe\")\n",
        "    plt.ylabel(\"Quantidade de Sinais\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(axis=\"y\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # üìÑ Tabela completa das previs√µes\n",
        "    display(df_eval)\n",
        "\n",
        "    # üîÑ Atualizar o prediction_log.csv com a coluna 'Acertou'\n",
        "    try:\n",
        "        df_log = safe_read_csv(results_file)\n",
        "        df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"])\n",
        "\n",
        "        for _, row in df_eval.iterrows():\n",
        "            dt = pd.to_datetime(row[\"Data Previs√£o\"])\n",
        "            mask = (df_log[\"Date\"] == dt) & (df_log[\"Asset\"] == row[\"Ativo\"]) & (df_log[\"Timeframe\"] == row[\"Timeframe\"])\n",
        "            df_log.loc[mask, \"Acertou\"] = row[\"Acertou\"]\n",
        "\n",
        "        df_log.to_csv(results_file, index=False)\n",
        "        print(\"‚úÖ Log de previs√µes atualizado com coluna 'Acertou'.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao atualizar o prediction_log.csv com 'Acertou': {e}\")\n",
        "\n",
        "    return df_eval\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def clear_models(model_dir=\"/content/models\"):\n",
        "    import shutil\n",
        "\n",
        "    if os.path.exists(model_dir):\n",
        "        print(f\"üßπ Limpando todos os modelos salvos em: {model_dir}\")\n",
        "        shutil.rmtree(model_dir)\n",
        "        os.makedirs(model_dir, exist_ok=True)\n",
        "        print(\"‚úÖ Modelos deletados com sucesso.\")\n",
        "    else:\n",
        "        print(\"üìÇ Nenhuma pasta de modelos encontrada para limpar.\")\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def plot_prediction_performance_por_timeframe(log_path=\"/content/prediction_log.csv\"):\n",
        "    if not os.path.exists(log_path):\n",
        "        print(\"üì≠ Nenhum log encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(log_path)\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "    df = df.dropna(subset=[\"TargetPrice\", \"Price\", \"Timeframe\"])\n",
        "\n",
        "    for timeframe in df[\"Timeframe\"].unique():\n",
        "        df_tf = df[df[\"Timeframe\"] == timeframe].copy()\n",
        "        df_tf[\"Erro\"] = df_tf[\"Price\"] - df_tf[\"TargetPrice\"]\n",
        "        df_tf[\"AbsError\"] = abs(df_tf[\"Erro\"])\n",
        "        df_tf[\"Dia\"] = df_tf[\"Date\"].dt.date\n",
        "\n",
        "        if df_tf.empty:\n",
        "            continue\n",
        "\n",
        "        # Erro absoluto m√©dio por dia\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        df_grouped = df_tf.groupby(\"Dia\")[\"AbsError\"].mean()\n",
        "        plt.plot(df_grouped.index, df_grouped.values, marker=\"o\")\n",
        "        plt.title(f\"üìà Erro Absoluto M√©dio por Dia - {timeframe}\")\n",
        "        plt.xlabel(\"Data\")\n",
        "        plt.ylabel(\"Erro ($)\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"/tmp/erro_absoluto_{timeframe}.png\")\n",
        "        plt.close()\n",
        "\n",
        "        # Dispers√£o do valor previsto x real\n",
        "        plt.figure(figsize=(8, 4))\n",
        "        plt.scatter(df_tf[\"TargetPrice\"], df_tf[\"Price\"], alpha=0.6)\n",
        "        plt.plot([df_tf[\"TargetPrice\"].min(), df_tf[\"TargetPrice\"].max()],\n",
        "                 [df_tf[\"TargetPrice\"].min(), df_tf[\"TargetPrice\"].max()], 'r--', label=\"Perfeito\")\n",
        "        plt.title(f\"üéØ Previs√£o LSTM vs Pre√ßo Real - {timeframe}\")\n",
        "        plt.xlabel(\"Valor Previsto\")\n",
        "        plt.ylabel(\"Valor Real\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        path_img = f\"/tmp/previsao_vs_real_{timeframe}.png\"\n",
        "        plt.savefig(path_img)\n",
        "        plt.close()\n",
        "        print(f\"‚úÖ Gr√°fico salvo: {path_img}\")\n",
        "\n",
        "def enviar_graficos_desempenho_por_timeframe():\n",
        "    import glob\n",
        "    from pathlib import Path\n",
        "\n",
        "    timeframes = [\"15m\", \"1h\", \"1d\"]  # Edite se tiver outros\n",
        "    path_base = \"/tmp\"\n",
        "\n",
        "    for tf in timeframes:\n",
        "        # Gr√°fico 1: Previs√£o vs Real\n",
        "        grafico_pred = f\"{path_base}/previsao_vs_real_{tf}.png\"\n",
        "        if os.path.exists(grafico_pred):\n",
        "            with open(grafico_pred, \"rb\") as img:\n",
        "                url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                files = {\"photo\": img}\n",
        "                data = {\n",
        "                    \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                    \"caption\": f\"üìà Previs√£o LSTM vs Real ‚Äî {tf}\"\n",
        "                }\n",
        "                r = requests.post(url, data=data, files=files)\n",
        "                print(f\"‚úÖ Enviado: previsao_vs_real_{tf}.png\")\n",
        "\n",
        "        # Gr√°fico 2: Erro absoluto por dia\n",
        "        grafico_erro = f\"{path_base}/erro_absoluto_{tf}.png\"\n",
        "        if os.path.exists(grafico_erro):\n",
        "            with open(grafico_erro, \"rb\") as img:\n",
        "                url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "                files = {\"photo\": img}\n",
        "                data = {\n",
        "                    \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                    \"caption\": f\"üìä Erro Absoluto por Dia ‚Äî {tf}\"\n",
        "                }\n",
        "                r = requests.post(url, data=data, files=files)\n",
        "                print(f\"‚úÖ Enviado: erro_absoluto_{tf}.png\")\n",
        "\n",
        "def enviar_grafico_lucro_por_confianca(log_path=\"/content/prediction_log.csv\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if not os.path.exists(log_path):\n",
        "        print(\"üì≠ Nenhum log encontrado.\")\n",
        "        return\n",
        "\n",
        "    df = safe_read_csv(log_path)\n",
        "    if \"AdjustedProb\" not in df.columns or \"TP1\" not in df.columns or \"Price\" not in df.columns:\n",
        "        print(\"‚ö†Ô∏è Colunas necess√°rias n√£o encontradas no log.\")\n",
        "        return\n",
        "\n",
        "    df = df.dropna(subset=[\"AdjustedProb\", \"TP1\", \"Price\"])\n",
        "    df[\"LucroEstimado\"] = df[\"TP1\"] - df[\"Price\"]\n",
        "    df[\"FaixaConfian√ßa\"] = pd.cut(df[\"AdjustedProb\"], bins=[0, 0.6, 0.7, 0.8, 0.9, 1.0], labels=[\"‚â§60%\", \"60-70%\", \"70-80%\", \"80-90%\", \">90%\"])\n",
        "\n",
        "    lucro_medio = df.groupby(\"FaixaConfian√ßa\")[\"LucroEstimado\"].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    lucro_medio.plot(kind=\"bar\", color=\"skyblue\")\n",
        "    plt.title(\"üìä Lucro Estimado M√©dio por Faixa de Confian√ßa\")\n",
        "    plt.ylabel(\"Lucro Estimado ($)\")\n",
        "    plt.xlabel(\"Faixa de Confian√ßa Ajustada\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = \"/tmp/lucro_por_confianca.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "\n",
        "    with open(path, \"rb\") as img:\n",
        "        url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "        files = {\"photo\": img}\n",
        "        data = {\n",
        "            \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "            \"caption\": \"üìä Lucro m√©dio estimado por faixa de confian√ßa ajustada\"\n",
        "        }\n",
        "        response = requests.post(url, data=data, files=files)\n",
        "        if response.status_code == 200:\n",
        "            print(\"‚úÖ Gr√°fico de lucro por confian√ßa enviado.\")\n",
        "        else:\n",
        "            print(f\"‚ùå Falha ao enviar gr√°fico: {response.status_code} - {response.text}\")\n",
        "\n",
        "def adjust_signal_based_on_history(asset, timeframe, max_lookback=20, min_signals=5):\n",
        "    try:\n",
        "        df = safe_read_csv(\"prediction_log.csv\")\n",
        "        if df is None:\n",
        "            print(\"‚ö†Ô∏è Ignorando leitura do prediction_log.csv pois est√° vazio ou ausente.\")\n",
        "            return 1.0  # Retorna confian√ßa padr√£o\n",
        "\n",
        "        df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "        df = df[(df[\"Asset\"] == asset) & (df[\"Timeframe\"] == timeframe)]\n",
        "\n",
        "        if len(df) < min_signals or \"Acertou\" not in df.columns:\n",
        "            return 1.0\n",
        "\n",
        "        recent = df.sort_values(\"Date\", ascending=False).head(max_lookback)\n",
        "        acuracia = recent[\"Acertou\"].mean()\n",
        "        return acuracia\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao ajustar com hist√≥rico: {e}\")\n",
        "        return 1.0\n",
        "\n",
        "def gerar_grafico_previsao_vs_real(log_path=\"/content/prediction_log.csv\", output_path=\"/tmp/previsao_vs_real.png\"):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    df = safe_read_csv(log_path)\n",
        "    if df is None or df.empty or \"TargetPrice\" not in df.columns or \"Price\" not in df.columns:\n",
        "        print(\"‚ö†Ô∏è Log inv√°lido ou colunas ausentes.\")\n",
        "        return None\n",
        "\n",
        "    df = df.dropna(subset=[\"TargetPrice\", \"Price\"]).tail(20)  # √∫ltimos 20 sinais\n",
        "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df[\"Date\"], df[\"Price\"], label=\"üìà Pre√ßo Real\", marker=\"o\")\n",
        "    plt.plot(df[\"Date\"], df[\"TargetPrice\"], label=\"üîÆ Previs√£o LSTM\", marker=\"x\")\n",
        "    plt.title(\"üìä Previs√£o LSTM vs Pre√ßo Real\")\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Pre√ßo\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path)\n",
        "    plt.close()\n",
        "    print(f\"‚úÖ Gr√°fico salvo em: {output_path}\")\n",
        "    return output_path\n",
        "\n",
        "def enviar_grafico_previsao_real(df, timeframe):\n",
        "    import matplotlib.pyplot as plt\n",
        "    import os\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(df[\"Date\"], df[\"TargetPrice\"], label=\"LSTM Previsto\", marker=\"o\")\n",
        "    plt.plot(df[\"Date\"], df[\"Price\"], label=\"Pre√ßo Real\", marker=\"x\")\n",
        "    plt.title(f\"üìà Previs√£o LSTM vs Pre√ßo Real ({timeframe})\")\n",
        "    plt.xlabel(\"Data\")\n",
        "    plt.ylabel(\"Pre√ßo\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    image_path = f\"/tmp/previsao_vs_real_{timeframe}.png\"\n",
        "    plt.savefig(image_path)\n",
        "    plt.close()\n",
        "\n",
        "    with open(image_path, \"rb\") as img:\n",
        "        url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "        files = {\"photo\": img}\n",
        "        data = {\n",
        "            \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "            \"caption\": f\"üìâ Previs√£o LSTM vs Pre√ßo Real ({timeframe})\"\n",
        "        }\n",
        "        response = requests.post(url, data=data, files=files)\n",
        "        if response.status_code == 200:\n",
        "            print(\"‚úÖ Gr√°fico de previs√£o enviado.\")\n",
        "        else:\n",
        "            print(f\"‚ùå Erro ao enviar gr√°fico: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "\n",
        "def enviar_grafico_carteira():\n",
        "    image_path = \"/tmp/evolucao_carteira.png\"\n",
        "    if os.path.exists(image_path):\n",
        "        with open(image_path, \"rb\") as img:\n",
        "            url = f\"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendPhoto\"\n",
        "            files = {\"photo\": img}\n",
        "            data = {\n",
        "                \"chat_id\": TELEGRAM_CHAT_ID,\n",
        "                \"caption\": \"üíº Evolu√ß√£o da carteira virtual com base nos sinais do bot\"\n",
        "            }\n",
        "            response = requests.post(url, data=data, files=files)\n",
        "            if response.status_code == 200:\n",
        "                print(\"‚úÖ Gr√°fico da carteira enviado ao Telegram.\")\n",
        "            else:\n",
        "                print(f\"‚ùå Erro ao enviar imagem: {response.status_code} - {response.text}\")\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 5.1 CARTEIRA VIRTUAL PARA SIMULA√á√ÉO\n",
        "# ====================================================\n",
        "# ====================================================\n",
        "# 5.1 CARTEIRA VIRTUAL PARA SIMULA√á√ÉO\n",
        "# ====================================================\n",
        "\n",
        "carteira_virtual = {\n",
        "    \"capital_inicial\": 10000.0,\n",
        "    \"capital_atual\": 10000.0,\n",
        "    \"capital_maximo\": 10000.0,  # para c√°lculo de drawdown\n",
        "    \"historico_capital\": [],    # track evolu√ß√£o do capital\n",
        "    \"em_operacao\": False,\n",
        "}\n",
        "\n",
        "\n",
        "def to_scalar(val):\n",
        "    try:\n",
        "        if isinstance(val, pd.Series):\n",
        "            return float(val.iloc[0])\n",
        "        elif isinstance(val, (np.ndarray, list)):\n",
        "            return float(val[0])\n",
        "        elif val is None:\n",
        "            return np.nan\n",
        "        else:\n",
        "            return float(val)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Falha ao converter valor escalar: {val} | erro: {e}\")\n",
        "        return np.nan\n",
        "\n",
        "from datetime import timedelta\n",
        "import pytz\n",
        "\n",
        "from datetime import timedelta\n",
        "import pytz\n",
        "\n",
        "def simular_trade(row, df):\n",
        "    try:\n",
        "        asset = row[\"Asset\"]\n",
        "        timeframe = row[\"Timeframe\"]\n",
        "        signal_time = pd.to_datetime(row[\"Date\"])\n",
        "        preco_entrada = float(row[\"Price\"])\n",
        "        tp1 = float(row[\"TP1\"])\n",
        "        sl = float(row[\"SL\"])\n",
        "\n",
        "        # Ajustar timezone se necess√°rio\n",
        "        if df.index.tz is not None:\n",
        "            if signal_time.tzinfo is None:\n",
        "                signal_time = signal_time.replace(tzinfo=pytz.UTC)\n",
        "            else:\n",
        "                signal_time = signal_time.astimezone(pytz.UTC)\n",
        "\n",
        "        df_future = df[df.index >= signal_time]\n",
        "        if df_future.empty or \"Close\" not in df_future.columns:\n",
        "            raise ValueError(\"Candles futuros indispon√≠veis ou incompletos.\")\n",
        "\n",
        "        for i, (idx, candle) in enumerate(df_future.iterrows()):\n",
        "            preco_max = float(candle[\"High\"])\n",
        "            preco_min = float(candle[\"Low\"])\n",
        "\n",
        "            if row[\"Signal\"] == 1:\n",
        "                if preco_min <= sl:\n",
        "                    resultado = \"SL\"\n",
        "                    preco_saida = sl\n",
        "                    break\n",
        "                elif preco_max >= tp1:\n",
        "                    resultado = \"TP1\"\n",
        "                    preco_saida = tp1\n",
        "                    break\n",
        "            else:\n",
        "                if preco_max >= sl:\n",
        "                    resultado = \"SL\"\n",
        "                    preco_saida = sl\n",
        "                    break\n",
        "                elif preco_min <= tp1:\n",
        "                    resultado = \"TP1\"\n",
        "                    preco_saida = tp1\n",
        "                    break\n",
        "        else:\n",
        "            resultado = \"Sem alvo\"\n",
        "            preco_saida = df_future[\"Close\"].iloc[-1]\n",
        "\n",
        "        # üéØ C√°lculo de posi√ß√£o e lucro\n",
        "        capital_disponivel = carteira_virtual[\"capital_atual\"]\n",
        "        capital_por_trade = capital_disponivel * 0.10\n",
        "        quantidade = capital_por_trade / preco_entrada\n",
        "        lucro_total = (preco_saida - preco_entrada) * quantidade if row[\"Signal\"] == 1 else (preco_entrada - preco_saida) * quantidade\n",
        "        carteira_virtual[\"capital_atual\"] += lucro_total\n",
        "        carteira_virtual[\"historico_capital\"].append(carteira_virtual[\"capital_atual\"])\n",
        "\n",
        "        # üé¢ Drawdown\n",
        "        if carteira_virtual[\"capital_atual\"] > carteira_virtual[\"capital_maximo\"]:\n",
        "            carteira_virtual[\"capital_maximo\"] = carteira_virtual[\"capital_atual\"]\n",
        "        drawdown = 1 - (carteira_virtual[\"capital_atual\"] / carteira_virtual[\"capital_maximo\"])\n",
        "\n",
        "        roi = (carteira_virtual[\"capital_atual\"] / carteira_virtual[\"capital_inicial\"]) - 1\n",
        "        duracao = (idx - signal_time).total_seconds() / 60\n",
        "\n",
        "        return {\n",
        "            \"Resultado\": resultado,\n",
        "            \"PrecoSaida\": preco_saida,\n",
        "            \"LucroEstimado\": round(lucro_total, 2),\n",
        "            \"DuracaoMin\": round(duracao, 1),\n",
        "            \"Capital Atual\": round(carteira_virtual[\"capital_atual\"], 2),\n",
        "            \"Quantidade\": round(quantidade, 6),\n",
        "            \"ROI\": round(roi * 100, 2),\n",
        "            \"Drawdown\": round(drawdown * 100, 2)\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro inesperado na simula√ß√£o: {e}\")\n",
        "        return {\n",
        "            \"Resultado\": \"Erro\",\n",
        "            \"PrecoSaida\": None,\n",
        "            \"LucroEstimado\": None,\n",
        "            \"DuracaoMin\": None,\n",
        "            \"Capital Atual\": carteira_virtual[\"capital_atual\"],\n",
        "            \"Quantidade\": None,\n",
        "            \"ROI\": None,\n",
        "            \"Drawdown\": None\n",
        "        }\n",
        "\n",
        "\n",
        "def plotar_grafico_lucro(df):\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    df_valid = df[df[\"Resultado\"].isin([\"TP1\", \"SL\", \"Sem alvo\"])].copy()\n",
        "    if df_valid.empty:\n",
        "        print(\"‚ö†Ô∏è Nenhum resultado v√°lido para gr√°fico.\")\n",
        "        return\n",
        "\n",
        "    df_valid[\"FaixaConfian√ßa\"] = pd.cut(\n",
        "        df_valid[\"AdjustedProb\"].fillna(0.5),\n",
        "        bins=[0, 0.6, 0.75, 0.9, 1.01],\n",
        "        labels=[\"<60%\", \"60-75%\", \"75-90%\", \">90%\"]\n",
        "    )\n",
        "\n",
        "    lucro_medio = df_valid.groupby(\"FaixaConfian√ßa\")[\"LucroEstimado\"].mean()\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    lucro_medio.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
        "    plt.title(\"üìä Lucro M√©dio por Faixa de Confian√ßa\")\n",
        "    plt.ylabel(\"Lucro Estimado\")\n",
        "    plt.xlabel(\"Faixa de Confian√ßa\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = \"lucro_por_faixa.png\"\n",
        "    plt.savefig(path)\n",
        "    plt.close()\n",
        "    print(\"‚úÖ Gr√°fico de lucro por confian√ßa enviado.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def simular_todos_trades(prediction_log_path=\"prediction_log.csv\", df_candles=None, timeframe=\"15m\"):\n",
        "    print(\"üìä Rodando simula√ß√£o de carteira virtual com sinais do log...\")\n",
        "\n",
        "    if not os.path.exists(prediction_log_path):\n",
        "        print(\"‚ö†Ô∏è Log de previs√µes n√£o encontrado.\")\n",
        "        return\n",
        "\n",
        "    df_log = safe_read_csv(prediction_log_path)\n",
        "    if df_log is None or df_log.empty:\n",
        "        print(\"‚ö†Ô∏è Log vazio.\")\n",
        "        return\n",
        "\n",
        "    df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"])\n",
        "\n",
        "    intervalo_futuro = {\n",
        "        \"15m\": timedelta(minutes=15 * 5),\n",
        "        \"1h\": timedelta(hours=5),\n",
        "        \"4h\": timedelta(hours=20),\n",
        "        \"1d\": timedelta(days=5)\n",
        "    }.get(timeframe, timedelta(hours=1))\n",
        "\n",
        "    now = datetime.utcnow()\n",
        "    resultados = []\n",
        "\n",
        "    for _, row in df_log.iterrows():\n",
        "        signal_time = pd.to_datetime(row[\"Date\"])\n",
        "        if (now - signal_time) < intervalo_futuro:\n",
        "            continue  # sinal ainda recente\n",
        "\n",
        "        try:\n",
        "            resultado = simular_trade(row, df_candles)\n",
        "            for key, value in resultado.items():\n",
        "                row[key] = value\n",
        "            resultados.append(row)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro inesperado na simula√ß√£o: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not resultados:\n",
        "        print(\"üì≠ Nenhum trade foi simulado (ainda).\")\n",
        "        return\n",
        "\n",
        "    df_resultados = pd.DataFrame(resultados)\n",
        "    df_resultados.to_csv(prediction_log_path, index=False)\n",
        "    print(f\"üìã Log de previs√µes atualizado com resultados e capital: {prediction_log_path}\")\n",
        "    plotar_grafico_lucro(df_resultados)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def salvar_grafico_evolucao():\n",
        "    import pandas as pd\n",
        "    import os\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if not os.path.exists(\"trades_simulados.csv\"):\n",
        "        print(\"‚ùå Arquivo de simula√ß√£o n√£o encontrado.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = safe_read_csv(\"trades_simulados.csv\")\n",
        "        if df.empty or \"Data Entrada\" not in df.columns:\n",
        "            print(\"‚ö†Ô∏è Arquivo vazio ou colunas ausentes.\")\n",
        "            return\n",
        "\n",
        "        df[\"Data Entrada\"] = pd.to_datetime(df[\"Data Entrada\"], errors=\"coerce\")\n",
        "        df = df[df[\"Data Entrada\"].dt.year >= 2000]\n",
        "        if df.empty:\n",
        "            print(\"‚ö†Ô∏è Nenhum dado recente dispon√≠vel para o gr√°fico.\")\n",
        "            return\n",
        "\n",
        "        # Escolhe a cor de cada ponto com base no resultado do trade\n",
        "        cor_map = {\n",
        "            \"TP1\": \"green\",\n",
        "            \"SL\": \"red\",\n",
        "            \"Sem alvo\": \"orange\"\n",
        "        }\n",
        "        cores = df[\"Resultado\"].map(cor_map).fillna(\"gray\")\n",
        "\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.scatter(df[\"Data Entrada\"], df[\"Capital Atual\"], c=cores, s=70, label=\"Capital\", edgecolors='black')\n",
        "        plt.plot(df[\"Data Entrada\"], df[\"Capital Atual\"], linestyle=\"--\", alpha=0.5)\n",
        "        plt.title(\"üí∞ Evolu√ß√£o da Carteira Virtual\")\n",
        "        plt.xlabel(\"Data\")\n",
        "        plt.ylabel(\"Capital ($)\")\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        image_path = \"/tmp/evolucao_carteira.png\"\n",
        "        plt.savefig(image_path)\n",
        "        plt.close()\n",
        "        print(\"‚úÖ Gr√°fico salvo em:\", image_path)\n",
        "\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(\"‚ö†Ô∏è trades_simulados.csv est√° vazio.\")\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 6. EXECU√á√ÉO DAS AN√ÅLISES E ALERTAS\n",
        "# ====================================================\n",
        "\n",
        "def run_analysis(\n",
        "    selected_timeframes=None,\n",
        "    plot_timeframes=[\"15m\", \"1h\"],\n",
        "    alert_timeframes=[\"15m\", \"1h\", \"1d\"],\n",
        "    retrain_models=False\n",
        "):\n",
        "    criar_prediction_log_padrao()\n",
        "\n",
        "    if selected_timeframes is None:\n",
        "        selected_timeframes = TIMEFRAMES\n",
        "\n",
        "    results = []\n",
        "    houve_alerta = False\n",
        "\n",
        "    for asset in ASSETS:\n",
        "        print(f\"\\nüìä Analisando {asset}...\")\n",
        "        models = {}\n",
        "        lstm_models = {}\n",
        "        data = {}\n",
        "\n",
        "        try:\n",
        "            for tf in selected_timeframes:\n",
        "                interval = tf['interval']\n",
        "                period = tf['period']\n",
        "                df = get_stock_data(asset, interval, period)\n",
        "                df = calculate_indicators(df)\n",
        "                data[interval] = df\n",
        "\n",
        "                if retrain_models:\n",
        "                    models[interval] = train_ml_model(df, asset=asset, interval=interval, verbose=True)\n",
        "                else:\n",
        "                    models[interval] = load_xgb_model(asset, interval)\n",
        "                    if models[interval] is None:\n",
        "                        models[interval] = train_ml_model(df, asset=asset, interval=interval, verbose=True)\n",
        "\n",
        "                lstm_models[interval] = train_lstm_model(df, asset=asset, interval=interval, window_size=20, force_retrain=retrain_models)\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Erro ao processar {asset}: {e}\")\n",
        "            continue\n",
        "\n",
        "        if all(model is None for model in models.values()):\n",
        "            print(f\"‚ö†Ô∏è Nenhum modelo foi treinado para {asset}.\")\n",
        "            continue\n",
        "\n",
        "        for tf in selected_timeframes:\n",
        "            interval = tf['interval']\n",
        "            latest_data = data[interval].iloc[-1]\n",
        "            current_price = data[interval][\"Close\"].iloc[-1]\n",
        "\n",
        "            predicted_price_lstm = None\n",
        "            pred_high = None\n",
        "            pred_low = None\n",
        "            try:\n",
        "                lstm_model = lstm_models.get(interval)\n",
        "                if lstm_model:\n",
        "                    pred_lstm = predict_with_lstm(lstm_model, data[interval])\n",
        "                    predicted_price_lstm = pred_lstm.get(\"Close\")\n",
        "                    pred_high = pred_lstm.get(\"High\")\n",
        "                    pred_low = pred_lstm.get(\"Low\")\n",
        "            except Exception as e:\n",
        "                print(f\"[!] Erro na previs√£o LSTM: {e}\")\n",
        "\n",
        "            print(f\"üîç Pre√ßo atual ({interval}): ${current_price:,.2f}\")\n",
        "            if predicted_price_lstm is not None and not np.isnan(predicted_price_lstm):\n",
        "                variation = round((predicted_price_lstm - current_price) / current_price * 100, 2)\n",
        "                print(f\"üîÆ Previs√£o LSTM: ${predicted_price_lstm:,.2f}\")\n",
        "                print(f\"üìà Varia√ß√£o prevista: {variation:+.2f}%\")\n",
        "            else:\n",
        "                print(\"üîÆ Previs√£o LSTM: Indispon√≠vel ou inv√°lida.\")\n",
        "                variation = 0.0\n",
        "\n",
        "            if predicted_price_lstm and not np.isnan(predicted_price_lstm) and pred_high and pred_low:\n",
        "                margem = current_price * 0.005\n",
        "                if pred_high >= current_price + margem:\n",
        "                    prediction = 1  # Compra\n",
        "                elif pred_low <= current_price - margem:\n",
        "                    prediction = 0  # Venda\n",
        "                else:\n",
        "                    prediction = -1  # Neutro\n",
        "            else:\n",
        "                prediction = -1\n",
        "\n",
        "            targets = calculate_targets(current_price, prediction, tf['atr'])\n",
        "            explanation = generate_explanation(latest_data, prediction)\n",
        "            rr_ratio = round((targets['TP1'] - current_price) / (current_price - targets['SL']), 2) if prediction == 1 else \\\n",
        "                       round((current_price - targets['TP1']) / (targets['SL'] - current_price), 2) if prediction == 0 else \"-\"\n",
        "\n",
        "            ajuste = adjust_signal_based_on_history(asset, interval)\n",
        "            model_xgb = models.get(interval)\n",
        "            val_score = model_xgb.validation_score if model_xgb and hasattr(model_xgb, \"validation_score\") else {}\n",
        "\n",
        "            result = {\n",
        "                \"Asset\": asset,\n",
        "                \"Timeframe\": interval,\n",
        "                \"Date\": datetime.now(),\n",
        "                \"Price\": current_price,\n",
        "                \"Signal\": prediction,\n",
        "                \"Confidence\": None,\n",
        "                \"AdjustedProb\": round(ajuste, 2),\n",
        "                \"TP1\": targets['TP1'],\n",
        "                \"TP2\": targets['TP2'],\n",
        "                \"SL\": targets['SL'],\n",
        "                \"Accuracy\": val_score.get(\"accuracy\"),\n",
        "                \"Precision\": val_score.get(\"precision\"),\n",
        "                \"Recall\": val_score.get(\"recall\"),\n",
        "                \"F1\": val_score.get(\"f1\"),\n",
        "                \"LSTM_Predicted\": predicted_price_lstm,\n",
        "                \"TargetPrice\": predicted_price_lstm,\n",
        "                \"LSTM_High_Predicted\": pred_high,\n",
        "                \"LSTM_Low_Predicted\": pred_low\n",
        "            }\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            if interval in alert_timeframes:\n",
        "                if prediction in [0, 1]:\n",
        "                    trend_emoji = \"üü¢\" if prediction == 1 else \"üî¥\"\n",
        "                    trend_text = \"COMPRA\" if prediction == 1 else \"VENDA\"\n",
        "                    message = f\"\"\"\n",
        "üì¢ <b>SINAL DETECTADO</b>\n",
        "\n",
        "ü™ô <b>Ativo:</b> {asset}\n",
        "üïí <b>Timeframe:</b> {interval}\n",
        "{trend_emoji} <b>Tend√™ncia (via LSTM):</b> {trend_text}\n",
        "\n",
        "üí∞ <b>Pre√ßo Atual:</b> ${current_price:,.2f}\n",
        "üîÆ <b>Previs√£o LSTM (Fechamento):</b> ${predicted_price_lstm:,.2f} ({variation:+.2f}%)\n",
        "üìà <b>Alta Prevista (High):</b> ${pred_high:,.2f}\n",
        "üìâ <b>Baixa Prevista (Low):</b> ${pred_low:,.2f}\n",
        "üéØ <b>TP1:</b> ${targets['TP1']:,.2f}\n",
        "üéØ <b>TP2:</b> ${targets['TP2']:,.2f}\n",
        "üõë <b>Stop Loss:</b> ${targets['SL']:,.2f}\n",
        "\n",
        "üìã <b>Justificativa T√©cnica:</b>\n",
        "{explanation}\n",
        "\n",
        "üìä <b>Risco/Retorno estimado:</b> {rr_ratio}\n",
        "üß† <b>Confian√ßa hist√≥rica:</b> {ajuste*100:.1f}%\n",
        "üóì <b>V√°lido at√©:</b> {(datetime.now() + timedelta(minutes=15)).strftime('%d/%m %H:%M')}\n",
        "\"\"\"\n",
        "                    try:\n",
        "                        send_telegram_message(message)\n",
        "                        print(\"üì® Alerta enviado para o Telegram!\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ùå Erro ao enviar mensagem: {e}\")\n",
        "\n",
        "                    try:\n",
        "                        df_log = safe_read_csv(\"/content/prediction_log.csv\")\n",
        "                        if df_log is not None:\n",
        "                            df_log = df_log[df_log[\"Timeframe\"] == interval]\n",
        "                            df_log = df_log.dropna(subset=[\"TargetPrice\", \"Price\"])\n",
        "                            df_log[\"Date\"] = pd.to_datetime(df_log[\"Date\"])\n",
        "                            df_recent = df_log.sort_values(\"Date\").tail(20)\n",
        "                            enviar_grafico_previsao_real(df_recent, interval)\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Erro ao enviar gr√°fico de previs√£o: {e}\")\n",
        "\n",
        "                    try:\n",
        "                        salvar_grafico_evolucao()\n",
        "                        enviar_grafico_carteira()\n",
        "                    except Exception as e:\n",
        "                        print(f\"‚ö†Ô∏è Erro ao enviar gr√°fico da carteira: {e}\")\n",
        "\n",
        "                    houve_alerta = True\n",
        "                else:\n",
        "                    print(\"‚õî Previs√£o LSTM neutra ‚Äî alerta n√£o enviado.\")\n",
        "            else:\n",
        "                print(\"‚õî Timeframe fora da lista de alertas.\")\n",
        "\n",
        "    df_results = pd.DataFrame(results)\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"model_results_{timestamp}.csv\"\n",
        "    df_results.to_csv(filename, index=False)\n",
        "    print(f\"\\nüìÅ Resultados salvos em: {filename}\")\n",
        "\n",
        "    log_path = \"/content/prediction_log.csv\"\n",
        "    df_log_old = safe_read_csv(log_path)\n",
        "\n",
        "    if df_log_old is not None:\n",
        "        df_log_combined = pd.concat([df_log_old, df_results], ignore_index=True).fillna(\"\")\n",
        "        df_log_combined.to_csv(log_path, index=False)\n",
        "        print(f\"üìã Log de previs√µes atualizado em: {log_path}\")\n",
        "    else:\n",
        "        df_results.to_csv(log_path, index=False)\n",
        "        print(f\"üîÑ Log de previs√µes criado em: {log_path}\")\n",
        "\n",
        "    print(\"‚úÖ An√°lise completa.\")\n",
        "\n",
        "    try:\n",
        "        df_log = safe_read_csv(log_path)\n",
        "        if df_log is not None and not df_log.empty:\n",
        "            colunas = [\"Date\", \"Asset\", \"Timeframe\", \"Price\", \"Signal\",\n",
        "                       \"LSTM_High_Predicted\", \"LSTM_Low_Predicted\", \"LSTM_Predicted\",\n",
        "                       \"TP1\", \"TP2\", \"SL\", \"TargetPrice\", \"AdjustedProb\"]\n",
        "            colunas_disponiveis = [c for c in colunas if c in df_log.columns]\n",
        "            df_log = df_log[colunas_disponiveis].tail(5)\n",
        "            print(\"\\nüß™ √öltimos sinais registrados no log:\")\n",
        "            print(df_log.to_string(index=False))\n",
        "        else:\n",
        "            print(\"üóï Log de previs√µes est√° vazio ou inv√°lido.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao exibir √∫ltimos sinais: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# 7. AGENDAMENTO E EXECU√á√ÉO AUTOM√ÅTICA\n",
        "# ====================================================\n",
        "\n",
        "def is_time_to_run(interval):\n",
        "    now = datetime.now()\n",
        "    if interval == \"15m\":\n",
        "        return now.minute % 15 == 0\n",
        "    elif interval == \"1h\":\n",
        "        return now.minute == 0\n",
        "    elif interval == \"1d\":\n",
        "        return now.hour == 8 and now.minute == 0\n",
        "    elif interval == \"1wk\":\n",
        "        return now.weekday() == 0 and now.hour == 8 and now.minute == 0  # Segunda 8h\n",
        "    return False\n",
        "# üöÄ Execu√ß√£o cont√≠nua: Verifica os timeframes a cada minuto\n",
        "while True:\n",
        "    now = datetime.now()\n",
        "    print(f\"\\n‚è∞ Verificando timeframes - {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    for tf in TIMEFRAMES:\n",
        "        interval = tf[\"interval\"]\n",
        "        if is_time_to_run(interval):\n",
        "            print(f\"\\nüöÄ Rodando an√°lise para timeframe {interval}...\")\n",
        "            try:\n",
        "                run_analysis(\n",
        "                    selected_timeframes=[tf],\n",
        "                    plot_timeframes=[\"1h\"],           # Gr√°ficos apenas para timeframes desejados\n",
        "                    alert_timeframes=[\"15m\", \"1h\", \"1d\", \"1wk\"]\n",
        "\n",
        "                )\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro durante a an√°lise de {interval}: {e}\")\n",
        "        else:\n",
        "            print(f\"‚è≥ Ainda n√£o √© hora para {interval}...\")\n",
        "\n",
        "    time.sleep(60)  # Espera 1 minuto antes de verificar de novo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "_FRgd1-k06BB",
        "outputId": "c6791905-6ff0-4719-9896-ab56383c644d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è∞ Verificando timeframes - 2025-04-22 09:28:33\n",
            "‚è≥ Ainda n√£o √© hora para 15m...\n",
            "‚è≥ Ainda n√£o √© hora para 1h...\n",
            "‚è≥ Ainda n√£o √© hora para 1d...\n",
            "‚è≥ Ainda n√£o √© hora para 1wk...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-641db81b7d9e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1625\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚è≥ Ainda n√£o √© hora para {interval}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Espera 1 minuto antes de verificar de novo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[{\"interval\": \"1wk\", \"period\": \"max\", \"atr\": 0.08}],\n",
        "    plot_timeframes=[\"1wk\"],\n",
        "    alert_timeframes=[\"1wk\"],\n",
        "    retrain_models=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmHNYau_4KrU",
        "outputId": "2d823932-3efc-4ffc-9c6c-71c1fd3e02e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Analisando BTC-USD...\n",
            "‚úÖ X.shape: (136, 20, 23), y.shape: (136, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Modelo LSTM salvo em: /content/models/lstm_model_BTCUSD_1wk.h5\n",
            "üì¶ Metadados salvos em: /content/models/lstm_model_BTCUSD_1wk_meta.pkl\n",
            "‚úÖ Features usadas no LSTM:\n",
            "['Close', 'High', 'Low', 'RSI', 'MACD', 'MACD_Signal', 'SMA_50', 'SMA_200', 'Bollinger_Upper', 'Bollinger_Lower', 'ADX', 'Stoch_K', 'Stoch_D', 'ATR', 'ROC', 'OBV', 'CCI', 'Tenkan_Sen', 'Kijun_Sen', 'VWAP', 'Doji', 'Engulfing', 'Hammer']\n",
            "‚úÖ √öltimos dados de entrada:\n",
            "            Close          High           Low        RSI         MACD  \\\n",
            "352  83684.976562  86015.187500  74436.679688  48.522502  1352.632165   \n",
            "353  85174.304688  86429.351562  83100.617188  49.942541  1117.494919   \n",
            "354  88508.218750  88600.156250  85143.835938  53.063864  1186.488856   \n",
            "\n",
            "     MACD_Signal        SMA_50       SMA_200  Bollinger_Upper  \\\n",
            "352  4319.049361  76911.316484  45830.698223    108573.362683   \n",
            "353  3678.738472  77334.179922  46078.078262    108215.103774   \n",
            "354  3180.288549  77875.376406  46347.371133    107138.613251   \n",
            "\n",
            "     Bollinger_Lower  ...          ATR        ROC           OBV         CCI  \\\n",
            "352     77664.700598  ...  9742.600381 -17.217034  5.662843e+12 -122.511781   \n",
            "353     76812.411070  ...  9284.467095 -17.050807  5.818521e+12  -75.495228   \n",
            "354     76616.121905  ...  8868.170896  -9.397947  5.898461e+12  -45.069435   \n",
            "\n",
            "       Tenkan_Sen     Kijun_Sen          VWAP  Doji  Engulfing  Hammer  \n",
            "352  86967.324219  85778.517578  40139.990893     0          0       0  \n",
            "353  86967.324219  87151.458984  40236.450036     0          0       0  \n",
            "354  85470.066406  87959.265625  40288.601549     0          0       0  \n",
            "\n",
            "[3 rows x 23 columns]\n",
            "‚úÖ Valores m√≠nimos do scaler X:\n",
            "[ 1.62918320e+04  1.67714746e+04  1.55990469e+04  2.56706772e+01\n",
            " -6.32228147e+03 -5.46928874e+03  2.19973323e+04  2.17470938e+04\n",
            "  2.18393071e+04  1.25309582e+04  1.54606866e+01  1.26902039e+00\n",
            "  7.39493036e+00  1.94586510e+03 -5.61019747e+01  2.93377846e+12\n",
            " -2.34908718e+02  1.83261465e+04  2.03665820e+04  2.75480815e+04\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "‚úÖ Valores m√°ximos do scaler X:\n",
            "[1.04298695e+05 1.09114883e+05 9.94713594e+04 8.83009987e+01\n",
            " 1.03741539e+04 9.23561821e+03 7.78753764e+04 4.63473711e+04\n",
            " 1.16917754e+05 8.11203445e+04 5.91406614e+01 9.89660529e+01\n",
            " 9.60911186e+01 9.99761583e+03 7.73833160e+01 6.89707045e+12\n",
            " 2.97764776e+02 9.91874922e+04 8.79592656e+04 4.02886015e+04\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            "üíæ Modelo XGBoost salvo em: /content/models/xgb_model_BTCUSD_1wk.joblib\n",
            "‚úÖ X.shape: (335, 20, 23), y.shape: (335, 3)\n",
            "üìÇ Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_1wk.h5\n",
            "üì¶ Metadados carregados de: /content/models/lstm_model_BTCUSD_1wk_meta.pkl\n",
            "üîç Pre√ßo atual (1wk): $88,508.22\n",
            "üîÆ Previs√£o LSTM: $95,571.21\n",
            "üìà Varia√ß√£o prevista: +7.98%\n",
            "üì® Mensagem enviada com sucesso!\n",
            "üì® Alerta enviado para o Telegram!\n",
            "‚úÖ Gr√°fico de previs√£o enviado.\n",
            "‚ùå Arquivo de simula√ß√£o n√£o encontrado.\n",
            "\n",
            "üìÅ Resultados salvos em: model_results_2025-04-22_09-42-56.csv\n",
            "üìã Log de previs√µes atualizado em: /content/prediction_log.csv\n",
            "‚úÖ An√°lise completa.\n",
            "\n",
            "üß™ √öltimos sinais registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1       TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-22 09:33:52.908958 BTC-USD       15m 88477.242188      -1         88227.242188        88454.375000    88144.218750 86707.70  84938.15 90246.79 88144.218750           1.0\n",
            "2025-04-22 09:39:19.621634 BTC-USD        1h 88485.898438       1         89581.375000        88112.812500    88271.398438 91140.48  93795.05 85831.32 88271.398438           1.0\n",
            "2025-04-22 09:41:35.000400 BTC-USD        1d 88490.742188       0         84370.265625        81402.593750    85121.515625 84066.21  79641.67 92915.28 85121.515625           1.0\n",
            "2025-04-22 09:42:54.960985 BTC-USD       1wk 88508.218750       1         89080.445312        94586.546875    95571.210938 95588.88 102669.53 81427.56 95571.210938           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[{\"interval\": \"1d\", \"period\": \"1000d\", \"atr\": 0.05}],\n",
        "    plot_timeframes=[\"1d\"],\n",
        "    alert_timeframes=[\"1d\"],\n",
        "    retrain_models=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lZAmWtI3rf7",
        "outputId": "e7cb021b-ebec-4d4e-bd41-ede8602a34ad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Analisando BTC-USD...\n",
            "‚úÖ X.shape: (582, 20, 23), y.shape: (582, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Modelo LSTM salvo em: /content/models/lstm_model_BTCUSD_1d.h5\n",
            "üì¶ Metadados salvos em: /content/models/lstm_model_BTCUSD_1d_meta.pkl\n",
            "‚úÖ Features usadas no LSTM:\n",
            "['Close', 'High', 'Low', 'RSI', 'MACD', 'MACD_Signal', 'SMA_50', 'SMA_200', 'Bollinger_Upper', 'Bollinger_Lower', 'ADX', 'Stoch_K', 'Stoch_D', 'ATR', 'ROC', 'OBV', 'CCI', 'Tenkan_Sen', 'Kijun_Sen', 'VWAP', 'Doji', 'Engulfing', 'Hammer']\n",
            "‚úÖ √öltimos dados de entrada:\n",
            "            Close          High           Low        RSI        MACD  \\\n",
            "798  85174.304688  85306.382812  83976.843750  53.214385  131.780245   \n",
            "799  87518.906250  88460.093750  85143.835938  58.115191  404.107847   \n",
            "800  88490.742188  88600.156250  87286.664062  59.986190  690.390084   \n",
            "\n",
            "     MACD_Signal        SMA_50       SMA_200  Bollinger_Upper  \\\n",
            "798  -374.289173  84191.161875  88086.381016     87894.493961   \n",
            "799  -218.609769  84056.572969  88220.178535     88320.599299   \n",
            "800   -36.809799  84105.074375  88352.294863     89121.246613   \n",
            "\n",
            "     Bollinger_Lower  ...          ATR        ROC           OBV         CCI  \\\n",
            "798     77928.968539  ...  3103.260465  11.671855  6.479581e+11   66.361516   \n",
            "799     77737.836638  ...  3118.474562   5.988514  6.893543e+11  132.393323   \n",
            "800     77537.692450  ...  2989.547249  11.132778  7.278119e+11  152.411821   \n",
            "\n",
            "       Tenkan_Sen     Kijun_Sen          VWAP  Doji  Engulfing  Hammer  \n",
            "798  84599.363281  81451.816406  65484.977259     1          0       1  \n",
            "799  85743.550781  81451.816406  65521.935868     0          0       0  \n",
            "800  85850.386719  81518.417969  65557.882853     0          0       0  \n",
            "\n",
            "[3 rows x 23 columns]\n",
            "‚úÖ Valores m√≠nimos do scaler X:\n",
            "[ 2.51626543e+04  2.58583750e+04  2.49302969e+04  2.46849696e+01\n",
            " -3.53684375e+03 -3.18840330e+03  2.64460345e+04  2.75015102e+04\n",
            "  2.70226518e+04  2.40995703e+04  1.15995189e+01  0.00000000e+00\n",
            "  6.00577783e+00  5.38589885e+02 -1.89724787e+01 -1.85094612e+11\n",
            " -4.21139903e+02  2.56721514e+04  2.62095303e+04  2.69563181e+04\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "‚úÖ Valores m√°ximos do scaler X:\n",
            "[1.06146266e+05 1.09114883e+05 1.05291734e+05 8.78702958e+01\n",
            " 7.04921763e+03 6.42778414e+03 9.92817217e+04 8.83522949e+04\n",
            " 1.08849355e+05 9.85180446e+04 7.02950856e+01 1.00000000e+02\n",
            " 9.74367724e+01 5.08319166e+03 3.35444079e+01 1.04991108e+12\n",
            " 3.44478605e+02 1.04293121e+05 1.00178887e+05 6.55578829e+04\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            "üíæ Modelo XGBoost salvo em: /content/models/xgb_model_BTCUSD_1d.joblib\n",
            "‚úÖ X.shape: (781, 20, 23), y.shape: (781, 3)\n",
            "üìÇ Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_1d.h5\n",
            "üì¶ Metadados carregados de: /content/models/lstm_model_BTCUSD_1d_meta.pkl\n",
            "üîç Pre√ßo atual (1d): $88,490.74\n",
            "üîÆ Previs√£o LSTM: $85,121.52\n",
            "üìà Varia√ß√£o prevista: -3.81%\n",
            "üì® Mensagem enviada com sucesso!\n",
            "üì® Alerta enviado para o Telegram!\n",
            "‚úÖ Gr√°fico de previs√£o enviado.\n",
            "‚ùå Arquivo de simula√ß√£o n√£o encontrado.\n",
            "\n",
            "üìÅ Resultados salvos em: model_results_2025-04-22_09-41-36.csv\n",
            "üìã Log de previs√µes atualizado em: /content/prediction_log.csv\n",
            "‚úÖ An√°lise completa.\n",
            "\n",
            "üß™ √öltimos sinais registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-22 09:33:52.908958 BTC-USD       15m 88477.242188      -1         88227.242188         88454.37500    88144.218750 86707.70 84938.15 90246.79 88144.218750           1.0\n",
            "2025-04-22 09:39:19.621634 BTC-USD        1h 88485.898438       1         89581.375000         88112.81250    88271.398438 91140.48 93795.05 85831.32 88271.398438           1.0\n",
            "2025-04-22 09:41:35.000400 BTC-USD        1d 88490.742188       0         84370.265625         81402.59375    85121.515625 84066.21 79641.67 92915.28 85121.515625           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[{\"interval\": \"1h\", \"period\": \"90d\", \"atr\": 0.03}],\n",
        "    plot_timeframes=[\"1h\"],\n",
        "    alert_timeframes=[\"1h\"],\n",
        "    retrain_models=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coST15vd3E71",
        "outputId": "807433f0-6eeb-4f27-f44a-8199708830cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Adicionando colunas faltantes: ['Acertou', 'Resultado', 'PrecoSaida', 'LucroEstimado', 'DuracaoMin']\n",
            "\n",
            "üìä Analisando BTC-USD...\n",
            "‚úÖ X.shape: (721, 20, 23), y.shape: (721, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Modelo LSTM salvo em: /content/models/lstm_model_BTCUSD_1h.h5\n",
            "üì¶ Metadados salvos em: /content/models/lstm_model_BTCUSD_1h_meta.pkl\n",
            "‚úÖ Features usadas no LSTM:\n",
            "['Close', 'High', 'Low', 'RSI', 'MACD', 'MACD_Signal', 'SMA_50', 'SMA_200', 'Bollinger_Upper', 'Bollinger_Lower', 'ADX', 'Stoch_K', 'Stoch_D', 'ATR', 'ROC', 'OBV', 'CCI', 'Tenkan_Sen', 'Kijun_Sen', 'VWAP', 'Doji', 'Engulfing', 'Hammer']\n",
            "‚úÖ √öltimos dados de entrada:\n",
            "            Close          High           Low        RSI        MACD  \\\n",
            "937  88456.234375  88456.234375  88171.218750  65.765500  565.465792   \n",
            "938  88398.929688  88644.320312  88338.664062  64.869333  575.308873   \n",
            "939  88485.898438  88518.875000  88339.195312  65.634698  583.402140   \n",
            "\n",
            "     MACD_Signal        SMA_50       SMA_200  Bollinger_Upper  \\\n",
            "937   528.804603  86154.791719  82975.695547     88554.774162   \n",
            "938   538.105457  86224.019531  83007.357188     88668.713442   \n",
            "939   547.164794  86302.746563  83035.873516     88783.194650   \n",
            "\n",
            "     Bollinger_Lower  ...         ATR       ROC           OBV         CCI  \\\n",
            "937     86530.907088  ...  516.711371  0.326230  4.854679e+10  148.071246   \n",
            "938     86523.642027  ...  501.636005  0.370210  3.991045e+10  137.903262   \n",
            "939     86503.601444  ...  478.639125  1.612084  4.404061e+10  115.219512   \n",
            "\n",
            "       Tenkan_Sen     Kijun_Sen          VWAP  Doji  Engulfing  Hammer  \n",
            "937  87578.835938  86570.863281  88276.087318     0          0       0  \n",
            "938  87694.019531  86735.164062  88277.632096     0          0       0  \n",
            "939  87806.218750  86895.968750  88278.311322     0          0       0  \n",
            "\n",
            "[3 rows x 23 columns]\n",
            "‚úÖ Valores m√≠nimos do scaler X:\n",
            "[ 7.48302969e+04  7.52768906e+04  7.44677031e+04  1.58830428e+01\n",
            " -2.16721538e+03 -1.88043774e+03  7.82208620e+04  8.21645653e+04\n",
            "  7.95581637e+04  7.27506554e+04  7.04921005e+00  0.00000000e+00\n",
            "  1.40644692e+00  3.33533128e+02 -1.02878051e+01 -3.75431475e+10\n",
            " -3.14805470e+02  7.59839336e+04  7.77893594e+04  8.82754008e+04\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "‚úÖ Valores m√°ximos do scaler X:\n",
            "[9.93920000e+04 9.94737266e+04 9.88440781e+04 8.19544450e+01\n",
            " 2.88036931e+03 2.38800449e+03 9.69209500e+04 9.76456252e+04\n",
            " 1.00089865e+05 9.67738256e+04 6.04090612e+01 1.00000000e+02\n",
            " 9.79953131e+01 1.71254249e+03 1.47208765e+01 4.85467884e+10\n",
            " 3.29137960e+02 9.87940820e+04 9.80049375e+04 9.71269711e+04\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            "üíæ Modelo XGBoost salvo em: /content/models/xgb_model_BTCUSD_1h.joblib\n",
            "‚úÖ X.shape: (920, 20, 23), y.shape: (920, 3)\n",
            "üìÇ Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_1h.h5\n",
            "üì¶ Metadados carregados de: /content/models/lstm_model_BTCUSD_1h_meta.pkl\n",
            "üîç Pre√ßo atual (1h): $88,485.90\n",
            "üîÆ Previs√£o LSTM: $88,271.40\n",
            "üìà Varia√ß√£o prevista: -0.24%\n",
            "üì® Mensagem enviada com sucesso!\n",
            "üì® Alerta enviado para o Telegram!\n",
            "‚úÖ Gr√°fico de previs√£o enviado.\n",
            "‚ùå Arquivo de simula√ß√£o n√£o encontrado.\n",
            "\n",
            "üìÅ Resultados salvos em: model_results_2025-04-22_09-39-21.csv\n",
            "üìã Log de previs√µes atualizado em: /content/prediction_log.csv\n",
            "‚úÖ An√°lise completa.\n",
            "\n",
            "üß™ √öltimos sinais registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted      TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-22 09:33:52.908958 BTC-USD       15m 88477.242188      -1         88227.242188          88454.3750    88144.218750 86707.70 84938.15 90246.79 88144.218750           1.0\n",
            "2025-04-22 09:39:19.621634 BTC-USD        1h 88485.898438       1         89581.375000          88112.8125    88271.398438 91140.48 93795.05 85831.32 88271.398438           1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_analysis(\n",
        "    selected_timeframes=[{\"interval\": \"15m\", \"period\": \"30d\", \"atr\": 0.02}],\n",
        "    plot_timeframes=[\"15m\"],\n",
        "    alert_timeframes=[\"15m\"],\n",
        "    retrain_models=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WV4tPwK1LSC",
        "outputId": "2f595c23-f94a-48bd-cd5b-ffc8c2b03673"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÑ Criando novo prediction_log com colunas padr√£o em: /content/prediction_log.csv\n",
            "\n",
            "üìä Analisando BTC-USD...\n",
            "‚úÖ X.shape: (2058, 20, 23), y.shape: (2058, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ Modelo LSTM salvo em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "üì¶ Metadados salvos em: /content/models/lstm_model_BTCUSD_15m_meta.pkl\n",
            "‚úÖ Features usadas no LSTM:\n",
            "['Close', 'High', 'Low', 'RSI', 'MACD', 'MACD_Signal', 'SMA_50', 'SMA_200', 'Bollinger_Upper', 'Bollinger_Lower', 'ADX', 'Stoch_K', 'Stoch_D', 'ATR', 'ROC', 'OBV', 'CCI', 'Tenkan_Sen', 'Kijun_Sen', 'VWAP', 'Doji', 'Engulfing', 'Hammer']\n",
            "‚úÖ √öltimos dados de entrada:\n",
            "             Close          High           Low        RSI        MACD  \\\n",
            "2274  88398.929688  88416.125000  88338.664062  58.589961  160.233074   \n",
            "2275  88339.617188  88485.273438  88339.617188  56.183049  148.925638   \n",
            "2276  88477.242188  88477.242188  88339.195312  60.262258  149.348009   \n",
            "\n",
            "      MACD_Signal        SMA_50       SMA_200  Bollinger_Upper  \\\n",
            "2274   165.252061  87812.924844  86451.289258     88562.196621   \n",
            "2275   161.986776  87834.957500  86466.704258     88569.448814   \n",
            "2276   159.459023  87859.491875  86482.839063     88595.408576   \n",
            "\n",
            "      Bollinger_Lower  ...         ATR       ROC           OBV        CCI  \\\n",
            "2274     87937.304942  ...  169.367663  0.020632  1.741354e+10  73.125976   \n",
            "2275     87952.328530  ...  167.673990  0.193165  1.608915e+10  66.951958   \n",
            "2276     87951.206268  ...  165.557768  0.352645  1.822102e+10  80.364336   \n",
            "\n",
            "        Tenkan_Sen     Kijun_Sen          VWAP  Doji  Engulfing  Hammer  \n",
            "2274  88333.933594  88252.742188  83067.298916     0          0       1  \n",
            "2275  88407.769531  88252.742188  83073.658827     0          0       0  \n",
            "2276  88408.156250  88252.742188  83083.947184     0          1       0  \n",
            "\n",
            "[3 rows x 23 columns]\n",
            "‚úÖ Valores m√≠nimos do scaler X:\n",
            "[ 7.46807734e+04  7.50814922e+04  7.44677031e+04  7.87661279e+00\n",
            " -9.34990648e+02 -7.98300066e+02  7.63981427e+04  7.77543223e+04\n",
            "  7.68572739e+04  7.42381765e+04  7.42692641e+00  0.00000000e+00\n",
            "  0.00000000e+00  7.73048997e+01 -5.12829440e+00 -2.53189786e+10\n",
            " -3.51859688e+02  7.54795234e+04  7.57337930e+04  8.09605763e+04\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "‚úÖ Valores m√°ximos do scaler X:\n",
            "[8.85605781e+04 8.88214688e+04 8.84452500e+04 8.74095514e+01\n",
            " 1.41447573e+03 1.26625240e+03 8.78594919e+04 8.70263770e+04\n",
            " 8.87535461e+04 8.79523285e+04 5.82971570e+01 1.00000000e+02\n",
            " 9.98689638e+01 9.65087956e+02 6.96237293e+00 2.36433244e+10\n",
            " 3.98173955e+02 8.84081562e+04 8.82970859e+04 8.67924056e+04\n",
            " 1.00000000e+00 1.00000000e+00 1.00000000e+00]\n",
            "üíæ Modelo XGBoost salvo em: /content/models/xgb_model_BTCUSD_15m.joblib\n",
            "‚úÖ X.shape: (2257, 20, 23), y.shape: (2257, 3)\n",
            "üìÇ Modelo LSTM encontrado em: /content/models/lstm_model_BTCUSD_15m.h5\n",
            "üì¶ Metadados carregados de: /content/models/lstm_model_BTCUSD_15m_meta.pkl\n",
            "üîç Pre√ßo atual (15m): $88,477.24\n",
            "üîÆ Previs√£o LSTM: $88,144.22\n",
            "üìà Varia√ß√£o prevista: -0.38%\n",
            "‚ö†Ô∏è Arquivo inv√°lido (sem colunas): prediction_log.csv\n",
            "‚ö†Ô∏è Ignorando leitura do prediction_log.csv pois est√° vazio ou ausente.\n",
            "‚õî Previs√£o LSTM neutra ‚Äî alerta n√£o enviado.\n",
            "\n",
            "üìÅ Resultados salvos em: model_results_2025-04-22_09-33-52.csv\n",
            "‚ö†Ô∏è Arquivo inv√°lido (sem colunas): /content/prediction_log.csv\n",
            "üîÑ Log de previs√µes criado em: /content/prediction_log.csv\n",
            "‚úÖ An√°lise completa.\n",
            "\n",
            "üß™ √öltimos sinais registrados no log:\n",
            "                      Date   Asset Timeframe        Price  Signal  LSTM_High_Predicted  LSTM_Low_Predicted  LSTM_Predicted     TP1      TP2       SL  TargetPrice  AdjustedProb\n",
            "2025-04-22 09:33:52.908958 BTC-USD       15m 88477.242188      -1         88227.242188           88454.375     88144.21875 86707.7 84938.15 90246.79  88144.21875           1.0\n"
          ]
        }
      ]
    }
  ]
}